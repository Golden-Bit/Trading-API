########################################
docu-analyzers-analyzers.txt - lunghezza: 13171
########################################
Analyzers

Be it backtesting or trading, being able to analyze the performance of the
trading system is key to understanding if not only profit has been attained,
but also if it has been achieved with too much risk or if it was really worth
the effort when compared with a reference asset (or a risk-free asset)

That’s where the family of 
Analyzer
 objects comes in: provide an analysis
of what’s happened or even of what’s actually happening.

Nature of analyzers

The interface is modeled after that of 
Lines
 objects, feature for example a

next
 method but there is a major difference:

Analyzers
 do not hold lines.

That means they are not expensive in terms of memory because even after
having analyzed thousands of price bars they may still simply hold a single
result in memory.

Location in the ecosystem

Analyzer
 objects are (like 
strategies
, 
observers
 and 
datas
) added to
the system through a 
cerebro
 instance:

addanalyzer(ancls, *args, **kwargs)

But when it comes to operation during 
cerebro.run
 the following will happen
for each 
strategy
 present in the system

ancls
 will be instantiated with 
*args
 and 
**kwargs
 during a 
cerebro.run

The 
ancls
 instance will be attached to the strategy

That means:

If the backtesting run contains for example 
3 strategies
 then 
3
    instances
 of 
ancls
 will be created and each of them will be attached
    to a different strategy.

Bottomline: 
an analyzer analyzes the performance of a single strategy
 and

not the performance of an entires system

Additional Location

Some 
Analyzer
 objects may actually use other analyzers to complete its
work. For example: 
SharpeRatio
 uses the output of 
TimeReturn
 for the
calculations.

These 
sub-analyzers
 or 
slave-analyzers
 will also be inserted into the same
strategy as the one creating them. But they are completely invisible to the user.

Attributes

To carry out the intended work, 
Analyzer
 objects are provided with some
default attributes which are automagically passed and set in the instance for
ease of use:

self.strategy
: reference to the strategy subclass in which the
    analyzer object is operating.  Anything accessible by the 
strategy
 can
    also be accessd by the 
analyzer

self.datas[x]
: the array of data feeds present in the
    strategy. Although this could be accesed over the 
strategy
 reference, the
    shortcut makes work more comfortable.

self.data
: shortcut to 
self.datas[0]
 for extra comfort.

self.dataX
: shortcuts to the different 
self.datas[x]

Some other aliases are available although they are probably an overkill:

```
* `self.dataX_Y` where X is a reference to `self.datas[X]` and `Y`
  refers to the line, finally pointing to: `self.datas[X].lines[Y]`

```

If the line has a name, the following is also available:

```
* `self.dataX_Name` which resolves to `self.datas[X].Name` returning
  the line by name rather than by index

```

For the first data, the last two shortcuts are available without the initial

X
 numeric reference. For example:

```
* `self.data_2` refers to `self.datas[0].lines[2]`

```

And

```
* `self.data_close` refers to `self.datas[0].close`

```

Returning the analysis

The 
Analyzer
 base class creates a 
self.rets
 (of type

collections.OrderedDict
) member attribute to return the analysis. This is
done in the method 
create_analysis
 which can be overriden by subclasses if
creating custom analyzers.

Modus operandi

Although 
Analyzer
 objects are not 
Lines
 objects and therefore do not
iterate over lines, they have been designed to follow the same operation
pattern.

Instantiated before the system is put into motion (therefore calling

__init__
)

Signaled the begin of operations with 
start

prenext
 / 
nextstart
 / 
next
 will be invoked following the
     calculated minimum period of the 
strategy
 the indicator is working in.

The default behaviour of 
prenext
 and 
nextstart
 is to invoke next,
 because an analyzer may be analyzing from the very first moment the system
 is alive.

It may be customary to call 
len(self)
 in 
Lines
 objects to check the
 actual amount of bars. This also works in 
Analyzers
 by returning the
 value for 
self.strategy

Orders and trades will be notified just like they are to the strategy via

notify_order
 and 
notify_trade

Cash and value will also be notified like it is done with the strategy
     over the 
notify_cashvalue
 method

Cash, value and fundvalue and fund shares will also be notified like it is
     done with the strategy over the 
notify_fund
 method

stop
 will be invoked to signal the end of operations

Once the regular operations cycle has been completed, the 
analyzers
 featuring
additional methods for extracting/outputting information

get_analysis
: which ideally (not enforced) returnes a 
dict
 -like
    object containing the analysis results.

print
 uses a standard 
backtrader.WriterFile
 (unless overriden) to
    write the analysis result from 
get_analysis
.

pprint
 (
pretty print
) uses the Python 
pprint
 module to print the

get_analysis
 resutls.

And finally:

get_analysis
 creates a member attribute 
self.ret
 (of type

collections.OrderedDict
) to which analyzers write the analysis results.

Subclasses of 
Analyzer
 can override this method to change this behavior

Analyzer Patterns

Development of 
Analyzer
 objects in the 
backtrader
 platform have revealed
2 different usage patterns for the generation of the analysis:

During execution by gathering information in the 
notify_xxx
 and

next
 methods, and generating the current information of the analysis
     in 
next

The 
TradeAnalyzer
, for example, uses just the 
notify_trade
 method
 to generate the statistics.

Gather (or not) the information as above, but generate the analysis in a
     single pass during the 
stop
 method

The 
SQN
 (
System Quality Number
) gathers trade information during

notify_trade
 but generates the statistic during the 
stop
 method

A quick example

As easy as it can be:

```
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import datetime

import backtrader as bt
import backtrader.analyzers as btanalyzers
import backtrader.feeds as btfeeds
import backtrader.strategies as btstrats

cerebro = bt.Cerebro()

# data
dataname = '../datas/sample/2005-2006-day-001.txt'
data = btfeeds.BacktraderCSVData(dataname=dataname)

cerebro.adddata(data)

# strategy
cerebro.addstrategy(btstrats.SMA_CrossOver)

# Analyzer
cerebro.addanalyzer(btanalyzers.SharpeRatio, _name='mysharpe')

thestrats = cerebro.run()
thestrat = thestrats[0]

print('Sharpe Ratio:', thestrat.analyzers.mysharpe.get_analysis())

```

Executing it (having stored it in 
analyzer-test.py
:

```
$ ./analyzer-test.py
Sharpe Ratio: {'sharperatio': 11.647332609673256}

```

There is no plotting, because the 
SharpeRatio
 is a single value at the end
of the calculation.

Forensic Analysis of an Analyzer

Let’s repeat that 
Analyzers
 are not Lines objects, but to seamlessly
integrate them into the 
backtrader
 ecosystem, the internal API conventions
of several Lines object are followed (actually a 
mixture
 of them)

Note

The code for the 
SharpeRatio
 has evolved to take for example into
account annualization and the version here should only be a
reference.

Please check the Analyzers Reference

There is additionally a 
SharpeRatio_A
 which provides the value
directly in annualized form regardless of the sought timeframe

Code for 
SharpeRatio
 to serve as a basis (a simplified version)

```
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import operator

from backtrader.utils.py3 import map
from backtrader import Analyzer, TimeFrame
from backtrader.mathsupport import average, standarddev
from backtrader.analyzers import AnnualReturn

class SharpeRatio(Analyzer):
    params = (('timeframe', TimeFrame.Years), ('riskfreerate', 0.01),)

    def __init__(self):
        super(SharpeRatio, self).__init__()
        self.anret = AnnualReturn()

    def start(self):
        # Not needed ... but could be used
        pass

    def next(self):
        # Not needed ... but could be used
        pass

    def stop(self):
        retfree = [self.p.riskfreerate] * len(self.anret.rets)
        retavg = average(list(map(operator.sub, self.anret.rets, retfree)))
        retdev = standarddev(self.anret.rets)

        self.ratio = retavg / retdev

    def get_analysis(self):
        return dict(sharperatio=self.ratio)

```

The code can be broken down into:

params
 declaration

Although the declared ones are not used (meant as an example), 
Analyzers

like most other objects in 
backtrader
 support parameters

__init__
 method

Just like 
Strategies
 declare 
Indicators
 in 
__init__
, the same do
analyzers with support objects.

In this case: the 
SharpeRatio
 is calculated using 
Annual Returns
. The
calculation will be automatic and will be available to 
SharpeRatio
 for
its own calculations.

Note

The actual implementation of 
SharpeRatio
 uses the more
generic and later developed 
TimeReturn
 analyzer

next
 method

SharpeRatio
 doesn’t need it, but this method will be called after each
invocation of the parent strategy 
next

start
 method

Called right before the backtesting starts. Can be used for extra
initialization tasks. Sharperatio doesn’t need it

stop
 method

Called right after the backtesting ends. Like 
SharpeRatio
 does, it can
be used to finish/make the calculation

get_analysis
 method (returns a dictionary)

Access for external callers to the produced analysis

Returns: a dictionary with the analysis.

Reference

class backtrader.Analyzer()

Analyzer base class. All analyzers are subclass of this one

An Analyzer instance operates in the frame of a strategy and provides an
analysis for that strategy.

Automagically set member attributes:

self.strategy
 (giving access to the 
strategy
 and anything
    accessible from it)

self.datas[x]
 giving access to the array of data feeds present in
    the the system, which could also be accessed via the strategy reference

self.data
, giving access to 
self.datas[0]

self.dataX
 -> 
self.datas[X]

self.dataX_Y
 -> 
self.datas[X].lines[Y]

self.dataX_name
 -> 
self.datas[X].name

self.data_name
 -> 
self.datas[0].name

self.data_Y
 -> 
self.datas[0].lines[Y]

This is not a 
Lines
 object, but the methods and operation follow the same
design

__init__
 during instantiation and initial setup

start
 / 
stop
 to signal the begin and end of operations

prenext
 / 
nextstart
 / 
next
 family of methods that follow
    the calls made to the same methods in the strategy

notify_trade
 / 
notify_order
 / 
notify_cashvalue
 /

notify_fund
 which receive the same notifications as the equivalent
    methods of the strategy

The mode of operation is open and no pattern is preferred. As such the
analysis can be generated with the 
next
 calls, at the end of operations
during 
stop
 and even with a single method like 
notify_trade

The important thing is to override 
get_analysis
 to return a 
dict-like

object containing the results of the analysis (the actual format is
implementation dependent)

start()

Invoked to indicate the start of operations, giving the analyzer
time to setup up needed things

stop()

Invoked to indicate the end of operations, giving the analyzer
time to shut down needed things

prenext()

Invoked for each prenext invocation of the strategy, until the minimum
period of the strategy has been reached

The default behavior for an analyzer is to invoke 
next

nextstart()

Invoked exactly once for the nextstart invocation of the strategy,
when the minimum period has been first reached

next()

Invoked for each next invocation of the strategy, once the minum
preiod of the strategy has been reached

notify_cashvalue(cash, value)

Receives the cash/value notification before each next cycle

notify_fund(cash, value, fundvalue, shares)

Receives the current cash, value, fundvalue and fund shares

notify_order(order)

Receives order notifications before each next cycle

notify_trade(trade)

Receives trade notifications before each next cycle

get_analysis()

Returns a 
dict-like
 object with the results of the analysis

The keys and format of analysis results in the dictionary is
implementation dependent.

It is not even enforced that the result is a 
dict-like object
, just
the convention

The default implementation returns the default OrderedDict 
rets

created by the default 
create_analysis
 method

create_analysis()

Meant to be overriden by subclasses. Gives a chance to create the
structures that hold the analysis.

The default behaviour is to create a 
OrderedDict
 named 
rets

print(*args, **kwargs)

Prints the results returned by 
get_analysis
 via a standard

Writerfile
 object, which defaults to writing things to standard
output

pprint(*args, **kwargs)

Prints the results returned by 
get_analysis
 using the pretty
print Python module (
pprint
)

len
()

Support for invoking 
len
 on analyzers by actually returning the
current length of the strategy the analyzer operates on
########################################
docu-analyzers-pyfolio.txt - lunghezza: 2738
########################################
PyFolio Overview

Note

As of (at least) 2017-07-25 the 
pyfolio
 APIs have changed and

create_full_tear_sheet
 no longer has a 
gross_lev
 as a named
argument.

Consequently the sample for integration doesn’t work

Quoting from the main 
pyfolio
 page at 
http://quantopian.github.io/pyfolio/
:

```
pyfolio is a Python library for performance and risk analysis of financial
portfolios developed by Quantopian Inc. It works well with the Zipline open
source backtesting library

```

And now it works also well with 
backtrader
. What’s needed:

pyfolio
 obviously

And its dependencies (things like 
pandas
, 
seaborn
 …)

Note

During the integration with version 
0.5.1
, an update to the most
recent packages of the dependencies was needed, like 
seaborn
 from
the previously installed 
0.7.0-dev
 to 
0.7.1
, apparently due to
the absence of the method 
swarmplot

Usage

Add the 
PyFolio
 analyzer to the 
cerebro
 mix:

```
cerebro.addanalyzer(bt.analyzers.PyFolio)

```

Run and retrieve the 1
st
 strategy:

```
strats = cerebro.run()
strat0 = strats[0]

```

Retrieve the analyzer using whatever name you gave to it or the default
     name it will be given to it: 
pyfolio
. For example:

```
pyfolio = strats.analyzers.getbyname('pyfolio')

```

Use the analyzer method 
get_pf_items
 to retrieve the 4 components
     later needed for 
pyfolio
:

```
returns, positions, transactions, gross_lev = pyfoliozer.get_pf_items()

```

!!! note

```
The integration was done looking at test samples available with
`pyfolio` and the same headers (or absence of) has been replicated

```

Work with 
pyfolio
 (this is already outside of the 
backtrader

     ecosystem)

Some usage notes not directly related to 
backtrader

pyfolio
 automatic plotting works outside of a 
Jupyter Notebook
, but

it works best
 inside

pyfolio
 data tables’ output seems to barely work outside of a 
Jupyter
    Notebook
. It works inside the 
Notebook

The conclusion is easy if working with 
pyfolio
 is wished: 
work inside a
Jupyter Notebook

Sample Code

The code would look like this:

```
...
cerebro.addanalyzer(bt.analyzers.PyFolio, _name='pyfolio')
...
results = cerebro.run()
strat = results[0]
pyfoliozer = strat.analyzers.getbyname('pyfolio')
returns, positions, transactions, gross_lev = pyfoliozer.get_pf_items()
...
...
# pyfolio showtime
import pyfolio as pf
pf.create_full_tear_sheet(
    returns,
    positions=positions,
    transactions=transactions,
    gross_lev=gross_lev,
    live_start_date='2005-05-01',  # This date is sample specific
    round_trips=True)

# At this point tables and chart will show up

```

Reference

Look into the Analyzers Reference for the 
PyFolio
 analyzer and which
analyzers it uses internally
########################################
docu-analyzers-reference.txt - lunghezza: 18953
########################################
Analyzers Reference

AnnualReturn

class backtrader.analyzers.AnnualReturn()

This analyzer calculates the AnnualReturns by looking at the beginning
and end of the year

Params:

(None)

Member Attributes:

rets
: list of calculated annual returns

ret
: dictionary (key: year) of annual returns

get_analysis
:

Returns a dictionary of annual returns (key: year)

Calmar

class backtrader.analyzers.Calmar()

This analyzer calculates the CalmarRatio
timeframe which can be different from the one used in the underlying data
Params:

timeframe
 (default: 
None
)
    If 
None
 the 
timeframe
 of the 1
st
 data in the system will be
    used

Pass 
TimeFrame.NoTimeFrame
 to consider the entire dataset with no
time constraints

compression
 (default: 
None
)

Only used for sub-day timeframes to for example work on an hourly
timeframe by specifying “TimeFrame.Minutes” and 60 as compression

If 
None
 then the compression of the 1
st
 data of the system will be
used

None

fund
 (default: 
None
)

If 
None
 the actual mode of the broker (fundmode - True/False) will
be autodetected to decide if the returns are based on the total net
asset value or on the fund value. See 
set_fundmode
 in the broker
documentation

Set it to 
True
 or 
False
 for a specific behavior

- ``get_analysis``()

Returns a OrderedDict with a key for the time period and the
corresponding rolling Calmar ratio

- ``calmar`` the latest calculated calmar ratio()

DrawDown

class backtrader.analyzers.DrawDown()

This analyzer calculates trading system drawdowns stats such as drawdown
values in %s and in dollars, max drawdown in %s and in dollars, drawdown
length and drawdown max length

Params:

fund
 (default: 
None
)

If 
None
 the actual mode of the broker (fundmode - True/False) will
be autodetected to decide if the returns are based on the total net
asset value or on the fund value. See 
set_fundmode
 in the broker
documentation

Set it to 
True
 or 
False
 for a specific behavior

- ``get_analysis``()

Returns a dictionary (with . notation support and subdctionaries) with
drawdown stats as values, the following keys/attributes are available:

drawdown
 - drawdown value in 0.xx %

moneydown
 - drawdown value in monetary units

len
 - drawdown length

max.drawdown
 - max drawdown value in 0.xx %

max.moneydown
 - max drawdown value in monetary units

max.len
 - max drawdown length

TimeDrawDown

class backtrader.analyzers.TimeDrawDown()

This analyzer calculates trading system drawdowns on the chosen
timeframe which can be different from the one used in the underlying data
Params:

timeframe
 (default: 
None
)
    If 
None
 the 
timeframe
 of the 1
st
 data in the system will be
    used

Pass 
TimeFrame.NoTimeFrame
 to consider the entire dataset with no
time constraints

compression
 (default: 
None
)

Only used for sub-day timeframes to for example work on an hourly
timeframe by specifying “TimeFrame.Minutes” and 60 as compression

If 
None
 then the compression of the 1
st
 data of the system will be
used

None

fund
 (default: 
None
)

If 
None
 the actual mode of the broker (fundmode - True/False) will
be autodetected to decide if the returns are based on the total net
asset value or on the fund value. See 
set_fundmode
 in the broker
documentation

Set it to 
True
 or 
False
 for a specific behavior

- ``get_analysis``()

Returns a dictionary (with . notation support and subdctionaries) with
drawdown stats as values, the following keys/attributes are available:

drawdown
 - drawdown value in 0.xx %

maxdrawdown
 - drawdown value in monetary units

maxdrawdownperiod
 - drawdown length

- Those are available during runs as attributes()

dd

maxdd

maxddlen

GrossLeverage

class backtrader.analyzers.GrossLeverage()

This analyzer calculates the Gross Leverage of the current strategy
on a timeframe basis

Params:

fund
 (default: 
None
)

If 
None
 the actual mode of the broker (fundmode - True/False) will
be autodetected to decide if the returns are based on the total net
asset value or on the fund value. See 
set_fundmode
 in the broker
documentation

Set it to 
True
 or 
False
 for a specific behavior

- get_analysis()

Returns a dictionary with returns as values and the datetime points for
each return as keys

PositionsValue

class backtrader.analyzers.PositionsValue()

This analyzer reports the value of the positions of the current set of
datas

Params:

timeframe (default: 
None
)
    If 
None
 then the timeframe of the 1
st
 data of the system will be
    used

compression (default: 
None
)

Only used for sub-day timeframes to for example work on an hourly
timeframe by specifying “TimeFrame.Minutes” and 60 as compression

If 
None
 then the compression of the 1
st
 data of the system will be
used

headers (default: 
False
)

Add an initial key to the dictionary holding the results with the names
of the datas (‘Datetime’ as key

cash (default: 
False
)

Include the actual cash as an extra position (for the header ‘cash’
will be used as name)

- get_analysis()

Returns a dictionary with returns as values and the datetime points for
each return as keys

PyFolio

class backtrader.analyzers.PyFolio()

This analyzer uses 4 children analyzers to collect data and transforms it
in to a data set compatible with 
pyfolio

Children Analyzer

TimeReturn

Used to calculate the returns of the global portfolio value

PositionsValue

Used to calculate the value of the positions per data. It sets the

headers
 and 
cash
 parameters to 
True

Transactions

Used to record each transaction on a data (size, price, value). Sets
the 
headers
 parameter to 
True

GrossLeverage

Keeps track of the gross leverage (how much the strategy is invested)

Params:

```
These are passed transparently to the children

* timeframe (default: `bt.TimeFrame.Days`)

  If `None` then the timeframe of the 1st data of the system will be
  used

* compression (default: 1\`)

  If `None` then the compression of the 1st data of the system will be
  used

```

Both 
timeframe
 and 
compression
 are set following the default
behavior of 
pyfolio
 which is working with 
daily
 data and upsample it
to obtaine values like yearly returns.

- get_analysis()

Returns a dictionary with returns as values and the datetime points for
each return as keys

get_pf_items()

Returns a tuple of 4 elements which can be used for further processing with

```
`pyfolio`

returns, positions, transactions, gross_leverage

```

Because the objects are meant to be used as direct input to 
pyfolio

this method makes a local import of 
pandas
 to convert the internal

backtrader
 results to 
pandas DataFrames
 which is the expected input
by, for example, 
pyfolio.create_full_tear_sheet

The method will break if 
pandas
 is not installed

LogReturnsRolling

class backtrader.analyzers.LogReturnsRolling()

This analyzer calculates rolling returns for a given timeframe and
compression

Params:

timeframe
 (default: 
None
)
    If 
None
 the 
timeframe
 of the 1
st
 data in the system will be
    used

Pass 
TimeFrame.NoTimeFrame
 to consider the entire dataset with no
time constraints

compression
 (default: 
None
)

Only used for sub-day timeframes to for example work on an hourly
timeframe by specifying “TimeFrame.Minutes” and 60 as compression

If 
None
 then the compression of the 1
st
 data of the system will be
used

data
 (default: 
None
)

Reference asset to track instead of the portfolio value.

NOTE
: this data must have been added to a 
cerebro
 instance with

addata
, 
resampledata
 or 
replaydata

firstopen
 (default: 
True
)

When tracking the returns of a 
data
 the following is done when
crossing a timeframe boundary, for example 
Years
:

Last 
close
 of previous year is used as the reference price to
    see the return in the current year

The problem is the 1
st
 calculation, because the data has** no
previous** closing price. As such and when this parameter is 
True

the 
opening
 price will be used for the 1
st
 calculation.

This requires the data feed to have an 
open
 price (for 
close

the standard [0] notation will be used without reference to a field
price)

Else the initial close will be used.

fund
 (default: 
None
)

If 
None
 the actual mode of the broker (fundmode - True/False) will
be autodetected to decide if the returns are based on the total net
asset value or on the fund value. See 
set_fundmode
 in the broker
documentation

Set it to 
True
 or 
False
 for a specific behavior

- get_analysis()

Returns a dictionary with returns as values and the datetime points for
each return as keys

PeriodStats

class backtrader.analyzers.PeriodStats()

Calculates basic statistics for given timeframe

Params:

timeframe
 (default: 
Years
)
    If 
None
 the 
timeframe
 of the 1
st
 data in the system will be
    used

Pass 
TimeFrame.NoTimeFrame
 to consider the entire dataset with no
time constraints

compression
 (default: 
1
)

Only used for sub-day timeframes to for example work on an hourly
timeframe by specifying “TimeFrame.Minutes” and 60 as compression

If 
None
 then the compression of the 1
st
 data of the system will be
used

fund
 (default: 
None
)

If 
None
 the actual mode of the broker (fundmode - True/False) will
be autodetected to decide if the returns are based on the total net
asset value or on the fund value. See 
set_fundmode
 in the broker
documentation

Set it to 
True
 or 
False
 for a specific behavior

get_analysis
 returns a dictionary containing the keys:

average

stddev

positive

negative

nochange

best

worst

If the parameter 
zeroispos
 is set to 
True
, periods with no change
will be counted as positive

Returns

class backtrader.analyzers.Returns()

Total, Average, Compound and Annualized Returns calculated using a
logarithmic approach

See:

https://www.crystalbull.com/sharpe-ratio-better-with-log-returns/

Params:

timeframe
 (default: 
None
)

If 
None
 the 
timeframe
 of the 1
st
 data in the system will be
used

Pass 
TimeFrame.NoTimeFrame
 to consider the entire dataset with no
time constraints

compression
 (default: 
None
)

Only used for sub-day timeframes to for example work on an hourly
timeframe by specifying “TimeFrame.Minutes” and 60 as compression

If 
None
 then the compression of the 1
st
 data of the system will be
used

tann
 (default: 
None
)

Number of periods to use for the annualization (normalization) of the

namely:

days: 252

weeks: 52

months: 12

years: 1

fund
 (default: 
None
)

If 
None
 the actual mode of the broker (fundmode - True/False) will
be autodetected to decide if the returns are based on the total net
asset value or on the fund value. See 
set_fundmode
 in the broker
documentation

Set it to 
True
 or 
False
 for a specific behavior

- get_analysis()

Returns a dictionary with returns as values and the datetime points for
each return as keys

The returned dict the following keys:

rtot
: Total compound return

ravg
: Average return for the entire period (timeframe specific)

rnorm
: Annualized/Normalized return

rnorm100
: Annualized/Normalized return expressed in 100%

SharpeRatio

class backtrader.analyzers.SharpeRatio()

This analyzer calculates the SharpeRatio of a strategy using a risk free
asset which is simply an interest rate

Params:

timeframe
: (default: 
TimeFrame.Years
)

compression
 (default: 
1
)

Only used for sub-day timeframes to for example work on an hourly
timeframe by specifying “TimeFrame.Minutes” and 60 as compression

riskfreerate
 (default: 0.01 -> 1%)

Expressed in annual terms (see 
convertrate
 below)

convertrate
 (default: 
True
)

Convert the 
riskfreerate
 from annual to monthly, weekly or daily
rate. Sub-day conversions are not supported

factor
 (default: 
None
)

If 
None
, the conversion factor for the riskfree rate from 
annual

to the chosen timeframe will be chosen from a predefined table

Days: 252, Weeks: 52, Months: 12, Years: 1

Else the specified value will be used

annualize
 (default: 
False
)

If 
convertrate
 is 
True
, the 
SharpeRatio
 will be delivered in
the 
timeframe
 of choice.

In most occasions the SharpeRatio is delivered in annualized form.
Convert the 
riskfreerate
 from annual to monthly, weekly or daily
rate. Sub-day conversions are not supported

stddev_sample
 (default: 
False
)

If this is set to 
True
 the 
standard deviation
 will be calculated
decreasing the denominator in the mean by 
1
. This is used when
calculating the 
standard deviation
 if it’s considered that not all
samples are used for the calculation. This is known as the 
Bessels’
correction

daysfactor
 (default: 
None
)

Old naming for 
factor
. If set to anything else than 
None
 and
the 
timeframe
 is 
TimeFrame.Days
 it will be assumed this is old
code and the value will be used

legacyannual
 (default: 
False
)

Use the 
AnnualReturn
 return analyzer, which as the name implies
only works on years

fund
 (default: 
None
)

If 
None
 the actual mode of the broker (fundmode - True/False) will
be autodetected to decide if the returns are based on the total net
asset value or on the fund value. See 
set_fundmode
 in the broker
documentation

Set it to 
True
 or 
False
 for a specific behavior

- get_analysis()

Returns a dictionary with key “sharperatio” holding the ratio

SharpeRatio_A

class backtrader.analyzers.SharpeRatio_A()

Extension of the SharpeRatio which returns the Sharpe Ratio directly in
annualized form

The following param has been changed from 
SharpeRatio

annualize
 (default: 
True
)

SQN

class backtrader.analyzers.SQN()

SQN or SystemQualityNumber. Defined by Van K. Tharp to categorize trading
systems.

1.6 - 1.9 Below average

2.0 - 2.4 Average

2.5 - 2.9 Good

3.0 - 5.0 Excellent

5.1 - 6.9 Superb

7.0 -     Holy Grail?

The formula:

SquareRoot(NumberTrades) * Average(TradesProfit) / StdDev(TradesProfit)

The sqn value should be deemed reliable when the number of trades >= 30

- get_analysis()

Returns a dictionary with keys “sqn” and “trades” (number of
considered trades)

TimeReturn

class backtrader.analyzers.TimeReturn()

This analyzer calculates the Returns by looking at the beginning
and end of the timeframe

Params:

timeframe
 (default: 
None
)
    If 
None
 the 
timeframe
 of the 1
st
 data in the system will be
    used

Pass 
TimeFrame.NoTimeFrame
 to consider the entire dataset with no
time constraints

compression
 (default: 
None
)

Only used for sub-day timeframes to for example work on an hourly
timeframe by specifying “TimeFrame.Minutes” and 60 as compression

If 
None
 then the compression of the 1
st
 data of the system will be
used

data
 (default: 
None
)

Reference asset to track instead of the portfolio value.

NOTE
: this data must have been added to a 
cerebro
 instance with

addata
, 
resampledata
 or 
replaydata

firstopen
 (default: 
True
)

When tracking the returns of a 
data
 the following is done when
crossing a timeframe boundary, for example 
Years
:

Last 
close
 of previous year is used as the reference price to
    see the return in the current year

The problem is the 1
st
 calculation, because the data has** no
previous** closing price. As such and when this parameter is 
True

the 
opening
 price will be used for the 1
st
 calculation.

This requires the data feed to have an 
open
 price (for 
close

the standard [0] notation will be used without reference to a field
price)

Else the initial close will be used.

fund
 (default: 
None
)

If 
None
 the actual mode of the broker (fundmode - True/False) will
be autodetected to decide if the returns are based on the total net
asset value or on the fund value. See 
set_fundmode
 in the broker
documentation

Set it to 
True
 or 
False
 for a specific behavior

- get_analysis()

Returns a dictionary with returns as values and the datetime points for
each return as keys

TradeAnalyzer

class backtrader.analyzers.TradeAnalyzer()

Provides statistics on closed trades (keeps also the count of open ones)

Total Open/Closed Trades

Streak Won/Lost Current/Longest

ProfitAndLoss Total/Average

Won/Lost Count/ Total PNL/ Average PNL / Max PNL

Long/Short Count/ Total PNL / Average PNL / Max PNL

Won/Lost Count/ Total PNL/ Average PNL / Max PNL

Length (bars in the market)

Total/Average/Max/Min

Won/Lost Total/Average/Max/Min

Long/Short Total/Average/Max/Min

Won/Lost Total/Average/Max/Min

NOTE
: The analyzer uses an “auto”dict for the fields, which means that if no
trades are executed, no statistics will be generated.

In that case there will be a single field/subfield in the dictionary
returned by 
get_analysis
, namely:

dictname[‘total’][‘total’] which will have a value of 0 (the field is
    also reachable with dot notation dictname.total.total

Transactions

class backtrader.analyzers.Transactions()

This analyzer reports the transactions occurred with each an every data in
the system

It looks at the order execution bits to create a 
Position
 starting from
0 during each 
next
 cycle.

The result is used during next to record the transactions

Params:

headers (default: 
True
)

Add an initial key to the dictionary holding the results with the names
of the datas

This analyzer was modeled to facilitate the integration with

pyfolio
 and the header names are taken from the samples used for
it:

```
'date', 'amount', 'price', 'sid', 'symbol', 'value'

```

- get_analysis()

Returns a dictionary with returns as values and the datetime points for
each return as keys

VWR

class backtrader.analyzers.VWR()

Variability-Weighted Return: Better SharpeRatio with Log Returns

Alias:

VariabilityWeightedReturn

See:

https://www.crystalbull.com/sharpe-ratio-better-with-log-returns/

Params:

timeframe
 (default: 
None
)
    If 
None
 then the complete return over the entire backtested period
    will be reported

Pass 
TimeFrame.NoTimeFrame
 to consider the entire dataset with no
time constraints

compression
 (default: 
None
)

Only used for sub-day timeframes to for example work on an hourly
timeframe by specifying “TimeFrame.Minutes” and 60 as compression

If 
None
 then the compression of the 1
st
 data of the system will be
used

tann
 (default: 
None
)

Number of periods to use for the annualization (normalization) of the
average returns. If 
None
, then standard 
t
 values will be used,
namely:

days: 252

weeks: 52

months: 12

years: 1

tau
 (default: 
2.0
)

factor for the calculation (see the literature)

sdev_max
 (default: 
0.20
)

max standard deviation (see the literature)

fund
 (default: 
None
)

If 
None
 the actual mode of the broker (fundmode - True/False) will
be autodetected to decide if the returns are based on the total net
asset value or on the fund value. See 
set_fundmode
 in the broker
documentation

Set it to 
True
 or 
False
 for a specific behavior

- get_analysis()

Returns a dictionary with returns as values and the datetime points for
each return as keys

The returned dict contains the following keys:

vwr
: Variability-Weighted Return
########################################
docu-automated-bt-run-automated-bt-run.txt - lunghezza: 22584
########################################
Automating BackTesting

So far all 
backtrader
 examples and working samples have started from scratch
creating a main 
Python
 module which loads datas, strategies, observers and
prepares cash and commission schemes.

One of the goals of 
algorithmic trading
 is the automation of trading and given
that backtrader is a 
backtesting
 platform intented to check trading algorithms
(hence is an 
algotrading
 platform), automating the use of backtrader was an
obvious goal.

When installed 
backtrader
 provides 2 entry points in the form of
scripts/executables which which automates most tasks:

bt-run-py
 a script which uses the codebase from the next item

and

btrun
 (executable)

Entry point created by 
setuptools
 during packaging. The executable
offers advantages under Windows where in theory no errors about “path/file
not found” will happen.

The description below applies equally to both tools.

btrun
 allows the end user to:

Say which data feeds have to be loaded

Set the format to load the datas

Specify the date range for the datas

Pass parameters to Cerebro

Disable standard observers

This was an original extra switch before the “Cerebro” parameters were
  implemented. As such and if a parameter to cerebro with regards to
  Standard Observers is passed, this will be ignored (parameter 
stdstats

  to Cerebro)

Load one or more observers (example: 
DrawDown
) from the built-in ones or
    from a python module

Set the cash and commission scheme parameters for the broker (commission,
    margin, mult)

Enable plotting, controlling the amount of charts and style to present the
    data

Add a parametrized writer to the system

And finally what should be the core competence:

Load a strategy (a built-in one or from a Python module)

Pass parameters to the loaded strategy

See below for the 
Usage
 of the script.

Applying a User Defined Strategy

Let’s consider the following strategy which:

Simply loads a SimpleMovingAverage (default period 15)

Prints outs

Is in a file named 
mymod.py

```
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import backtrader as bt
import backtrader.indicators as btind

class MyTest(bt.Strategy):
    params = (('period', 15),)

    def log(self, txt, dt=None):
        ''' Logging function fot this strategy'''
        dt = dt or self.data.datetime[0]
        if isinstance(dt, float):
            dt = bt.num2date(dt)
        print('%s, %s' % (dt.isoformat(), txt))

    def __init__(self):
        sma = btind.SMA(period=self.p.period)

    def next(self):
        ltxt = '%d, %.2f, %.2f, %.2f, %.2f, %.2f, %.2f'

        self.log(ltxt %
                 (len(self),
                  self.data.open[0], self.data.high[0],
                  self.data.low[0], self.data.close[0],
                  self.data.volume[0], self.data.openinterest[0]))

```

Executing the strategy with the usual testing sample is easy:
easy:

```
btrun --csvformat btcsv \
      --data ../../datas/2006-day-001.txt \
      --strategy mymod.py

```

The chart output

The console output:

```
2006-01-20T23:59:59+00:00, 15, 3593.16, 3612.37, 3550.80, 3550.80, 0.00, 0.00
2006-01-23T23:59:59+00:00, 16, 3550.24, 3550.24, 3515.07, 3544.31, 0.00, 0.00
2006-01-24T23:59:59+00:00, 17, 3544.78, 3553.16, 3526.37, 3532.68, 0.00, 0.00
2006-01-25T23:59:59+00:00, 18, 3532.72, 3578.00, 3532.72, 3578.00, 0.00, 0.00
...
...
2006-12-22T23:59:59+00:00, 252, 4109.86, 4109.86, 4072.62, 4073.50, 0.00, 0.00
2006-12-27T23:59:59+00:00, 253, 4079.70, 4134.86, 4079.70, 4134.86, 0.00, 0.00
2006-12-28T23:59:59+00:00, 254, 4137.44, 4142.06, 4125.14, 4130.66, 0.00, 0.00
2006-12-29T23:59:59+00:00, 255, 4130.12, 4142.01, 4119.94, 4119.94, 0.00, 0.00

```

Same strategy but:

Setting the parameter 
period
 to 50

The command line:

```
btrun --csvformat btcsv \
      --data ../../datas/2006-day-001.txt \
      --plot \
      --strategy mymod.py:period=50

```

The chart output.

Note

if no 
.py
 extension is given, bt-run will add it.

Using a built-in Strategy

backtrader
 will slowly be including sample (textbook) strategies. Along with
the 
bt-run.py
 script a standard 
Simple Moving Average CrossOver
 strategy
is included. The name:

SMA_CrossOver

Parameters

fast
 (default 
10
) period of the fast moving average

slow
 (default 
30
) period of the slow moving average

The strategy buys if the fast moving average crosses up the fast and sells (only
if it has bought before) upon the fast moving average crossing down the slow
moving average.

The code

```
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import backtrader as bt
import backtrader.indicators as btind

class SMA_CrossOver(bt.Strategy):

    params = (('fast', 10), ('slow', 30))

    def __init__(self):

        sma_fast = btind.SMA(period=self.p.fast)
        sma_slow = btind.SMA(period=self.p.slow)

        self.buysig = btind.CrossOver(sma_fast, sma_slow)

    def next(self):
        if self.position.size:
            if self.buysig < 0:
                self.sell()

        elif self.buysig > 0:
            self.buy()

```

Standard execution:

```
btrun --csvformat btcsv \
      --data ../../datas/2006-day-001.txt \
      --plot \
      --strategy :SMA_CrossOver

```

Notice the 
:
. The standard notation (see below) to load a strategy is:

module:stragegy:kwargs

With the following rules:

If module is there and strategy is specified, then that strategy will be
    used

If module is there but no strategy is specified, the 1
st
 strategy found in
    the module will be returned

If no module is specified, “strategy” is assumed to refer to a strategy in
    the 
backtrader
 package

If module and/or strategy are there, if kwargs are present they will be
    passed to the corresponding strategy

Note

The same notation and rules apply to 
--observer
, 
--analyzer
 and

--indicator
 options

Obviously for the corresponding object types

The output

One last example adding commission schemes, cash and changing the parameters:

```
btrun --csvformat btcsv \
      --data ../../datas/2006-day-001.txt \
      --plot \
      --cash 20000 \
      --commission 2.0 \
      --mult 10 \
      --margin 2000 \
      --strategy :SMA_CrossOver:fast=5,slow=20

```

The output

We have backtested the strategy:

Changing the moving average periods

Setting a new starting cash

Putting a commission scheme in place for a futures-like instrument

See the continuous variations in cash with each bar, as cash is adjusted for
the futures-like instrument daily changes

Using no Strategy

This is a an over-statement. A strategy will be applied, but you can ommit any
kind of strategy and a default backtrader.Strategy will be added.

Analyzers, Observers and Indicators will be automatically injected in the strategy.

An example:

```
btrun --csvformat btcsv \
      --data ../../datas/2006-day-001.txt \
      --cash 20000 \
      --commission 2.0 \
      --mult 10 \
      --margin 2000 \
      --nostdstats \
      --observer :Broker

```

This will do not much but serves the purpose:

A default backtrader.Strategy is added in the background

Cerebro will not instantiate the regular 
stdstats
 observers (Broker,
    BuySell, Trades)

A 
Broker
 observer is added manually

As mentioned above, the 
nostdstats
 is a legacy parameter. Newer versions of

btrun
 can pass parameters directly to 
Cerebro
. An equivalent invocation
would be:

```
btrun --csvformat btcsv \
      --data ../../datas/2006-day-001.txt \
      --cash 20000 \
      --commission 2.0 \
      --mult 10 \
      --margin 2000 \
      --cerebro stdstats=False \
      --observer :Broker

```

Adding Analyzers

btrun
 also supports adding 
Analyzers
 with the same syntax used for the
strategies to choose between internal/external analyzers.

Example with a 
SharpeRatio
 analysis for the years 2005-2006:

```
btrun --csvformat btcsv \
      --data ../../datas/2005-2006-day-001.txt \
      --strategy :SMA_CrossOver \
      --analyzer :SharpeRatio

```

The console output is 
nothing
.

If a printout of the 
Analyzer
 results is wished, it must be specified with:

--pranalyzer
 which defaults to calling the next one (unless the Analyzer
    has overriden the proper method)

--ppranalyzer
 which uses the 
pprint
 module to print the results

Note

The two printing options were implemented before 
writers
 were part of
backtrader. Adding a writer without csv output will achieve the same (and
the output has been improved)

Extending the example from above:

```
btrun --csvformat btcsv \
      --data ../../datas/2005-2006-day-001.txt \
      --strategy :SMA_CrossOver \
      --analyzer :SharpeRatio \
      --plot \
      --pranalyzer

====================
== Analyzers
====================
##########
sharperatio
##########
{'sharperatio': 11.647332609673256}

```

Good strategy!!! (Pure luck for the example actually which also bears no
commissions)

The chart (which simply shows the Analyzer is not in the plot, because Analyzers
cannot be plotted, they aren’t lines objects)

The same example but using a 
writer
 argument:

```
btrun --csvformat btcsv \
      --data ../../datas/2005-2006-day-001.txt \
      --strategy :SMA_CrossOver \
      --analyzer :SharpeRatio \
      --plot \
      --writer

===============================================================================
Cerebro:
  -----------------------------------------------------------------------------
  - Datas:
    +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    - Data0:
      - Name: 2005-2006-day-001
      - Timeframe: Days
      - Compression: 1
  -----------------------------------------------------------------------------
  - Strategies:
    +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    - SMA_CrossOver:
      *************************************************************************
      - Params:
        - fast: 10
        - slow: 30
        - _movav: SMA
      *************************************************************************
      - Indicators:
        .......................................................................
        - SMA:
          - Lines: sma
          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          - Params:
            - period: 30
        .......................................................................
        - CrossOver:
          - Lines: crossover
          - Params: None
      *************************************************************************
      - Observers:
        .......................................................................
        - Broker:
          - Lines: cash, value
          - Params: None
        .......................................................................
        - BuySell:
          - Lines: buy, sell
          - Params: None
        .......................................................................
        - Trades:
          - Lines: pnlplus, pnlminus
          - Params: None
      *************************************************************************
      - Analyzers:
        .......................................................................
        - Value:
          - Begin: 10000.0
          - End: 10496.68
        .......................................................................
        - SharpeRatio:
          - Params: None
          ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          - Analysis:
            - sharperatio: 11.6473326097

```

Adding Indicators and Observers

As with 
Strategies
 and 
Analyzers
 btrun can also add:

Indicators

and

Observers

The syntax is exactly the same as seen above when adding a 
Broker
 observer.

Let’s repeat the example but adding a 
Stochastic
, the 
Broker
 and having
a look at the plot (we’ll change some parameters):

```
btrun --csvformat btcsv \
      --data ../../datas/2006-day-001.txt \
      --nostdstats \
      --observer :Broker \
      --indicator :Stochastic:period_dslow=5 \
      --plot

```

The chart

Plotting Control

Most of the above examples have used the following option:

--plot
 which has activated the creation a default plot

More control can be achieved by adding 
kwargs
 to the 
--plot

option

--plot style="candle"
 for example to plot with candlesticks instead of
    plotting with a 
LineOnClose
 style (which is the plotting default)

The invocation:

```
btrun --csvformat btcsv \
      --data ../../datas/2006-day-001.txt \
      --nostdstats \
      --observer :Broker \
      --indicator :Stochastic:period_dslow=5 \
      --plot style=\"candle\"

```

Note

The quotes around 
candle
 are quoted with backslashed 
\\
 because the
example is being run in a bash shell which removes that before passing the
arguments to the script.

Backslash quoting is needed in this case to ensure “bar” makes it to the
script and can be evaluated as a string

The chart

Usage of the script

Directly from the script:

```
$ btrun --help
usage: btrun-script.py [-h] --data DATA [--cerebro [kwargs]] [--nostdstats]
                       [--format {yahoocsv_unreversed,vchart,vchartcsv,yahoo,mt4csv,ibdata,sierracsv,yahoocsv,btcsv,vcdata}]
                       [--fromdate FROMDATE] [--todate TODATE]
                       [--timeframe {microseconds,seconds,weeks,months,minutes,days,years}]
                       [--compression COMPRESSION]
                       [--resample RESAMPLE | --replay REPLAY]
                       [--strategy module:name:kwargs]
                       [--signal module:signaltype:name:kwargs]
                       [--observer module:name:kwargs]
                       [--analyzer module:name:kwargs]
                       [--pranalyzer | --ppranalyzer]
                       [--indicator module:name:kwargs] [--writer [kwargs]]
                       [--cash CASH] [--commission COMMISSION]
                       [--margin MARGIN] [--mult MULT] [--interest INTEREST]
                       [--interest_long] [--slip_perc SLIP_PERC]
                       [--slip_fixed SLIP_FIXED] [--slip_open]
                       [--no-slip_match] [--slip_out] [--flush]
                       [--plot [kwargs]]

Backtrader Run Script

optional arguments:
  -h, --help            show this help message and exit
  --resample RESAMPLE, -rs RESAMPLE
                        resample with timeframe:compression values
  --replay REPLAY, -rp REPLAY
                        replay with timeframe:compression values
  --pranalyzer, -pralyzer
                        Automatically print analyzers
  --ppranalyzer, -ppralyzer
                        Automatically PRETTY print analyzers
  --plot [kwargs], -p [kwargs]
                        Plot the read data applying any kwargs passed

                        For example:

                          --plot style="candle" (to plot candlesticks)

Data options:
  --data DATA, -d DATA  Data files to be added to the system

Cerebro options:
  --cerebro [kwargs], -cer [kwargs]
                        The argument can be specified with the following form:

                          - kwargs

                            Example: "preload=True" which set its to True

                        The passed kwargs will be passed directly to the cerebro
                        instance created for the execution

                        The available kwargs to cerebro are:
                          - preload (default: True)
                          - runonce (default: True)
                          - maxcpus (default: None)
                          - stdstats (default: True)
                          - live (default: False)
                          - exactbars (default: False)
                          - preload (default: True)
                          - writer (default False)
                          - oldbuysell (default False)
                          - tradehistory (default False)
  --nostdstats          Disable the standard statistics observers
  --format {yahoocsv_unreversed,vchart,vchartcsv,yahoo,mt4csv,ibdata,sierracsv,yahoocsv,btcsv,vcdata}, --csvformat {yahoocsv_unreversed,vchart,vchartcsv,yahoo,mt4csv,ibdata,sierracsv,yahoocsv,btcsv,vcdata}, -c {yahoocsv_unreversed,vchart,vchartcsv,yahoo,mt4csv,ibdata,sierracsv,yahoocsv,btcsv,vcdata}
                        CSV Format
  --fromdate FROMDATE, -f FROMDATE
                        Starting date in YYYY-MM-DD[THH:MM:SS] format
  --todate TODATE, -t TODATE
                        Ending date in YYYY-MM-DD[THH:MM:SS] format
  --timeframe {microseconds,seconds,weeks,months,minutes,days,years}, -tf {microseconds,seconds,weeks,months,minutes,days,years}
                        Ending date in YYYY-MM-DD[THH:MM:SS] format
  --compression COMPRESSION, -cp COMPRESSION
                        Ending date in YYYY-MM-DD[THH:MM:SS] format

Strategy options:
  --strategy module:name:kwargs, -st module:name:kwargs
                        This option can be specified multiple times.

                        The argument can be specified with the following form:

                          - module:classname:kwargs

                            Example: mymod:myclass:a=1,b=2

                        kwargs is optional

                        If module is omitted then class name will be sought in
                        the built-in strategies module. Such as in:

                          - :name:kwargs or :name

                        If name is omitted, then the 1st strategy found in the mod
                        will be used. Such as in:

                          - module or module::kwargs

Signals:
  --signal module:signaltype:name:kwargs, -sig module:signaltype:name:kwargs
                        This option can be specified multiple times.

                        The argument can be specified with the following form:

                          - signaltype:module:signaltype:classname:kwargs

                            Example: longshort+mymod:myclass:a=1,b=2

                        signaltype may be ommited: longshort will be used

                            Example: mymod:myclass:a=1,b=2

                        kwargs is optional

                        signaltype will be uppercased to match the defintions
                        fromt the backtrader.signal module

                        If module is omitted then class name will be sought in
                        the built-in signals module. Such as in:

                          - LONGSHORT::name:kwargs or :name

                        If name is omitted, then the 1st signal found in the mod
                        will be used. Such as in:

                          - module or module:::kwargs

Observers and statistics:
  --observer module:name:kwargs, -ob module:name:kwargs
                        This option can be specified multiple times.

                        The argument can be specified with the following form:

                          - module:classname:kwargs

                            Example: mymod:myclass:a=1,b=2

                        kwargs is optional

                        If module is omitted then class name will be sought in
                        the built-in observers module. Such as in:

                          - :name:kwargs or :name

                        If name is omitted, then the 1st observer found in the
                        will be used. Such as in:

                          - module or module::kwargs

Analyzers:
  --analyzer module:name:kwargs, -an module:name:kwargs
                        This option can be specified multiple times.

                        The argument can be specified with the following form:

                          - module:classname:kwargs

                            Example: mymod:myclass:a=1,b=2

                        kwargs is optional

                        If module is omitted then class name will be sought in
                        the built-in analyzers module. Such as in:

                          - :name:kwargs or :name

                        If name is omitted, then the 1st analyzer found in the
                        will be used. Such as in:

                          - module or module::kwargs

Indicators:
  --indicator module:name:kwargs, -ind module:name:kwargs
                        This option can be specified multiple times.

                        The argument can be specified with the following form:

                          - module:classname:kwargs

                            Example: mymod:myclass:a=1,b=2

                        kwargs is optional

                        If module is omitted then class name will be sought in
                        the built-in analyzers module. Such as in:

                          - :name:kwargs or :name

                        If name is omitted, then the 1st analyzer found in the
                        will be used. Such as in:

                          - module or module::kwargs

Writers:
  --writer [kwargs], -wr [kwargs]
                        This option can be specified multiple times.

                        The argument can be specified with the following form:

                          - kwargs

                            Example: a=1,b=2

                        kwargs is optional

                        It creates a system wide writer which outputs run data

                        Please see the documentation for the available kwargs

Cash and Commission Scheme Args:
  --cash CASH, -cash CASH
                        Cash to set to the broker
  --commission COMMISSION, -comm COMMISSION
                        Commission value to set
  --margin MARGIN, -marg MARGIN
                        Margin type to set
  --mult MULT, -mul MULT
                        Multiplier to use
  --interest INTEREST   Credit Interest rate to apply (0.0x)
  --interest_long       Apply credit interest to long positions
  --slip_perc SLIP_PERC
                        Enable slippage with a percentage value
  --slip_fixed SLIP_FIXED
                        Enable slippage with a fixed point value
  --slip_open           enable slippage for when matching opening prices
  --no-slip_match       Disable slip_match, ie: matching capped at
                        high-low if slippage goes over those limits
  --slip_out            with slip_match enabled, match outside high-low
  --flush               flush the output - useful under win32 systems

```
########################################
docu-broker.txt - lunghezza: 8965
########################################
Broker

Reference

class backtrader.brokers.BackBroker()

Broker Simulator

The simulation supports different order types, checking a submitted order
cash requirements against current cash, keeping track of cash and value
for each iteration of 
cerebro
 and keeping the current position on
different datas.

cash
 is adjusted on each iteration for instruments like 
futures
 for

```
which a price change implies in real brokers the addition/substracion of
cash.

```

Supported order types:

Market
: to be executed with the 1
st
 tick of the next bar (namely
    the 
open
 price)

Close
: meant for intraday in which the order is executed with the
    closing price of the last bar of the session

Limit
: executes if the given limit price is seen during the
    session

Stop
: executes a 
Market
 order if the given stop price is seen

StopLimit
: sets a 
Limit
 order in motion if the given stop
    price is seen

Because the broker is instantiated by 
Cerebro
 and there should be
(mostly) no reason to replace the broker, the params are not controlled
by the user for the instance.  To change this there are two options:

Manually create an instance of this class with the desired params
     and use 
cerebro.broker = instance
 to set the instance as the
     broker for the 
run
 execution

Use the 
set_xxx
 to set the value using

cerebro.broker.set_xxx
 where 
\
xxx` stands for the name of the
     parameter to set

Note

cerebro.broker
 is a 
property
 supported by the 
getbroker

and 
setbroker
 methods of 
Cerebro

Params:

cash
 (default: 
10000
): starting cash

commission
 (default: 
CommInfoBase(percabs=True)
)
    base commission scheme which applies to all assets

checksubmit
 (default: 
True
)
    check margin/cash before accepting an order into the system

eosbar
 (default: 
False
):
    With intraday bars consider a bar with the same 
time
 as the end
    of session to be the end of the session. This is not usually the
    case, because some bars (final auction) are produced by many
    exchanges for many products for a couple of minutes after the end of
    the session

eosbar
 (default: 
False
):
    With intraday bars consider a bar with the same 
time
 as the end
    of session to be the end of the session. This is not usually the
    case, because some bars (final auction) are produced by many
    exchanges for many products for a couple of minutes after the end of
    the session

filler
 (default: 
None
)

A callable with signature: 
callable(order, price, ago)

order
: obviously the order in execution. This provides access
    to the 
data
 (and with it the 
ohlc
 and 
volume
 values), the

execution type
, remaining size (
order.executed.remsize
) and
    others.

Please check the 
Order
 documentation and reference for things
available inside an 
Order
 instance

price
 the price at which the order is going to be executed in
    the 
ago
 bar

ago
: index meant to be used with 
order.data
 for the
    extraction of the 
ohlc
 and 
volume
 prices. In most cases this
    will be 
0
 but on a corner case for 
Close
 orders, this
    will be 
-1
.

In order to get the bar volume (for example) do: 
volume =
order.data.voluume[ago]

The callable must return the 
executed size
 (a value >= 0)

The callable may of course be an object with 
__call__
 matching
the aforementioned signature

With the default 
None
 orders will be completely executed in a
single shot

slip_perc
 (default: 
0.0
) Percentage in absolute termns (and
    positive) that should be used to slip prices up/down for buy/sell
    orders

Note:

0.01
 is 
1%

0.001
 is 
0.1%

slip_fixed
 (default: 
0.0
) Percentage in units (and positive)
    that should be used to slip prices up/down for buy/sell orders

Note: if 
slip_perc
 is non zero, it takes precendence over this.

slip_open
 (default: 
False
) whether to slip prices for order
    execution which would specifically used the 
opening
 price of the
    next bar. An example would be 
Market
 order which is executed with
    the next available tick, i.e: the opening price of the bar.

This also applies to some of the other executions, because the logic
tries to detect if the 
opening
 price would match the requested
price/execution type when moving to a new bar.

slip_match
 (default: 
True
)

If 
True
 the broker will offer a match by capping slippage at

high/low
 prices in case they would be exceeded.

If 
False
 the broker will not match the order with the current
prices and will try execution during the next iteration

slip_limit
 (default: 
True
)

Limit
 orders, given the exact match price requested, will be
matched even if 
slip_match
 is 
False
.

This option controls that behavior.

If 
True
, then 
Limit
 orders will be matched by capping prices
to the 
limit
 / 
high/low
 prices

If 
False
 and slippage exceeds the cap, then there will be no
match

slip_out
 (default: 
False
)

Provide 
slippage
 even if the price falls outside the 
high
 -

low
 range.

coc
 (default: 
False
)

Cheat-On-Close
 Setting this to 
True
 with 
set_coc
 enables

```
matching a `Market` order to the closing price of the bar in which
the order was issued. This is actually *cheating*, because the bar
is *closed* and any order should first be matched against the prices
in the next bar

```

coo
 (default: 
False
)

Cheat-On-Open
 Setting this to 
True
 with 
set_coo
 enables

```
matching a `Market` order to the opening price, by for example
using a timer with `cheat` set to `True`, because such a timer
gets executed before the broker has evaluated

```

int2pnl
 (default: 
True
)

Assign generated interest (if any) to the profit and loss of
operation that reduces a position (be it long or short). There may be
cases in which this is undesired, because different strategies are
competing and the interest would be assigned on a non-deterministic
basis to any of them.

shortcash
 (default: 
True
)

If True then cash will be increased when a stocklike asset is shorted
and the calculated value for the asset will be negative.

If 
False
 then the cash will be deducted as operation cost and the
calculated value will be positive to end up with the same amount

fundstartval
 (default: 
100.0
)

This parameter controls the start value for measuring the performance
in a fund-like way, i.e.: cash can be added and deducted increasing
the amount of shares. Performance is not measured using the net
asset value of the porftoflio but using the value of the fund

fundmode
 (default: 
False
)

If this is set to 
True
 analyzers like 
TimeReturn
 can
automatically calculate returns based on the fund value and not on
the total net asset value

set_cash(cash)

Sets the cash parameter (alias: 
setcash
)

get_cash()

Returns the current cash (alias: 
getcash
)

get_value(datas=None, mkt=False, lever=False)

Returns the portfolio value of the given datas (if datas is 
None
, then
the total portfolio value will be returned (alias: 
getvalue
)

set_eosbar(eosbar)

Sets the eosbar parameter (alias: 
seteosbar

set_checksubmit(checksubmit)

Sets the checksubmit parameter

set_filler(filler)

Sets a volume filler for volume filling execution

set_coc(coc)

Configure the Cheat-On-Close method to buy the close on order bar

set_coo(coo)

Configure the Cheat-On-Open method to buy the close on order bar

set_int2pnl(int2pnl)

Configure assignment of interest to profit and loss

set_fundstartval(fundstartval)

Set the starting value of the fund-like performance tracker

set_slippage_perc(perc, slip_open=True, slip_limit=True, slip_match=True, slip_out=False)

Configure slippage to be percentage based

set_slippage_fixed(fixed, slip_open=True, slip_limit=True, slip_match=True, slip_out=False)

Configure slippage to be fixed points based

get_orders_open(safe=False)

Returns an iterable with the orders which are still open (either not
executed or partially executed

The orders returned must not be touched.

If order manipulation is needed, set the parameter 
safe
 to True

getcommissioninfo(data)

Retrieves the 
CommissionInfo
 scheme associated with the given

data

setcommission(commission=0.0, margin=None, mult=1.0, commtype=None, percabs=True, stocklike=False, interest=0.0, interest_long=False, leverage=1.0, automargin=False, name=None)

This method sets a `` CommissionInfo`` object for assets managed in
the broker with the parameters. Consult the reference for

CommInfoBase

If name is 
None
, this will be the default for assets for which no
other 
CommissionInfo
 scheme can be found

addcommissioninfo(comminfo, name=None)

Adds a 
CommissionInfo
 object that will be the default for all assets if

name
 is 
None

getposition(data)

Returns the current position status (a 
Position
 instance) for
the given 
data

get_fundshares()

Returns the current number of shares in the fund-like mode

get_fundvalue()

Returns the Fund-like share value

add_cash(cash)

Add/Remove cash to the system (use a negative value to remove)
########################################
docu-cerebro.txt - lunghezza: 29068
########################################
Cerebro

This class is the cornerstone of 
backtrader
 because it serves as a central
point for:

Gathering all inputs (
Data Feeds
), actors (
Stratgegies
), spectators
     (
Observers
), critics (
Analyzers
) and documenters (
Writers
) ensuring the
     show still goes on at any moment.

Execute the backtesting/or live data feeding/trading

Returning the results

Giving access to the plotting facilities

Gathering input

Start by creating a 
cerebro
:

```
cerebro = bt.Cerebro(**kwargs)

```

Some 
**kwargs
 to control execution are supported, see the reference
 (the same arguments can be applied later to the 
run
 method)

Add 
Data feeds

The most usual pattern is 
cerebro.adddata(data)
, where 
data
 is a

data feed
 already instantiated. Example:

```
data = bt.BacktraderCSVData(dataname='mypath.days', timeframe=bt.TimeFrame.Days)
cerebro.adddata(data)

```

Resampling
 and 
Replaying
 a data is possible and follows the same pattern:

```
data = bt.BacktraderCSVData(dataname='mypath.min', timeframe=bt.TimeFrame.Minutes)
cerebro.resampledata(data, timeframe=bt.TimeFrame.Days)

```

or:

```
data = bt.BacktraderCSVData(dataname='mypath.min', timeframe=bt.TimeFrame.Minutes)
cerebro.replaydatadata(data, timeframe=bt.TimeFrame.Days)

```

The system can accept any number of data feeds, including mixing regular data
 with resampled and/or replayed data. Of course some of this combinationns
 will for sure make no sense and a restriction apply in order to be able to
 combine datas: 
time aligment
. See the
 Data - Multiple Timeframes,
 Data Resampling - Resampling` and
 Data - Replay sections.

Add 
Strategies

Unlike the 
datas feeds
 which are already an instance of a class,

cerebro
 takes directly the 
Strategy
 class and the arguments to
 pass to it. The rationale behind: 
in an optimization scenario the class
 will be instantiated several times and passed different arguments

Even if no 
optimization
 is run, the pattern still applies:

```
cerebro.addstrategy(MyStrategy, myparam1=value1, myparam2=value2)

```

When 
optimizing
 the parameters have to be added as iterables. See the

Optimization
 section for a detailed explanation. The basic pattern:

```
cerebro.optstrategy(MyStrategy, myparam1=range(10, 20))

```

Which will run 
MyStrategy
 10 times with 
myparam1
 taking values
 from 10 to 19 (remember ranges in Python are half-open and 
20
 will not
 be reached)

Other elements

There are some other elements which can be added to enhance the
 backtesting experience. See the appropriate sections for it. The methods
 are:

addwriter

addanalyzer

addobserver
 (or 
addobservermulti
)

Changing the broker

Cerebro will use the default broker in 
backtrader
, but this can be
 overriden:

```
broker = MyBroker()
cerebro.broker = broker  # property using getbroker/setbroker methods

```

Receive notifications

If 
data feeds
 and/or 
brokers
 send notifications (or a 
store
 provider
 which creates them) they will be received through the

Cerebro.notify_store
 method. There are three (3) ways to work with
 these notifications

Add a 
callback
 to a 
cerebro
 instance via the

addnotifycallback(callback)
 call. The callback has to support this
   signature:

```
callback(msg, *args, **kwargs)

```

The actual 
msg
, 
*args
 and 
**kwargs
 received are
   implementation defined (depend entirely on the 
data/broker/store
) but
   in general one should expect them to be 
printable
 to allow for
   reception and experimentation.

Override the 
notify_store
 method in the 
Strategy
 subclass which
   is added to a 
cerebro
 instance.

The signature: 
notify_store(self, msg, *args, **kwargs)

Subclass 
Cerebro
 and override 
notify_store
 (same signature as in
   the 
Strategy
)

This should be the least preferred method

Execute the backtesting

There is a single method to do it, but it supports several options (which can
be also specified when instantiating) to decide how to run:

```
result = cerebro.run(**kwargs)

```

See the reerence below to understand which arguments are available.

Standard Observers

cerebro
 (unless otherwise specified) automatically instantiates 
three

standard observers

A 
Broker
 observer which keeps track of 
cash
 and 
value
 (portfolio)

A 
Trades
 observer which should show how effective each trade has been

A 
Buy/Sell
 observer which should document when operations are executed

Should a cleaner plotting be wished just disable them with 
stdstats=False

Returning the results

cerebro
 returns the instances of the strategies it created during
backtesting. This allows to analyze what they did, because all elements in the
strategies are accessible:

```
result = cerebro.run(**kwargs)

```

The format of 
result
 returned by 
run
 will vary depending on whether 
optimization

is used (a 
strategy
 was added with 
optstrategy
):

All strategies added with 
addstrategy

result
 will be a 
list
 of the instances run during the backtesting

1 or more strategies were added with 
optstrategy

result
 will be a 
list
 of 
list
. Each internal list will contain
the strategies after each optimization run

Note

The default behavior for 
optimization
 was changed to only return
the 
analyzers
 present in the system, to make message passing across
computer cores lighter.

If the complete set of strategies is wished as return value, set the
parameter 
optreturn
 to 
False

Giving access to the plotting facilities

As an extra an if 
matplotlib
 is installed, the strategies can be
plotted. With the usual pattern being:

```
cerebro.plot()

```

See below for the reference and the section Plotting

Backtesting logic

Brief outline of the flow of things:

Deliver any store notifications

Ask data feeds to deliver the next set of ticks/bars

Versionchanged:
 Changed in version 1.9.0.99: 
New Behavior

Data Feeds are synchronized by peeking at the 
datetime
 which is going
 to be provided next by available data feeds. Feeds which have not
 traded in the new period still provide the old data points, whilst data
 feeds which have new data available offer this one (along with the
 calculation of indicators)

Old Behavior
 (retained when using 
oldsync=True
 with 
Cerebro
)

The 1
st
 data inserted into the system is the 
datamaster
 and the
 system will wait for it to deliver a tick

The other data feeds are, more or less, slaves to the 
datamaster

 and:

```
 * If the next tick to deliver is newer (datetime-wise) than the one
   delivered by the `datamaster` it will not be delivered

 * May return without delivering a new tick for a number of reasons

```

The logic was designed to easily synchronize multiple data feeds and
   data feeds with different timeframes

Notify the strategy about queued broker notifications of orders, trades
     and cash/value

Tell the broker to accept queued orders and execute the pending orders
     with the new data

Call the strategies’ 
next
 method to let the strategy evaluate the new
     data (and maybe issue orders which are queued in the broker)

Depending on the stage it may be 
prenext
 or 
nextstart
 before the
 minimum period requirements of the strategy/indicators are met

Internally the strategies will also kick the 
observers
,

indicators
, 
analyzers
  and other active elements

Tell any 
writers
 to write the data to its target

Important to take into account:

Note

In step 
1
 above when the 
data feeds
 deliver the new set of bars,
those bars are 
closed
. This means the data has already happened.

As such, 
orders
 issued by the strategy in step 
4
 cannot be

executed
 with the data from step 
1
.

This means that orders will be executed with the concept of 
x +
1
. Where 
x
 is the bar moment at which the order was executed
and 
x + 1
 the next one, which is the earliest moment in time for
a possible order execution

Reference

class backtrader.Cerebro()

Params:

preload
 (default: 
True
)

Whether to preload the different 
data feeds
 passed to cerebro for
  the Strategies

runonce
 (default: 
True
)

Run 
Indicators
 in vectorized mode to speed up the entire system.
  Strategies and Observers will always be run on an event based basis

live
 (default: 
False
)

If no data has reported itself as 
live
 (via the data’s 
islive

  method but the end user still want to run in 
live
 mode, this
  parameter can be set to true

This will simultaneously deactivate 
preload
 and 
runonce
. It
  will have no effect on memory saving schemes.

Run 
Indicators
 in vectorized mode to speed up the entire system.
  Strategies and Observers will always be run on an event based basis

maxcpus
 (default: None -> all available cores)

How many cores to use simultaneously for optimization

stdstats
 (default: 
True
)

If True default Observers will be added: Broker (Cash and Value),
  Trades and BuySell

oldbuysell
 (default: 
False
)

If 
stdstats
 is 
True
 and observers are getting automatically
  added, this switch controls the main behavior of the 
BuySell

  observer

False
: use the modern behavior in which the buy / sell signals
    are plotted below / above the low / high prices respectively to avoid
    cluttering the plot

True
: use the deprecated behavior in which the buy / sell signals
    are plotted where the average price of the order executions for the
    given moment in time is. This will of course be on top of an OHLC bar
    or on a Line on Cloe bar, difficulting the recognition of the plot.

oldtrades
 (default: 
False
)

If 
stdstats
 is 
True
 and observers are getting automatically
  added, this switch controls the main behavior of the 
Trades

  observer

False
: use the modern behavior in which trades for all datas are
    plotted with different markers

True
: use the old Trades observer which plots the trades with the
    same markers, differentiating only if they are positive or negative

exactbars
 (default: 
False
)

With the default value each and every value stored in a line is kept in
  memory

Possible values:

```
* `True` or `1`: all “lines” objects reduce memory usage to the
  automatically calculated minimum period.

  If a Simple Moving Average has a period of 30, the underlying data
  will have always a running buffer of 30 bars to allow the
  calculation of the Simple Moving Average

  * This setting will deactivate `preload` and `runonce`

  * Using this setting also deactivates **plotting**

* `-1`: datafreeds and indicators/operations at strategy level will
  keep all data in memory.

  For example: a `RSI` internally uses the indicator `UpDay` to
  make calculations. This subindicator will not keep all data in
  memory

  * This allows to keep `plotting` and `preloading` active.

  * `runonce` will be deactivated

* `-2`: data feeds and indicators kept as attributes of the
  strategy will keep all points in memory.

  For example: a `RSI` internally uses the indicator `UpDay` to
  make calculations. This subindicator will not keep all data in
  memory

  If in the `__init__` something like
  `a = self.data.close - self.data.high` is defined, then `a`
  will not keep all data in memory

  * This allows to keep `plotting` and `preloading` active.

  * `runonce` will be deactivated

```

objcache
 (default: 
False
)

Experimental option to implement a cache of lines objects and reduce
  the amount of them. Example from UltimateOscillator:

```
bp = self.data.close - TrueLow(self.data)
tr = TrueRange(self.data)  # -> creates another TrueLow(self.data)

```

If this is 
True
 the 2
nd

TrueLow(self.data)
 inside 
TrueRange

  matches the signature of the one in the 
bp
 calculation. It will be
  reused.

Corner cases may happen in which this drives a line object off its
  minimum period and breaks things and it is therefore disabled.

writer
 (default: 
False
)

If set to 
True
 a default WriterFile will be created which will
  print to stdout. It will be added to the strategy (in addition to any
  other writers added by the user code)

tradehistory
 (default: 
False
)

If set to 
True
, it will activate update event logging in each trade
  for all strategies. This can also be accomplished on a per strategy
  basis with the strategy method 
set_tradehistory

optdatas
 (default: 
True
)

If 
True
 and optimizing (and the system can 
preload
 and use

runonce
, data preloading will be done only once in the main process
  to save time and resources.

The tests show an approximate 
20%
 speed-up moving from a sample
  execution in 
83
 seconds to 
66

optreturn
 (default: 
True
)

If 
True
 the optimization results will not be full 
Strategy

  objects (and all 
datas
, 
indicators
, 
observers
 …) but and object
  with the following attributes (same as in 
Strategy
):

```
* `params` (or `p`) the strategy had for the execution

* `analyzers` the strategy has executed

```

In most occassions, only the 
analyzers
 and with which 
params
 are
  the things needed to evaluate a the performance of a strategy. If
  detailed analysis of the generated values for (for example)

indicators
 is needed, turn this off

The tests show a 
13% - 15%
 improvement in execution time. Combined
  with 
optdatas
 the total gain increases to a total speed-up of

32%
 in an optimization run.

oldsync
 (default: 
False
)

Starting with release 1.9.0.99 the synchronization of multiple datas
  (same or different timeframes) has been changed to allow datas of
  different lengths.

If the old behavior with data0 as the master of the system is wished,
  set this parameter to true

tz
 (default: 
None
)

Adds a global timezone for strategies. The argument 
tz
 can be

```
* `None`: in this case the datetime displayed by strategies will be
  in UTC, which has been always the standard behavior

* `pytz` instance. It will be used as such to convert UTC times to
  the chosen timezone

* `string`. Instantiating a `pytz` instance will be attempted.

* `integer`. Use, for the strategy, the same timezone as the
  corresponding `data` in the `self.datas` iterable (`0` would
  use the timezone from `data0`)

```

cheat_on_open
 (default: 
False
)

The 
next_open
 method of strategies will be called. This happens
  before 
next
 and before the broker has had a chance to evaluate
  orders. The indicators have not yet been recalculated. This allows
  issuing an orde which takes into account the indicators of the previous
  day but uses the 
open
 price for stake calculations

For cheat_on_open order execution, it is also necessary to make the
  call 
cerebro.broker.set_coo(True)
 or instantite a broker with

BackBroker(coo=True)
 (where 
coo
 stands for cheat-on-open) or set
  the 
broker_coo
 parameter to 
True
. Cerebro will do it
  automatically unless disabled below.

broker_coo
 (default: 
True
)

This will automatically invoke the 
set_coo
 method of the broker
  with 
True
 to activate 
cheat_on_open
 execution. Will only do it
  if 
cheat_on_open
 is also 
True

quicknotify
 (default: 
False
)

Broker notifications are delivered right before the delivery of the

next
 prices. For backtesting this has no implications, but with live
  brokers a notification can take place long before the bar is
  delivered. When set to 
True
 notifications will be delivered as soon
  as possible (see 
qcheck
 in live feeds)

Set to 
False
 for compatibility. May be changed to 
True

addstorecb(callback)

Adds a callback to get messages which would be handled by the
notify_store method

The signature of the callback must support the following:

callback(msg, *args, **kwargs)

The actual 
msg
, 
*args
 and 
**kwargs
 received are
implementation defined (depend entirely on the 
data/broker/store
) but
in general one should expect them to be 
printable
 to allow for
reception and experimentation.

notify_store(msg, *args, **kwargs)

Receive store notifications in cerebro

This method can be overridden in 
Cerebro
 subclasses

The actual 
msg
, 
*args
 and 
**kwargs
 received are
implementation defined (depend entirely on the 
data/broker/store
) but
in general one should expect them to be 
printable
 to allow for
reception and experimentation.

adddatacb(callback)

Adds a callback to get messages which would be handled by the
notify_data method

The signature of the callback must support the following:

callback(data, status, *args, **kwargs)

The actual 
*args
 and 
**kwargs
 received are implementation
defined (depend entirely on the 
data/broker/store
) but in general one
should expect them to be 
printable
 to allow for reception and
experimentation.

notify_data(data, status, *args, **kwargs)

Receive data notifications in cerebro

This method can be overridden in 
Cerebro
 subclasses

The actual 
*args
 and 
**kwargs
 received are
implementation defined (depend entirely on the 
data/broker/store
) but
in general one should expect them to be 
printable
 to allow for
reception and experimentation.

adddata(data, name=None)

Adds a 
Data Feed
 instance to the mix.

If 
name
 is not None it will be put into 
data._name
 which is
meant for decoration/plotting purposes.

resampledata(dataname, name=None, **kwargs)

Adds a 
Data Feed
 to be resample by the system

If 
name
 is not None it will be put into 
data._name
 which is
meant for decoration/plotting purposes.

Any other kwargs like 
timeframe
, 
compression
, 
todate
 which
are supported by the resample filter will be passed transparently

replaydata(dataname, name=None, **kwargs)

Adds a 
Data Feed
 to be replayed by the system

If 
name
 is not None it will be put into 
data._name
 which is
meant for decoration/plotting purposes.

Any other kwargs like 
timeframe
, 
compression
, 
todate
 which
are supported by the replay filter will be passed transparently

chaindata(*args, **kwargs)

Chains several data feeds into one

If 
name
 is passed as named argument and is not None it will be put
into 
data._name
 which is meant for decoration/plotting purposes.

If 
None
, then the name of the 1
st
 data will be used

rolloverdata(*args, **kwargs)

Chains several data feeds into one

If 
name
 is passed as named argument and is not None it will be put
into 
data._name
 which is meant for decoration/plotting purposes.

If 
None
, then the name of the 1
st
 data will be used

Any other kwargs will be passed to the RollOver class

addstrategy(strategy, *args, **kwargs)

Adds a 
Strategy
 class to the mix for a single pass run.
Instantiation will happen during 
run
 time.

args and kwargs will be passed to the strategy as they are during
instantiation.

Returns the index with which addition of other objects (like sizers)
can be referenced

optstrategy(strategy, *args, **kwargs)

Adds a 
Strategy
 class to the mix for optimization. Instantiation
will happen during 
run
 time.

args and kwargs MUST BE iterables which hold the values to check.

Example: if a Strategy accepts a parameter 
period
, for optimization
purposes the call to 
optstrategy
 looks like:

cerebro.optstrategy(MyStrategy, period=(15, 25))

This will execute an optimization for values 15 and 25. Whereas

cerebro.optstrategy(MyStrategy, period=range(15, 25))

will execute MyStrategy with 
period
 values 15 -> 25 (25 not
included, because ranges are semi-open in Python)

If a parameter is passed but shall not be optimized the call looks
like:

cerebro.optstrategy(MyStrategy, period=(15,))

Notice that 
period
 is still passed as an iterable … of just 1
element

backtrader
 will anyhow try to identify situations like:

cerebro.optstrategy(MyStrategy, period=15)

and will create an internal pseudo-iterable if possible

optcallback(cb)

Adds a 
callback
 to the list of callbacks that will be called with the
optimizations when each of the strategies has been run

The signature: cb(strategy)

addindicator(indcls, *args, **kwargs)

Adds an 
Indicator
 class to the mix. Instantiation will be done at

run
 time in the passed strategies

addobserver(obscls, *args, **kwargs)

Adds an 
Observer
 class to the mix. Instantiation will be done at

run
 time

addobservermulti(obscls, *args, **kwargs)

Adds an 
Observer
 class to the mix. Instantiation will be done at

run
 time

It will be added once per “data” in the system. A use case is a
buy/sell observer which observes individual datas.

A counter-example is the CashValue, which observes system-wide values

addanalyzer(ancls, *args, **kwargs)

Adds an 
Analyzer
 class to the mix. Instantiation will be done at

run
 time

addwriter(wrtcls, *args, **kwargs)

Adds an 
Writer
 class to the mix. Instantiation will be done at

run
 time in cerebro

run(**kwargs)

The core method to perform backtesting. Any 
kwargs
 passed to it
will affect the value of the standard parameters 
Cerebro
 was
instantiated with.

If 
cerebro
 has not datas the method will immediately bail out.

It has different return values:

For No Optimization: a list contanining instances of the Strategy
    classes added with 
addstrategy

For Optimization: a list of lists which contain instances of the
    Strategy classes added with 
addstrategy

runstop()

If invoked from inside a strategy or anywhere else, including other
threads the execution will stop as soon as possible.

setbroker(broker)

Sets a specific 
broker
 instance for this strategy, replacing the
one inherited from cerebro.

getbroker()

Returns the broker instance.

This is also available as a 
property
 by the name 
broker

plot(plotter=None, numfigs=1, iplot=True, start=None, end=None, width=16, height=9, dpi=300, tight=True, use=None, **kwargs)

Plots the strategies inside cerebro

If 
plotter
 is None a default 
Plot
 instance is created and

kwargs
 are passed to it during instantiation.

numfigs
 split the plot in the indicated number of charts reducing
chart density if wished

iplot
: if 
True
 and running in a 
notebook
 the charts will be
displayed inline

use
: set it to the name of the desired matplotlib backend. It will
take precedence over 
iplot

start
: An index to the datetime line array of the strategy or a

datetime.date
, 
datetime.datetime
 instance indicating the start
of the plot

end
: An index to the datetime line array of the strategy or a

datetime.date
, 
datetime.datetime
 instance indicating the end
of the plot

width
: in inches of the saved figure

height
: in inches of the saved figure

dpi
: quality in dots per inches of the saved figure

tight
: only save actual content and not the frame of the figure

addsizer(sizercls, *args, **kwargs)

Adds a 
Sizer
 class (and args) which is the default sizer for any
strategy added to cerebro

addsizer_byidx(idx, sizercls, *args, **kwargs)

Adds a 
Sizer
 class by idx. This idx is a reference compatible to
the one returned by 
addstrategy
. Only the strategy referenced by

idx
 will receive this size

add_signal(sigtype, sigcls, *sigargs, **sigkwargs)

Adds a signal to the system which will be later added to a

SignalStrategy

signal_concurrent(onoff)

If signals are added to the system and the 
concurrent
 value is
set to True, concurrent orders will be allowed

signal_accumulate(onoff)

If signals are added to the system and the 
accumulate
 value is
set to True, entering the market when already in the market, will be
allowed to increase a position

signal_strategy(stratcls, *args, **kwargs)

Adds a SignalStrategy subclass which can accept signals

addcalendar(cal)

Adds a global trading calendar to the system. Individual data feeds
may have separate calendars which override the global one

cal
 can be an instance of 
TradingCalendar
 a string or an
instance of 
pandas_market_calendars
. A string will be will be
instantiated as a 
PandasMarketCalendar
 (which needs the module

pandas_market_calendar
 installed in the system.

If a subclass of TradingCalendarBase is passed (not an instance) it
will be instantiated

addtz(tz)

This can also be done with the parameter 
tz

Adds a global timezone for strategies. The argument 
tz
 can be

None
: in this case the datetime displayed by strategies will be
    in UTC, which has been always the standard behavior

pytz
 instance. It will be used as such to convert UTC times to
    the chosen timezone

string
. Instantiating a 
pytz
 instance will be attempted.

integer
. Use, for the strategy, the same timezone as the
    corresponding 
data
 in the 
self.datas
 iterable (
0
 would
    use the timezone from 
data0
)

add_timer(when, offset=datetime.timedelta(0), repeat=datetime.timedelta(0), weekdays=[], weekcarry=False, monthdays=[], monthcarry=True, allow=None, tzdata=None, strats=False, cheat=False, *args, **kwargs)

Schedules a timer to invoke 
notify_timer

Parameters

when
 (
-
) – can be

datetime.time
 instance (see below 
tzdata
)

bt.timer.SESSION_START
 to reference a session start

bt.timer.SESSION_END
 to reference a session end

offset
 which must be a 
datetime.timedelta
 instance

Used to offset the value 
when
. It has a meaningful use in
  combination with 
SESSION_START
 and 
SESSION_END
, to indicated
  things like a timer being called 
15 minutes
 after the session
  start.

repeat
 which must be a 
datetime.timedelta
 instance

Indicates if after a 1
st
 call, further calls will be scheduled
within the same session at the scheduled 
repeat
 delta

Once the timer goes over the end of the session it is reset to the
original value for 
when

weekdays
: a 
sorted
 iterable with integers indicating on
    which days (iso codes, Monday is 1, Sunday is 7) the timers can
    be actually invoked

If not specified, the timer will be active on all days

weekcarry
 (default: 
False
). If 
True
 and the weekday was
    not seen (ex: trading holiday), the timer will be executed on the
    next day (even if in a new week)

monthdays
: a 
sorted
 iterable with integers indicating on
    which days of the month a timer has to be executed. For example
    always on day 
15
 of the month

If not specified, the timer will be active on all days

monthcarry
 (default: 
True
). If the day was not seen
    (weekend, trading holiday), the timer will be executed on the next
    available day.

allow
 (default: 
None
). A callback which receives a
    datetime.date` instance and returns 
True
 if the date is
    allowed for timers or else returns 
False

tzdata
 which can be either 
None
 (default), a 
pytz

    instance or a 
data feed
 instance.

None
: 
when
 is interpreted at face value (which translates
to handling it as if it where UTC even if it’s not)

pytz
 instance: 
when
 will be interpreted as being specified
in the local time specified by the timezone instance.

data feed
 instance: 
when
 will be interpreted as being
specified in the local time specified by the 
tz
 parameter of
the data feed instance.

Note

If 
when
 is either 
SESSION_START
 or 
SESSION_END
 and 
tzdata

is 
None
, the 1
st

data feed
 in the system (aka 
self.data0
)
will be used as the reference to find out the session times.

strats
 (default: 
False
) call also the 
notify_timer
 of
    strategies

cheat
 (default 
False
) if 
True
 the timer will be called
    before the broker has a chance to evaluate the orders. This opens
    the chance to issue orders based on opening price for example right
    before the session starts

*args
: any extra args will be passed to 
notify_timer

**kwargs
: any extra kwargs will be passed to 
notify_timer

Return Value:

The created timer

notify_timer(timer, when, *args, **kwargs)

Receives a timer notification where 
timer
 is the timer which was
returned by 
add_timer
, and 
when
 is the calling time. 
args

and 
kwargs
 are any additional arguments passed to 
add_timer

The actual 
when
 time can be later, but the system may have not be
able to call the timer before. This value is the timer value and no the
system time.

add_order_history(orders, notify=True)

Add a history of orders to be directly executed in the broker for
performance evaluation

orders
: is an iterable (ex: list, tuple, iterator, generator)
    in which each element will be also an iterable (with length) with
    the following sub-elements (2 formats are possible)

[datetime, size, price]
 or 
[datetime, size, price, data]

Note

it must be sorted (or produce sorted elements) by datetime ascending

where:

datetime
 is a python 
date/datetime
 instance or a string
    with format YYYY-MM-DD[THH:MM:SS[.us]] where the elements in
    brackets are optional

size
 is an integer (positive to 
buy
, negative to 
sell
)

price
 is a float/integer

data
 if present can take any of the following values

None
 - The 1
st
 data feed will be used as target

integer
 - The data with that index (insertion order in

Cerebro
) will be used

string
 - a data with that name, assigned for example with

cerebro.addata(data, name=value)
, will be the target

notify
 (default: 
True
)

If 
True
 the 1
st
 strategy inserted in the system will be
notified of the artificial orders created following the information
from each order in 
orders

Note

Implicit in the description is the need to add a data feed
which is the target of the orders. This is for example needed by
analyzers which track for example the returns
########################################
docu-commission-credit.txt - lunghezza: 3228
########################################
Commissions: Credit

In some situations, the cash amount in real brokers may be decreased because
the operation on assets includes an interest rate. Examples:

Short selling of stocks

ETFs both long and short

The charge goes directly against the cash balance in the broker account. But it
can still be seen as part of a commission scheme. And as such it has been
modeled in 
backtrader
.

The 
CommInfoBase
 class (and with it also the 
CommissionInfo
 main
interface object) has been extended with:

Two (2) new parameters that allow setting the interest rate and
    determining if should be applied only to the short side or to both long and
    short

Parameters

interest
 (def: 
0.0
)

If this is non-zero, this is the yearly interest charged for holding a
short selling position. This is mostly meant for stock short-selling

The default formula applied: 
days * price * size * (interest / 365)

It must be specified in absolute terms: 0.05 -> 5%

Note

the behavior can be changed by overriding the method:

get_credit_interest

interest_long
 (def: 
False
)

Some products like ETFs get charged on interest for short and long
positions. If ths is 
True
 and 
interest
 is non-zero the interest
will be charged on both directions

The formula

The default implementation will use the following formula:

```
days * abs(size) * price * (interest / 365)

```

Where:

days
: number of days elapsed since position was opened or the last
    credit interest calculation took place

Overriding the formula

In order to change the formula subclassing of 
CommissionInfo
 is needed. The
method to be overridden is:

```
def _get_credit_interest(self, size, price, days, dt0, dt1):
    '''
    This method returns  the cost in terms of credit interest charged by
    the broker.

    In the case of ``size > 0`` this method will only be called if the
    parameter to the class ``interest_long`` is ``True``

    The formulat for the calculation of the credit interest rate is:

      The formula: ``days * price * abs(size) * (interest / 365)``

    Params:
      - ``data``: data feed for which interest is charged

      - ``size``: current position size. > 0 for long positions and < 0 for
        short positions (this parameter will not be ``0``)

      - ``price``: current position price

      - ``days``: number of days elapsed since last credit calculation
        (this is (dt0 - dt1).days)

      - ``dt0``: (datetime.datetime) current datetime

      - ``dt1``: (datetime.datetime) datetime of previous calculation

    ``dt0`` and ``dt1`` are not used in the default implementation and are
    provided as extra input for overridden methods
    '''

```

It might be that the 
broker
 doesn’t consider weekends or bank holidays when
calculating the interest rate. In this case this subclass would do the trick

```
import backtrader as bt

class MyCommissionInfo(bt.CommInfo):

   def _get_credit_interest(self, size, price, days, dt0, dt1):
       return 1.0 * abs(size) * price * (self.p.interest / 365.0)

```

In this case, in the formula:

days
 has been replaced by 
1.0

Because if weekends/bank holidays do not count, the next calculation will
always happen 
1
 trading da after the previous calculation
########################################
docu-commission-schemes-commission-schemes.txt - lunghezza: 16048
########################################
Commissions: Stocks vs Futures

Agnosticity

Before going forward let’s remember that 
backtrader
 tries to remain agnostic
as to what the data represents. Different commission schemes can be applied to
the same data set.

Let’s see how it can be done.

Using the broker shortcuts

This keeps the end user away from 
CommissionInfo
 objects because a
commission scheme can be 
created/set
 with a single function call. Within the
regular 
cerebro
 creation/set-up process, just add a call to

setcommission
 over the 
broker
 member attribute. The following call sets
a usual commission scheme for 
Eurostoxx50
 futures when working with

Interactive Brokers
:

```
cerebro.broker.setcommission(commission=2.0, margin=2000.0, mult=10.0)

```

Since most users will usually just test a single instrument, that’s all that’s
down to it. If you have given a 
name
 to your data feed, because several
instruments are being considered simultaneously on a chart, this call can be
slightly extended to look as follows:

```
cerebro.broker.setcommission(commission=2.0, margin=2000.0, mult=10.0, name='Eurostoxxx50')

```

In this case this on-the-fly commission scheme will only applied to instruments
whose name matches 
Eurostoxx50
.

The meaning of the setcommission parameters

commission
 (default: 
0.0
)

Monetary units in absolute or percentage terms each 
action
 costs.

In the above example it is 2.0 euros per contract for a 
buy
 and again
2.0 euros per contract for a 
sell
.

The important issue here is when to use absolute or percentage values.

If 
margin
 evaluates to 
False
 (it is False, 0 or None for
    example) then it will be considered that 
commission
 expresses a
    percentage of the 
price
 times 
size
 operatin value

If 
margin
 is something else, it is considered the operations are
    happenning on a 
futures
 like intstrument and 
commission
 is a
    fixed price per 
size
 contracts

margin
 (default: 
None
)

Margin money needed when operating with 
futures
 like instruments. As
expressed above

If a 
no

margin
 is set, the 
commission
 will be understood to
    be indicated in percentage and applied to 
price * size
 components of
    a 
buy
 or 
sell
 operation

If a 
margin
 is set, the 
commission
 will be understood to be a
    fixed value which is multiplied by the 
size
 component of 
buy
 or

sell
 operation

mult
 (default: 1.0)

For 
future
 like instruments this determines the multiplicator to apply
to profit and loss calculations.

This is what makes futures attractive and risky at the same time.

name
 (default: None)

Limit the application of the commission scheme to instruments matching

name

This can be set during the creation of a data feed.

If left unset, the scheme will apply to any data present in the system.

Two examples now: stocks vs futures

The futures example from above:

```
cerebro.broker.setcommission(commission=2.0, margin=2000.0, mult=10.0)

```

A example for stocks:

```
cerebro.broker.setcommission(commission=0.005)  # 0.5% of the operation value

```

Note

The 2
nd
 syntax doesn’t set 
margin
 and 
mult
 and 
backtrader
 attempts a
smart approach by considering the commission to be 
%
 based.

To fully specify commission schemes, a subclass of 
CommissionInfo
 needs
to be created

Creating permanent Commission schemes

A more permanent commission scheme can be created by working directly with

CommissionInfo
 classes. The user could choose to have this definition
somewhere:

```
import backtrader as bt

commEurostoxx50 = bt.CommissionInfo(commission=2.0, margin=2000.0, mult=10.0)

```

To later apply it in another Python module with 
addcommissioninfo
:

```
from mycomm import commEurostoxx50

...

cerebro.broker.addcommissioninfo(commEuroStoxx50, name='Eurostoxxx50')

```

CommissionInfo
 is an object which uses a 
params
 declaration just like
other objects in the 
backtrader
 environment. As such the above can be also
expressed as:

```
import backtrader as bt

class CommEurostoxx50(bt.CommissionInfo):
    params = dict(commission=2.0, margin=2000.0, mult=10.0)

```

And later:

```
from mycomm import CommEurostoxx50

...

cerebro.broker.addcommissioninfoCommEuroStoxx50(), name='Eurostoxxx50')

```

Now a “real” comparison with a SMA Crossover

Using a SimpleMovingAverage crossover as the entry/exit signal the same data set
is going to be tested with a 
futures
 like commission scheme and then with a

stocks
 like one.

Note

Futures positions could also not only be given the enter/exit behavior but a
reversal behavior on each occassion. But this example is about comparing the
commission schemes.

The code (see at the bottom for the full strategy) is the same and the
scheme can be chosen before the strategy is defined.

```
futures_like = True

if futures_like:
    commission, margin, mult = 2.0, 2000.0, 10.0
else:
    commission, margin, mult = 0.005, None, 1

```

Just set 
futures_like
 to false to run with the 
stocks
 like scheme.

Some logging code has been added to evaluate the impact of the differrent
commission schemes. Let’s concentrate on just the 2 first operations.

For futures:

```
2006-03-09, BUY CREATE, 3757.59
2006-03-10, BUY EXECUTED, Price: 3754.13, Cost: 2000.00, Comm 2.00
2006-04-11, SELL CREATE, 3788.81
2006-04-12, SELL EXECUTED, Price: 3786.93, Cost: 2000.00, Comm 2.00
2006-04-12, OPERATION PROFIT, GROSS 328.00, NET 324.00
2006-04-20, BUY CREATE, 3860.00
2006-04-21, BUY EXECUTED, Price: 3863.57, Cost: 2000.00, Comm 2.00
2006-04-28, SELL CREATE, 3839.90
2006-05-02, SELL EXECUTED, Price: 3839.24, Cost: 2000.00, Comm 2.00
2006-05-02, OPERATION PROFIT, GROSS -243.30, NET -247.30

```

For stocks:

```
2006-03-09, BUY CREATE, 3757.59
2006-03-10, BUY EXECUTED, Price: 3754.13, Cost: 3754.13, Comm 18.77
2006-04-11, SELL CREATE, 3788.81
2006-04-12, SELL EXECUTED, Price: 3786.93, Cost: 3786.93, Comm 18.93
2006-04-12, OPERATION PROFIT, GROSS 32.80, NET -4.91
2006-04-20, BUY CREATE, 3860.00
2006-04-21, BUY EXECUTED, Price: 3863.57, Cost: 3863.57, Comm 19.32
2006-04-28, SELL CREATE, 3839.90
2006-05-02, SELL EXECUTED, Price: 3839.24, Cost: 3839.24, Comm 19.20
2006-05-02, OPERATION PROFIT, GROSS -24.33, NET -62.84

```

The 1
st
 operation has the following prices:

BUY (Execution) -> 3754.13 / SELL (Execution) -> 3786.93

Futures Profit & Loss (with commission): 324.0

Stocks Profit & Loss (with commission): -4.91

Hey!! Commission has fully eaten up any profit on the 
stocks
 operation
  but has only meant a small dent to the 
futures
 one.

The 2
nd
 operation:

BUY (Execution) -> 
3863.57
 / SELL (Execution) -> 
3389.24

Futures Profit & Loss (with commission): 
-247.30

Stocks Profit & Loss (with commission): 
-62.84

The bite has been sensibly larger for this negative operation with 
futures

But:

Futures accumulated net profit & loss: 
324.00 + (-247.30) = 76.70

Stocks accumulated net profit & loss: 
(-4.91) + (-62.84) = -67.75

The accumulated effect can be seen on the charts below, where it can also be
seen that at the end of the full year, futures have produced a larger profit,
but have also suffered a larger drawdown (were deeper underwater)

But the important thing: whether 
futures
 or 
stocks
 … 
it can be
backtested.

Commissions for futures

Commissions for stocks

The code

```
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import backtrader as bt
import backtrader.feeds as btfeeds
import backtrader.indicators as btind

futures_like = True

if futures_like:
    commission, margin, mult = 2.0, 2000.0, 10.0
else:
    commission, margin, mult = 0.005, None, 1

class SMACrossOver(bt.Strategy):
    def log(self, txt, dt=None):
        ''' Logging function fot this strategy'''
        dt = dt or self.datas[0].datetime.date(0)
        print('%s, %s' % (dt.isoformat(), txt))

    def notify(self, order):
        if order.status in [order.Submitted, order.Accepted]:
            # Buy/Sell order submitted/accepted to/by broker - Nothing to do
            return

        # Check if an order has been completed
        # Attention: broker could reject order if not enougth cash
        if order.status in [order.Completed, order.Canceled, order.Margin]:
            if order.isbuy():
                self.log(
                    'BUY EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %
                    (order.executed.price,
                     order.executed.value,
                     order.executed.comm))

                self.buyprice = order.executed.price
                self.buycomm = order.executed.comm
                self.opsize = order.executed.size
            else:  # Sell
                self.log('SELL EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %
                         (order.executed.price,
                          order.executed.value,
                          order.executed.comm))

                gross_pnl = (order.executed.price - self.buyprice) * \
                    self.opsize

                if margin:
                    gross_pnl *= mult

                net_pnl = gross_pnl - self.buycomm - order.executed.comm
                self.log('OPERATION PROFIT, GROSS %.2f, NET %.2f' %
                         (gross_pnl, net_pnl))

    def __init__(self):
        sma = btind.SMA(self.data)
        # > 0 crossing up / < 0 crossing down
        self.buysell_sig = btind.CrossOver(self.data, sma)

    def next(self):
        if self.buysell_sig > 0:
            self.log('BUY CREATE, %.2f' % self.data.close[0])
            self.buy()  # keep order ref to avoid 2nd orders

        elif self.position and self.buysell_sig < 0:
            self.log('SELL CREATE, %.2f' % self.data.close[0])
            self.sell()

if __name__ == '__main__':
    # Create a cerebro entity
    cerebro = bt.Cerebro()

    # Add a strategy
    cerebro.addstrategy(SMACrossOver)

    # Create a Data Feed
    datapath = ('../../datas/2006-day-001.txt')
    data = bt.feeds.BacktraderCSVData(dataname=datapath)

    # Add the Data Feed to Cerebro
    cerebro.adddata(data)

    # set commission scheme -- CHANGE HERE TO PLAY
    cerebro.broker.setcommission(
        commission=commission, margin=margin, mult=mult)

    # Run over everything
    cerebro.run()

    # Plot the result
    cerebro.plot()

```

Reference

class backtrader.CommInfoBase()

Base Class for the Commission Schemes.

Params:

commission
 (def: 
0.0
): base commission value in percentage or
    monetary units

mult
 (def 
1.0
): multiplier applied to the asset for
    value/profit

margin
 (def: 
None
): amount of monetary units needed to
    open/hold an operation. It only applies if the final 
_stocklike

    attribute in the class is set to 
False

automargin
 (def: 
False
): Used by the method 
get_margin

    to automatically calculate the margin/guarantees needed with the
    following policy

Use param 
margin
 if param 
automargin
 evaluates to 
False

Use param 
mult
 and use 
mult * price
 if 
automargin < 0

Use param 
automargin
 and use 
automargin * price
 if 
automargin > 0

commtype
 (def: 
None
): Supported values are

CommInfoBase.COMM_PERC
 (commission to be understood as %) and

CommInfoBase.COMM_FIXED
 (commission to be understood as monetary
    units)

The default value of 
None
 is a supported value to retain
compatibility with the legacy 
CommissionInfo
 object. If

commtype
 is set to None, then the following applies:

margin
 is 
None
: Internal 
_commtype
 is set to

COMM_PERC
 and 
_stocklike
 is set to 
True
 (Operating
    %-wise with Stocks)

margin
 is not 
None
: 
_commtype
 set to 
COMM_FIXED
 and

_stocklike
 set to 
False
 (Operating with fixed rount-trip
    commission with Futures)

If this param is set to something else than 
None
, then it will be
passed to the internal 
_commtype
 attribute and the same will be
done with the param 
stocklike
 and the internal attribute

_stocklike

stocklike
 (def: 
False
): Indicates if the instrument is
    Stock-like or Futures-like (see the 
commtype
 discussion above)

percabs
 (def: 
False
): when 
commtype
 is set to COMM_PERC,
    whether the parameter 
commission
 has to be understood as XX% or
    0.XX

If this param is 
True
: 0.XX
If this param is 
False
: XX%

interest
 (def: 
0.0
)

If this is non-zero, this is the yearly interest charged for holding a
short selling position. This is mostly meant for stock short-selling

The formula: 
days * price * abs(size) * (interest / 365)

It must be specified in absolute terms: 0.05 -> 5%

Note

the behavior can be changed by overriding the method:

_get_credit_interest

interest_long
 (def: 
False
)

Some products like ETFs get charged on interest for short and long
positions. If ths is 
True
 and 
interest
 is non-zero the interest
will be charged on both directions

leverage
 (def: 
1.0
)

Amount of leverage for the asset with regards to the needed cash

- ``_stocklike``()

Final value to use for Stock-like/Futures-like behavior

- ``_commtype``()

Final value to use for PERC vs FIXED commissions

This two are used internally instead of the declared params to enable the()

compatibility check described above for the legacy ``CommissionInfo``()

object()

class backtrader.CommissionInfo()

Base Class for the actual Commission Schemes.

CommInfoBase was created to keep suppor for the original, incomplete,
support provided by 
backtrader
. New commission schemes derive from this
class which subclasses 
CommInfoBase
.

The default value of 
percabs
 is also changed to 
True

Params:

percabs
 (def: True): when 
commtype
 is set to COMM_PERC, whether
    the parameter 
commission
 has to be understood as XX% or 0.XX

If this param is True: 0.XX
If this param is False: XX%

get_leverage()

Returns the level of leverage allowed for this comission scheme

getsize(price, cash)

Returns the needed size to meet a cash operation at a given price

getoperationcost(size, price)

Returns the needed amount of cash an operation would cost

getvaluesize(size, price)

Returns the value of size for given a price. For future-like
objects it is fixed at 
size * margin

getvalue(position, price)

Returns the value of a position given a price. For future-like
objects it is fixed at 
size * margin

get_margin(price)

Returns the actual margin/guarantees needed for a single item of the
asset at the given price. The default implementation has this policy:

Use param 
margin
 if param 
automargin
 evaluates to 
False

Use param 
mult
, i.e. 
mult * price
 if 
automargin < 0

Use param 
automargin
, i.e. 
automargin * price
 if 
automargin > 0

getcommission(size, price)

Calculates the commission of an operation at a given price

_getcommission(size, price, pseudoexec)

Calculates the commission of an operation at a given price

pseudoexec: if True the operation has not yet been executed

profitandloss(size, price, newprice)

Return actual profit and loss a position has

cashadjust(size, price, newprice)

Calculates cash adjustment for a given price difference

get_credit_interest(data, pos, dt)

Calculates the credit due for short selling or product specific

_get_credit_interest(data, size, price, days, dt0, dt1)

This method returns  the cost in terms of credit interest charged by
the broker.

In the case of 
size > 0
 this method will only be called if the
parameter to the class 
interest_long
 is 
True

The formulat for the calculation of the credit interest rate is:

The formula: 
days * price * abs(size) * (interest / 365)

Params:

```
* `data`: data feed for which interest is charged

* `size`: current position size. > 0 for long positions and < 0 for
  short positions (this parameter will not be `0`)

* `price`: current position price

* `days`: number of days elapsed since last credit calculation
  (this is (dt0 - dt1).days)

* `dt0`: (datetime.datetime) current datetime

* `dt1`: (datetime.datetime) datetime of previous calculation

```

dt0
 and 
dt1
 are not used in the default implementation and are
provided as extra input for overridden methods
########################################
docu-concepts.txt - lunghezza: 24911
########################################
Platform Concepts

This is a collection of some of the concepts of the platform. It tries to gather
information bits which can be useful in using the platform.

Before Starting

All mini-code examples assume the following imports are available:

```
import backtrader as bt
import backtrader.indicators as btind
import backtrader.feeds as btfeeds

```

Note

An alternative syntax for accessing sub-modules like 
indicators
 and

feeds
:

```
import backtrader as bt

```

And then:

```
thefeed = bt.feeds.OneOfTheFeeds(...)
theind = bt.indicators.SimpleMovingAverage(...)

```

Data Feeds - Passing them around

The basis of the work with the platform will be done with 
Strategies
. And
these will get passed 
Data Feeds
. The platform end user does not need to care
about receiving them:

Data Feeds are automagically provided member variables to the strategy in the
  form of an array and shortcuts to the array positions

Quick preview of a Strategy derived class declaration and running the platform:

```
class MyStrategy(bt.Strategy):
    params = dict(period=20)

    def __init__(self):

        sma = btind.SimpleMovingAverage(self.datas[0], period=self.params.period)

    ...

cerebro = bt.Cerebro()

...

data = btfeeds.MyFeed(...)
cerebro.adddata(data)

...

cerebro.addstrategy(MyStrategy, period=30)

...

```

Notice the following:

No 
*args
 or 
**kwargs
 are being received by the strategy’s

__init__
 method (they may still be used)

A member variable 
self.datas
 exists which is array/list/iterable holding
    at least one item (hopefully or else an exception will be raised)

So it is. 
Data Feeds
 get added to the platform and they will show up inside
the strategy in the sequential order in which they were added to the system.

Note

This also applies to 
Indicators
, should the end user develop his
own custom Indicator or when having a look at the source code for
some of the existing Indicator Reference

Shortcuts for Data Feeds

The self.datas array items can be directly accessed with additional automatic
member variables:

self.data
 targets 
self.datas[0]

self.dataX
 targets 
self.datas[X]

The example then:

```
class MyStrategy(bt.Strategy):
    params = dict(period=20)

    def __init__(self):

        sma = btind.SimpleMovingAverage(self.data, period=self.params.period)

    ...

```

Omitting the Data Feeds

The example above can be further simplified to:

```
class MyStrategy(bt.Strategy):
    params = dict(period=20)

    def __init__(self):

        sma = btind.SimpleMovingAverage(period=self.params.period)

    ...

```

self.data
 has been completely removed from the invocation of

SimpleMovingAverage
. If this is done, the indicator (in this case the

SimpleMovingAverage
) receives the first data of the object in which is
being created (the 
Strategy
), which is 
self.data
 (aka 
self.data0
 or

self.datas[0]
)

Almost everything is a 
Data Feed

Not only Data Feeds are data and can be passed around. 
Indicators
 and
results of 
Operations
 are also data.

In the previous example the 
SimpleMovingAverage
 was receiving

self.datas[0]
 as input to operate on. An example with operations and extra
indicators:

```
class MyStrategy(bt.Strategy):
    params = dict(period1=20, period2=25, period3=10, period4)

    def __init__(self):

        sma1 = btind.SimpleMovingAverage(self.datas[0], period=self.p.period1)

        # This 2nd Moving Average operates using sma1 as "data"
        sma2 = btind.SimpleMovingAverage(sma1, period=self.p.period2)

        # New data created via arithmetic operation
        something = sma2 - sma1 + self.data.close

        # This 3rd Moving Average operates using something  as "data"
        sma3 = btind.SimpleMovingAverage(something, period=self.p.period3)

        # Comparison operators work too ...
        greater = sma3 > sma1

        # Pointless Moving Average of True/False values but valid
        # This 4th Moving Average operates using greater  as "data"
        sma3 = btind.SimpleMovingAverage(greater, period=self.p.period4)

    ...

```

Basically everything gets transformed into an object which can be used as a
data feed once it has been operated upon.

Parameters

Mostly every other 
class
 in the platform supports the notion of

parameters
.

Parameters along with default values are declared as a class attribute
    (tuple of tuples or dict-like object)

Keywords args (
**kwargs
) are scanned for matching parameters, removing
    them from 
**kwargs
 if found and assigning the value to the corresponding
    parameter

And parameters can be finally used in instances of the class by accessing
    the member variable 
self.params
 (shorthand: 
self.p
)

The previous quick Strategy preview already contains a parameters example, but
for the sake of redundancy, again, focusing only on the parameters. Using 
tuples
:

```
class MyStrategy(bt.Strategy):
    params = (('period', 20),)

    def __init__(self):
        sma = btind.SimpleMovingAverage(self.data, period=self.p.period)

```

And using a 
dict
:

```
class MyStrategy(bt.Strategy):
    params = dict(period=20)

    def __init__(self):
        sma = btind.SimpleMovingAverage(self.data, period=self.p.period)

```

Lines

Again mostly every other object in the platform is a 
Lines
 enabled
object. From a end user point of view this means:

It can hold one of more line series, being a line series an array of values
    were the values put together in a chart they would form a line.

A good example of a 
line
 (or 
lineseries
) is the line formed by the closing
prices of a stock. This is actually a well-known chart representation of the
evolution of prices (known as 
Line on Close
)

Regular use of the platform is only concerned with 
accessing

lines
. The
previous mini-strategy example, lightly extended, comes in handy again:

```
class MyStrategy(bt.Strategy):
    params = dict(period=20)

    def __init__(self):

        self.movav = btind.SimpleMovingAverage(self.data, period=self.p.period)

    def next(self):
        if self.movav.lines.sma[0] > self.data.lines.close[0]:
            print('Simple Moving Average is greater than the closing price')

```

Two objects with 
lines
 have been exposed:

self.data

    It has a 
lines
 attribute which contains a 
close
 attribute in turn

self.movav
 which is a 
SimpleMovingAverage
 indicator
    It has a 
lines
 attribute which contains a 
sma
 attribute in turn

Note

It should be obvious from this, that 
lines
 are named. They can
also be accessed sequentially following the declaration order, but
this should only be used in 
Indicator
 development

And both 
lines
, namely 
close
 and 
sma
 can be queried for a point
(
index 0
) to compare the values.

Shorthand access to lines do exist:

xxx.lines
 can be shortened to 
xxx.l

xxx.lines.name
 can be shortened to 
xxx.lines_name

Complex objects like Strategies and Indicators offer quick access to data’s
    lines

self.data_name
 offers a direct access to 
self.data.lines.name

Which also applies to the numbered data variables: 
self.data1_name
 ->

self.data1.lines.name

Additionally the line names are directly accessible with:

self.data.close
 and 
self.movav.sma

But the notation doesn’t make as clear as the previous one if 
lines
 are
actually being accessed.

Not

Setting
/
Assigning
 the lines with these two later notations is
not supported

Lines
 declaration

If an 
Indicator
 is being developed, the 
lines
 which the indicator has must
be declared.

Just as with 
params
 this takes place as a class attribute this time 
ONLY
 as
a tuple. Dictionaries are not supported because they do not store things
following insertion order.

For the Simple Moving Average it would be done like this:

```
class SimpleMovingAverage(Indicator):
    lines = ('sma',)

    ...

```

Note

The 
comma
 following the declaration is needed in tuples if you pass
a single string to the tuple or else each letter in the string would be
interpreted as an item to be added to the tuple. Possibly one of the
few spots where Python’s syntax got it wrong.

As seen in the previous example this declaration creates a 
sma
 line in the

Indicator
 that can be later accessed in the Strategy’s logic (and possibly by
other indicators to create more complex indicators)

For development is sometimes useful to access the lines in a generic non-named
manner and this is where numbered access comes in handy:

self.lines[0]
 points to 
self.lines.sma

Had more lines been defined they would be accessed with index 1, 2, and higher.

And of course, extra shorthand versions do exist:

self.line
 points to 
self.lines[0]

self.lineX
 point to 
self.lines[X]

self.line_X
 point to 
self.lines[X]

Inside objects which are receiving 
datas feeds
 the lines below these data
feeds can also be quickly accessed by number:

self.dataY
 points to 
self.data.lines[Y]

self.dataX_Y
 points to 
self.dataX.lines[X]
 which is a full shorthard
    version of 
self.datas[X].lines[Y]

Accessing 
lines
 in 
Data Feeds

Inside 
data feeds
 the 
lines
 can also be accessed omitting the

lines
. This makes it more natural to work with thinks like 
close

prices.

For example:

```
data = btfeeds.BacktraderCSVData(dataname='mydata.csv')

...

class MyStrategy(bt.Strategy):

    ...

    def next(self):

        if self.data.close[0] > 30.0:
            ...

```

Which seems more natural than the also valid: 
if self.data.lines.close[0] >
30.0:
. The same doesn’t apply to 
Indicators
 with the reasoning being:

An 
Indicator
 could have an attribute 
close
 which holds an
    intermediate calculation, which is later delivered to the actual 
lines

    also named 
close

In the case of 
Data Feeds
, no calculation takes place, because it is only a
data source.

Lines
 len

Lines
 have a set of points and grow dynamically during execution, therefore
the length can be measured at any time by invoking the standard Python 
len

function.

This applies to for example:

Data Feeds

Strategies

Indicators

An additional property applies to 
Data Feeds
 when the data is 
preloaded
:

Method 
buflen

The method returns the actual number of bars the 
Data Feed
 has available.

The difference between 
len
 and 
buflen

len
 reports how many bars have been processed

buflen
 reports the total number of bars which have been loaded for the
    Data Feed

If both return the same value, either no data has been preloaded or the
processing of bars has consumed all preloaded bars (and unless the system is
connected to a live feed, this will mean the end of processing)

Inheritance of Lines and Params

A kind of metalanguage is in place to support declaration of 
Params
 and

Lines
. Every effort has been made to make it compatible with standard Python
inheritance rules.

Params inheritance

Inheritance should work as expected:

Multiple inheritance is supported

Params from base classes are inherited

If multiple base classes define the same param the default value of the last
    class in the inheritance list is used

If the same param is redefined in a child class, the new default value takes
    over that of the base class

Lines Inheritance

Multiple inheritance is supported

Lines from all base classes are inherited. Being 
named
 lines there will
    only be one version of a line if the same name has been used more than once
    in base classes

Indexing: 0 and -1

Lines
 as seen before are line series and have a set of points that conform a
line when drawn together (like when joining all closing prices together along a
time axis)

To access those points in regular code, the choice has been to use a 
0
 based
approach for the current 
get/set
 instant.

Strategies do only 
get
 values. Indicators do also 
set
 values.

From the previous quick strategy example where the 
next
 method was briefly seen:

```
def next(self):
    if self.movav.lines.sma[0] > self.data.lines.close[0]:
        print('Simple Moving Average is greater than the closing price')

```

The logic is 
getting
 the current value of the moving average and the current
closing price by applying index 
0
.

Note

Actually for index 
0
 and when applying logic/arithmetic operators
the comparison can be made directly as in:

```
if self.movav.lines.sma > self.data.lines.close:
    ...

```

See later in the document the explanation for operators.

Setting is meant to be used when developing, for example, an Indicator,
because the current output value has to be set by the indicator.

A SimpleMovingAverage can be calculated for the current get/set point as
follows:

```
def next(self):
  self.line[0] = math.fsum(self.data.get(0, size=self.p.period)) / self.p.period

```

Accessing previous set points has been modeled following the definition Python
makes for 
-1
 when accessing an array/iterable

It points to the last item of the array

The platform consider the last set item (before the current live get/set
point) to be 
-1
.

As such comparing the current 
close
 to the 
previous

close
 is a 
0

vs 
-1
 thing. In a strategy, for example:

```
def next(self):
    if self.data.close[0] > self.data.close[-1]:
        print('Closing price is higher today')

```

Of course and logically, prices 
set
 before 
-1
 will be accessed with 
-2,
-3, ...
.

Slicing

backtrader
 doesn’t support slicing for 
lines
 objects and this is a design
decision following the 
[0]
 and 
[-1]
 indexing scheme. With regular
indexable Python objects you would do things like:

```
myslice = self.my_sma[0:]  # slice from the beginning til the end

```

But remember that with the choice for 
0
 … it is actually the currently
delivered value, there is nothing after it. Also:

```
myslice = self.my_sma[0:-1]  # slice from the beginning til the end

```

Again … 
0
 is the current value and 
-1
 is the latest (previous)
delivered value. That’s why a slice from 
0
 -> 
-1
 makes no sense in the

backtrader
 ecosystem.

If slicing were ever to be supported, it would look like:

```
myslice = self.my_sma[:0]  # slice from current point backwards to the beginning

```

or:

```
myslice = self.my_sma[-1:0]  # last value and current value

```

or:

```
myslice = self.my_sma[-3:-1]  # from last value backwards to the 3rd last value

```

Getting a slice

An array with the latest values can still be gotten. The syntax:

```
myslice = self.my_sma.get(ago=0, size=1)  # default values shown

```

That would have returned an arry with 
1
 value (
size=1
) with the current
moment 
0
 as the staring point to look backwards.

To get 10 values from the current point in time (i.e.: the last 10 values):

```
myslice = self.my_sma.get(size=10)  # ago defaults to 0

```

Of course the array has the ordering you would expect. The leftmost value is
the oldest one and the rightmost value is the most current (it is a regular
python array and not a 
lines
 object)

To get the last 10 values skipping only the current point:

```
myslice = self.my_sma.get(ago=-1, size=10)

```

Lines: DELAYED indexing

The 
[]
 operator syntax is there to extract individual values during the

next
 logic phase. 
Lines
 objects support an additional notation to address
values through a 
delayed lines object
 during the 
__init__
 phase.

Let’s say that the interest in the logic is to compare the previous 
close
 value
to the actual value of a 
simple moving average
. Rather than doing it manually
in each 
next
 iteration a pre-canned 
lines
 object can be generated:

```
class MyStrategy(bt.Strategy):
    params = dict(period=20)

    def __init__(self):

        self.movav = btind.SimpleMovingAverage(self.data, period=self.p.period)
        self.cmpval = self.data.close(-1) > self.sma

    def next(self):
        if self.cmpval[0]:
            print('Previous close is higher than the moving average')

```

Here the 
(delay)
 notation is being used:

This delivers a replica of the 
close
 prices but delayed by 
-1
.

And the comparison 
self.data.close(-1) > self.sma
 generates another

lines
 object which returns either 
1
 if the condition is 
True
 or

0
 if 
False

Lines Coupling

The operator 
()
 can be used as shown above with 
delay
 value to provide
a delayed version of a 
lines
 object.

If the syntax is used 
WITHOUT
 providing a 
delay
 value, then a

LinesCoupler

lines
 object is returned. This is meant to establish a
coupling between indicators that operate on 
datas
 with different timeframes.

Data Feeds with different timeframes have different 
lengths
, and the
indicators operating on them replicate the length of the data. Example:

A daily data feed has around 250 bars per year

A weekly data feed has 52 bars per year

Trying to create an operation (for example) which compares 2 
simple moving
averages
, each operating on the datas quoted above would break. It would be
unclear how to match the 250 bars from the daily timeframe to the 52 bars of
the weekly timeframe.

The reader could imagine a 
date
 comparison taking place in the background
to find out a day - week correspondence, but:

Indicators
 are just mathematical formulas and have no 
datetime

    information

They know nothing about the environment, just that if the data provides
enough values, a calculation can take place.

The 
()
 (empty call) notation comes to the rescue:

```
class MyStrategy(bt.Strategy):
    params = dict(period=20)

    def __init__(self):

        # data0 is a daily data
        sma0 = btind.SMA(self.data0, period=15)  # 15 days sma
        # data1 is a weekly data
        sma1 = btind.SMA(self.data1, period=5)  # 5 weeks sma

        self.buysig = sma0 > sma1()

    def next(self):
        if self.buysig[0]:
            print('daily sma is greater than weekly sma1')

```

Here the larger timeframe indicator, 
sma1
 is 
coupled
 to the daily
timeframe with 
sma1()
. This returns an object which is compatible with the
larger numbers of bars of 
sma0
 and copies the values produced by 
sma1
,
effectively spreading the 52 weekly bars in 250 daily bars

Operators, using natural constructs

In order to achieve the “ease of use” goal the platform allows (within the
constraints of Python) the use of operators. And to further enhance this goal
, the use of operators has been broken in two stages.

Stage 1 - Operators Create Objects

An example has already been seen even if not explicitly meant for this. During
the initialization phase (
__init__
 method) of objects like Indicators and
Strategies, operators create objects that can be operated upon, assigned or kept
as reference for later using during the evaluation phase of the Strategy’s
logic.

Once again a potential implementation of a SimpleMovingAverage, further broken
down into steps.

The code inside the SimpleMovingAverage indicator 
__init__
 could look like:

```
def __init__(self):
    # Sum N period values - datasum is now a *Lines* object
    # that when queried with the operator [] and index 0
    # returns the current sum

    datasum = btind.SumN(self.data, period=self.params.period)

    # datasum (being *Lines* object although single line) can be
    # naturally divided by an int/float as in this case. It could
    # actually be divided by anothr *Lines* object.
    # The operation returns an object assigned to "av" which again
    # returns the current average at the current instant in time
    # when queried with [0]

    av = datasum / self.params.period

    # The av *Lines* object can be naturally assigned to the named
    # line this indicator delivers. Other objects using this
    # indicator will have direct access to the calculation

    self.line.sma = av

```

A more complete use case is shown during the initialization of a Strategy:

```
class MyStrategy(bt.Strategy):

    def __init__(self):

        sma = btind.SimpleMovinAverage(self.data, period=20)

        close_over_sma = self.data.close > sma
        sma_dist_to_high = self.data.high - sma

        sma_dist_small = sma_dist_to_high < 3.5

        # Unfortunately "and" cannot be overridden in Python being
        # a language construct and not an operator and thus a
        # function has to be provided by the platform to emulate it

        sell_sig = bt.And(close_over_sma, sma_dist_small)

```

After the above operations have taken place, 
sell_sig
 is a 
Lines
 object
which can be later used in the logic of the Strategy, indicating if the
conditions are met or not.

Stage 2 - Operators true to nature

Let’s first remember that a strategy has a 
next
 method which is called for
every bar the system processes. This is where operators are actually in the
stage 2 mode. Building on the previous example:

```
class MyStrategy(bt.Strategy):

    def __init__(self):

        self.sma = sma = btind.SimpleMovinAverage(self.data, period=20)

        close_over_sma = self.data.close > sma
        self.sma_dist_to_high = self.data.high - sma

        sma_dist_small = sma_dist_to_high < 3.5

        # Unfortunately "and" cannot be overridden in Python being
        # a language construct and not an operator and thus a
        # function has to be provided by the platform to emulate it

        self.sell_sig = bt.And(close_over_sma, sma_dist_small)

    def next(self):

        # Although this does not seem like an "operator" it actually is
        # in the sense that the object is being tested for a True/False
        # response

        if self.sma > 30.0:
            print('sma is greater than 30.0')

        if self.sma > self.data.close:
            print('sma is above the close price')

        if self.sell_sig:  # if sell_sig == True: would also be valid
            print('sell sig is True')
        else:
            print('sell sig is False')

        if self.sma_dist_to_high > 5.0:
            print('distance from sma to hig is greater than 5.0')

```

Not a very useful strategy, just an example. During Stage 2 operators return the
expected values (boolean if testing for truth and floats if comparing them to
floats) and also arithmetic operations do.

Note

Notice that comparisons are actually not using the [] operator. This
is meant to further simplify things.

if self.sma > 30.0:
 … compares 
self.sma[0]
 to 
30.0
 (1
st

line and current value)

if self.sma > self.data.close:
 … compares 
self.sma[0]
 to

self.data.close[0]

Some non-overriden operators/functions

Python will not allow overriding everything and thus some functions are provided
to cope with the cases.

Note

Only meant to be used during Stage 1, to create objects which later
provide values.

Operators:

and
 -> 
And

or
 -> 
Or

Logic Control:

if
 -> 
If

Functions:

any
 -> 
Any

all
 -> 
All

cmp
 -> 
Cmp

max
 -> 
Max

min
 -> 
Min

sum
 -> 
Sum

Sum
 actually uses 
math.fsum
 as the underlying operation because the
platform works with floating point numbers and applying a regular 
sum

may have an impact on precision.

reduce
 -> 
Reduce

These utility operators/functions operate on iterables. The elements in the
iterables can be regular Python numeric types (ints, floats, …) and also
objects with 
Lines
.

An example generating a very dumb buy signal:

```
class MyStrategy(bt.Strategy):

    def __init__(self):

        sma1 = btind.SMA(self.data.close, period=15)
        self.buysig = bt.And(sma1 > self.data.close, sma1 > self.data.high)

    def next(self):
        if self.buysig[0]:
            pass  # do something here

```

It is obvious that if the 
sma1
 is higher than the high, it must be higher
than the close. But the point is illustrating the use of 
bt.And
.

Using 
bt.If
:

```
class MyStrategy(bt.Strategy):

    def __init__(self):

        sma1 = btind.SMA(self.data.close, period=15)
        high_or_low = bt.If(sma1 > self.data.close, self.data.low, self.data.high)
        sma2 = btind.SMA(high_or_low, period=15)

```

Breakdown:

Generate a 
SMA
 on 
data.close
 of 
period=15

And then

bt.If
 the value of the 
sma
 is larger than 
close
, return

low
, else return 
high

Remember that no actual value is being returned when 
bt.If
 is being
  invoked. It returns a 
Lines
 object which is just like a

SimpleMovingAverage
.

The values will be calculated later when the system runs

The generated 
bt.If

Lines
 object is then fed to a 2
nd

SMA
 which
    will sometimes use the 
low
 prices and sometimes the 
high
 prices for
    the calculation

Those 
functions
 take also numeric values. The same example with a modification:

```
class MyStrategy(bt.Strategy):

    def __init__(self):

        sma1 = btind.SMA(self.data.close, period=15)
        high_or_30 = bt.If(sma1 > self.data.close, 30.0, self.data.high)
        sma2 = btind.SMA(high_or_30, period=15)

```

Now the 2
nd
 moving average uses either 
30.0
 or the 
high
 prices to
perform the calculation, depending on the logic status of 
sma
 vs 
close

Note

The value 
30
 is transformed internally into a pseudo-iterable which
always returns 
30
########################################
docu-data-multitimeframe-data-multitimeframe.txt - lunghezza: 9173
########################################
Data - Multiple Timeframes

Sometimes investing decisions are taken using different timeframes:

Weekly to evaluate the trend

Daily to execute the entry

Or 5 minutes vs 60 minutes.

That implies that combining datas of multiple timeframes in 
backtrader
 is
needed to support such combinations.

Native support for it is already built-in. The end user must only follow these
rules:

The data with the smallest timeframe (and thus the larger number of bars)
    must be the 1
st
 one to be added to the Cerebro instance

The datas must be properly date-time aligned for the platform to make any
    sense out of them

Beyond that, the end-user is free to apply indicators as wished on the
shorter/larger timeframes. Of course:

Indicators applied to larger timeframes will produce less bars

The platform will also have the following into account

The minimum period for larger timeframes

Minimum period which will probably have the side effect of having to consume
several orders of magnitude of the smaller timeframe bars before a Strategy
added to Cerebro kicks into action.

The built-in 
cerebro.resample
 is going to be used to create a larger timeframe.

Some examples below, but first the sauce of the test script.

```
    # Load the Data
    datapath = args.dataname or '../../datas/2006-day-001.txt'
    data = btfeeds.BacktraderCSVData(dataname=datapath)
    cerebro.adddata(data)  # First add the original data - smaller timeframe

    tframes = dict(daily=bt.TimeFrame.Days, weekly=bt.TimeFrame.Weeks,
                   monthly=bt.TimeFrame.Months)

    # Handy dictionary for the argument timeframe conversion
    # Resample the data
    if args.noresample:
        datapath = args.dataname2 or '../../datas/2006-week-001.txt'
        data2 = btfeeds.BacktraderCSVData(dataname=datapath)
        # And then the large timeframe
        cerebro.adddata(data2)
    else:
        cerebro.resampledata(data, timeframe=tframes[args.timeframe],
                             compression=args.compression)

    # Run over everything
    cerebro.run()

```

The steps:

Load a data

Resample it according to the user specified arguments

The script also allows for loading a 2
nd
 data

Add the data to cerebro

Add the resampled data (larger timeframe) to cerebro

run

Example 1 - Daily and Weekly

The invocation of the script:

```
$ ./multitimeframe-example.py --timeframe weekly --compression 1

```

And the output chart:

Example 2 - Daily and Daily Compression (2 bars to 1)

The invocation of the script:

```
$ ./multitimeframe-example.py --timeframe daily --compression 2

```

And the output chart:

Example 3 - Strategy with SMA

Although plotting is nice, the key issue here is showing how the larger
timeframe influences the system, especially when it comes down to the starting
point

The script can take a 
--indicators
 to add a strategy which creates simple
moving averages of 
period 10
 on the smaller an larger timeframe datas.

If only the smaller timeframe was taken into account:

next
 would be called first after 10 bars, which is the time the Simple
    Moving Average needs to produce a value

NOTE
: Remember that Strategy monitors created indicators and only calls

next
 when all indicators have produced a value. The rationale is that
the end user has added the indicators to use them in the logic and thus
no logic should take place if the indicators have produced no values

But in this case the larger timeframe (weekly) delays the invocation of 
next

until the Simple Moving Average oon the weekly data has produced a value, which
takes … 10 weeks.

The script overrides 
nextstart
 which is only called once and which defaults
to calling 
next
 to show when it is first called.

Invocation 1:

Only the smaller timeframe, daily, gets a Simple Moving Average

The command line and output

```
$ ./multitimeframe-example.py --timeframe weekly --compression 1 --indicators --onlydaily
--------------------------------------------------
nextstart called with len 10
--------------------------------------------------

```

And the chart.

Invocation 2:

Both timeframes get a Simple Moving Average

The command line:

```
$ ./multitimeframe-example.py --timeframe weekly --compression 1 --indicators
--------------------------------------------------
nextstart called with len 50
--------------------------------------------------
--------------------------------------------------
nextstart called with len 51
--------------------------------------------------
--------------------------------------------------
nextstart called with len 52
--------------------------------------------------
--------------------------------------------------
nextstart called with len 53
--------------------------------------------------
--------------------------------------------------
nextstart called with len 54
--------------------------------------------------

```

Two things to notice here:

Instead of being called after 
10
 periods, the strategy is 1
st
 called
    after 50 periods.

It is so because the Simple Moving Average applied on the larger (weekly)
timeframe produces a value after 10 weeks … and that is 
10 weeks * 5 days
/ week … 50 days

nextstart
 gets called 5 times rather than only 1.

This is a natural side effect of having mixed the timeframe and having (in
this case only one) indicators applied to the larger timeframe.

The larger timeframe Simple Moving Average produces 5 times the same value
whilst 5 daily bars are being consumed.

And because the start of the period is being controlled by the larger
timeframe 
nextstart
 gets called 5 times.

And the chart.

Conclusion

Multiple Timeframe Datas can be used in 
backtrader
 with no special objects
or tweaking: just add the smaller timeframes first.

The test script.

```
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import argparse

import backtrader as bt
import backtrader.feeds as btfeeds
import backtrader.indicators as btind

class SMAStrategy(bt.Strategy):
    params = (
        ('period', 10),
        ('onlydaily', False),
    )

    def __init__(self):
        self.sma_small_tf = btind.SMA(self.data, period=self.p.period)
        if not self.p.onlydaily:
            self.sma_large_tf = btind.SMA(self.data1, period=self.p.period)

    def nextstart(self):
        print('--------------------------------------------------')
        print('nextstart called with len', len(self))
        print('--------------------------------------------------')

        super(SMAStrategy, self).nextstart()

def runstrat():
    args = parse_args()

    # Create a cerebro entity
    cerebro = bt.Cerebro(stdstats=False)

    # Add a strategy
    if not args.indicators:
        cerebro.addstrategy(bt.Strategy)
    else:
        cerebro.addstrategy(
            SMAStrategy,

            # args for the strategy
            period=args.period,
            onlydaily=args.onlydaily,
        )

    # Load the Data
    datapath = args.dataname or '../../datas/2006-day-001.txt'
    data = btfeeds.BacktraderCSVData(dataname=datapath)
    cerebro.adddata(data)  # First add the original data - smaller timeframe

    tframes = dict(daily=bt.TimeFrame.Days, weekly=bt.TimeFrame.Weeks,
                   monthly=bt.TimeFrame.Months)

    # Handy dictionary for the argument timeframe conversion
    # Resample the data
    if args.noresample:
        datapath = args.dataname2 or '../../datas/2006-week-001.txt'
        data2 = btfeeds.BacktraderCSVData(dataname=datapath)
        # And then the large timeframe
        cerebro.adddata(data2)
    else:
        cerebro.resampledata(data, timeframe=tframes[args.timeframe],
                             compression=args.compression)

    # Run over everything
    cerebro.run()

    # Plot the result
    cerebro.plot(style='bar')

def parse_args():
    parser = argparse.ArgumentParser(
        description='Multitimeframe test')

    parser.add_argument('--dataname', default='', required=False,
                        help='File Data to Load')

    parser.add_argument('--dataname2', default='', required=False,
                        help='Larger timeframe file to load')

    parser.add_argument('--noresample', action='store_true',
                        help='Do not resample, rather load larger timeframe')

    parser.add_argument('--timeframe', default='weekly', required=False,
                        choices=['daily', 'weekly', 'monhtly'],
                        help='Timeframe to resample to')

    parser.add_argument('--compression', default=1, required=False, type=int,
                        help='Compress n bars into 1')

    parser.add_argument('--indicators', action='store_true',
                        help='Wether to apply Strategy with indicators')

    parser.add_argument('--onlydaily', action='store_true',
                        help='Indicator only to be applied to daily timeframe')

    parser.add_argument('--period', default=10, required=False, type=int,
                        help='Period to apply to indicator')

    return parser.parse_args()

if __name__ == '__main__':
    runstrat()

```
########################################
docu-data-replay-data-replay.txt - lunghezza: 8326
########################################
Data - Replay

The time is gone and testing a strategy against a fully formed and closed bar is
good, but it could be better.

This is where 
Data Replay
 comes in to help. If:

The strategy operates on data with a timeframe X (example: daily)

and

Data for a smaller timeframe Y (example: 1 minute) is available

Data replay does exactly what the name implies:

Replay a daily bar using the 1 minute data

This is of course not exactly how the market developed, but it is far better
than looking at the daily fully formed and closed bar in isolation:

If the strategy operates in realtime during the formation of the daily bar,
the approximation of the formation of the bar gives a chance to replicate the
actual behavior of the strategy under real conditions

Putting 
Data Replay
 into action follows the regular usage patterns of

backtrader

Load a data feed

Pass the data to cerebro with 
replaydata

Add a strategy

Note

Preloading is not supported when data is being replayed because each bar
is actually built in real-time. It will automatically disabled in any

Cerebro
 instance.

Parameters which can be passed to 
replaydata
:

timeframe
 (default: bt.TimeFrame.Days)

Destination timeframe  which to be useful has to
be equal or larger than the source

compression
 (default: 1)

Compress the selected value “n” to 1 bar

Extended parameters (do not touch if not really needed):

bar2edge
 (default: True)

replays using time boundaries as the target of the closed bar. For
example with a “ticks -> 5 seconds” the resulting 5 seconds bars will
be aligned to xx:00, xx:05, xx:10 …

adjbartime
 (default: False)

Use the time at the boundary to adjust the time of the delivered
resampled bar instead of the last seen timestamp. If resampling to “5
seconds” the time of the bar will be adjusted for example to hh
05
even if the last seen timestamp was hh
04.33

NOTE
: Time will only be adjusted if “bar2edge” is True. It wouldn’t make
sense to adjust the time if the bar has not been aligned to a
boundary

rightedge
 (default: True)

Use the right edge of the time boundaries to set the time.

If False and compressing to 5 seconds the time of a resampled bar for
seconds between hh
00 and hh
04 will be hh
00 (the starting
boundary

If True the used boundary for the time will be hh
05 (the ending
boundary)

For the sake of working with a example the standard 2006 daily data will be
replayed on a weekly basis. Which means:

There will finally be 52 bars, one for each week

Cerebro will call 
prenext
 and 
next
 a total of 255 times, which is
    the original count of daily bars

The trick:

When a weekly bar is forming, the length (
len(self)
) of the strategy
    will remain unchanged.

With each new week the length will increase by one

Some examples below, but first the sauce of the test script in which the data is
loaded and passed to cerebro with 
replaydata
 … and then 
run
.

```
    # Load the Data
    datapath = args.dataname or '../../datas/2006-day-001.txt'
    data = btfeeds.BacktraderCSVData(dataname=datapath)

    # Handy dictionary for the argument timeframe conversion
    tframes = dict(
        daily=bt.TimeFrame.Days,
        weekly=bt.TimeFrame.Weeks,
        monthly=bt.TimeFrame.Months)

    # First add the original data - smaller timeframe
    cerebro.replaydata(data,
                       timeframe=tframes[args.timeframe],
                       compression=args.compression)

```

Example - Replay Daily to Weekly

The invocation of the script:

```
$ ./replay-example.py --timeframe weekly --compression 1

```

The chart cannot unfortunately show us the real thing happening in the
background, so let’s have a look at the console output:

```
prenext len 1 - counter 1
prenext len 1 - counter 2
prenext len 1 - counter 3
prenext len 1 - counter 4
prenext len 1 - counter 5
prenext len 2 - counter 6
...
...
prenext len 9 - counter 44
prenext len 9 - counter 45
---next len 10 - counter 46
---next len 10 - counter 47
---next len 10 - counter 48
---next len 10 - counter 49
---next len 10 - counter 50
---next len 11 - counter 51
---next len 11 - counter 52
---next len 11 - counter 53
...
...
---next len 51 - counter 248
---next len 51 - counter 249
---next len 51 - counter 250
---next len 51 - counter 251
---next len 51 - counter 252
---next len 52 - counter 253
---next len 52 - counter 254
---next len 52 - counter 255

```

As we see the internal 
self.counter
 variable is keeping track of each call
to either 
prenext
 or 
next
. The former being called before the applied
Simple Moving Average produces a value. The latter called when the Simple Moving
Average is producing values.

The key:

The length (len(self)) of the strategy changes every 5 bars (5 trading days
    in the week)

The strategy is effectively seeing:

How the weekly bar developed in 5 shots.

This, again, doesn’t replicate the actual tick-by-tick (and not even minute,
hour) development of the market, but it is better than actually seeing a
bar.

The visual output is that of the weekly chart which is the final outcome the
system is being tested again.

Example 2 - Daily to Daily with Compression

Of course “Replaying” can be applied to the same timeframe but with a
compression.

The console:

```
$ ./replay-example.py --timeframe daily --compression 2
prenext len 1 - counter 1
prenext len 1 - counter 2
prenext len 2 - counter 3
prenext len 2 - counter 4
prenext len 3 - counter 5
prenext len 3 - counter 6
prenext len 4 - counter 7
...
...
---next len 125 - counter 250
---next len 126 - counter 251
---next len 126 - counter 252
---next len 127 - counter 253
---next len 127 - counter 254
---next len 128 - counter 255

```

This time we got half the bars as expected because of the factor 2 requested compression.

The chart:

Conclusion

A reconstruction of the market development is possible. Usually a smaller
timeframe set of data is available and can be used to discretely replay the
timeframe which the system operates on.

The test script.

```
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import argparse

import backtrader as bt
import backtrader.feeds as btfeeds
import backtrader.indicators as btind

class SMAStrategy(bt.Strategy):
    params = (
        ('period', 10),
        ('onlydaily', False),
    )

    def __init__(self):
        self.sma = btind.SMA(self.data, period=self.p.period)

    def start(self):
        self.counter = 0

    def prenext(self):
        self.counter += 1
        print('prenext len %d - counter %d' % (len(self), self.counter))

    def next(self):
        self.counter += 1
        print('---next len %d - counter %d' % (len(self), self.counter))

def runstrat():
    args = parse_args()

    # Create a cerebro entity
    cerebro = bt.Cerebro(stdstats=False)

    cerebro.addstrategy(
        SMAStrategy,
        # args for the strategy
        period=args.period,
    )

    # Load the Data
    datapath = args.dataname or '../../datas/2006-day-001.txt'
    data = btfeeds.BacktraderCSVData(dataname=datapath)

    # Handy dictionary for the argument timeframe conversion
    tframes = dict(
        daily=bt.TimeFrame.Days,
        weekly=bt.TimeFrame.Weeks,
        monthly=bt.TimeFrame.Months)

    # First add the original data - smaller timeframe
    cerebro.replaydata(data,
                       timeframe=tframes[args.timeframe],
                       compression=args.compression)

    # Run over everything
    cerebro.run()

    # Plot the result
    cerebro.plot(style='bar')

def parse_args():
    parser = argparse.ArgumentParser(
        description='Pandas test script')

    parser.add_argument('--dataname', default='', required=False,
                        help='File Data to Load')

    parser.add_argument('--timeframe', default='weekly', required=False,
                        choices=['daily', 'weekly', 'monhtly'],
                        help='Timeframe to resample to')

    parser.add_argument('--compression', default=1, required=False, type=int,
                        help='Compress n bars into 1')

    parser.add_argument('--period', default=10, required=False, type=int,
                        help='Period to apply to indicator')

    return parser.parse_args()

if __name__ == '__main__':
    runstrat()

```
########################################
docu-data-resampling-data-resampling.txt - lunghezza: 5680
########################################
Data Resampling

When data is only available in a single timeframe and the analysis has to be
done for a different timeframe, it’s time to do some resampling.

“Resampling” should actually be called “Upsampling” given that one goes from a
source timeframe to a larger time frame (for example: days to weeks)

backtrader
 has built-in support for resampling by passing the original data
through a filter object. Although there are several ways to achieve this, a
straightforward interface exists to achieve this:

Instead of using 
cerebro.adddata(data)
 to put a 
data
 into the system use

cerebro.resampledata(data, **kwargs)

There are two main options that can be controlled

Change the timeframe

Compress bars

To do so, use the following parameters when calling 
resampledata
:

timeframe
 (default: bt.TimeFrame.Days)

Destination timeframe  which to be useful has to
be equal or larger than the source

compression
 (default: 1)

Compress the selected value “n” to 1 bar

Let’s see an example from Daily to Weekly with a handcrafted script:

```
$ ./resampling-example.py --timeframe weekly --compression 1

```

The output:

We can compare it to the original daily data:

```
$ ./resampling-example.py --timeframe daily --compression 1

```

The output:

The magic is done by executing the following steps:

Loading the data as usual

Feeding the data into cerebro with 
resampledata
 with the desired
    parameters:

timeframe

compression

The code in the sample (the entire script at the bottom).

```
    # Load the Data
    datapath = args.dataname or '../../datas/2006-day-001.txt'
    data = btfeeds.BacktraderCSVData(dataname=datapath)

    # Handy dictionary for the argument timeframe conversion
    tframes = dict(
        daily=bt.TimeFrame.Days,
        weekly=bt.TimeFrame.Weeks,
        monthly=bt.TimeFrame.Months)

    # Add the resample data instead of the original
    cerebro.resampledata(data,
                         timeframe=tframes[args.timeframe],
                         compression=args.compression)

```

A last example in which we first change the time frame from daily to weekly and
then apply a 3 to 1 compression:

```
$ ./resampling-example.py --timeframe weekly --compression 3

```

The output:

From the original 256 daily bars we end up with 18 3-week bars. The breakdown:

52 weeks

52 / 3 = 17.33 and therefore 18 bars

It doesn’t take much more. Of course intraday data can also be resampled.

The resampling filter supports additional parameters, which in most cases
should not be touched:

bar2edge
 (default: 
True
)

resamples using time boundaries as the target. For example with a
“ticks -> 5 seconds” the resulting 5 seconds bars will be aligned to
xx:00, xx:05, xx:10 …

adjbartime
 (default: 
True
)

Use the time at the boundary to adjust the time of the delivered
resampled bar instead of the last seen timestamp. If resampling to “5
seconds” the time of the bar will be adjusted for example to hh
05
even if the last seen timestamp was hh
04.33

Note

Time will only be adjusted if “bar2edge” is True. It wouldn’t make
sense to adjust the time if the bar has not been aligned to a
boundary

rightedge
 (default: 
True
)

Use the right edge of the time boundaries to set the time.

If False and compressing to 5 seconds the time of a resampled bar for
seconds between hh
00 and hh
04 will be hh
00 (the starting
boundary

If True the used boundary for the time will be hh
05 (the ending
boundary)

boundoff
 (default: 
0
)

Push the boundary for resampling/replaying by an amount of units.

If for example the resampling is from 
1 minute
 to 
15 minutes
, the
default behavior is to take the 1-minute bars from 
00:01:00
 until

00:15:00
 to produce a 15-minutes replayed/resampled bar.

If 
boundoff
 is set to 
1
, then the boundary is pushed 
1 unit

forward. In this case the original 
unit
 is a 
1-minute
 bar. Consequently
the resampling/replaying will now:

Use the bars from 
00:00:00
 to 
00:14:00
 for the generation of the
    15-minutes bar

The sample code for the resampling test script.

```
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import argparse

import backtrader as bt
import backtrader.feeds as btfeeds

def runstrat():
    args = parse_args()

    # Create a cerebro entity
    cerebro = bt.Cerebro(stdstats=False)

    # Add a strategy
    cerebro.addstrategy(bt.Strategy)

    # Load the Data
    datapath = args.dataname or '../../datas/2006-day-001.txt'
    data = btfeeds.BacktraderCSVData(dataname=datapath)

    # Handy dictionary for the argument timeframe conversion
    tframes = dict(
        daily=bt.TimeFrame.Days,
        weekly=bt.TimeFrame.Weeks,
        monthly=bt.TimeFrame.Months)

    # Add the resample data instead of the original
    cerebro.resampledata(data,
                         timeframe=tframes[args.timeframe],
                         compression=args.compression)

    # Run over everything
    cerebro.run()

    # Plot the result
    cerebro.plot(style='bar')

def parse_args():
    parser = argparse.ArgumentParser(
        description='Pandas test script')

    parser.add_argument('--dataname', default='', required=False,
                        help='File Data to Load')

    parser.add_argument('--timeframe', default='weekly', required=False,
                        choices=['daily', 'weekly', 'monhtly'],
                        help='Timeframe to resample to')

    parser.add_argument('--compression', default=1, required=False, type=int,
                        help='Compress n bars into 1')

    return parser.parse_args()

if __name__ == '__main__':
    runstrat()

```
########################################
docu-data-rollover-rolling-futures-over.txt - lunghezza: 16871
########################################
Rolling over Futures

Not every provider offers a 
continuous
 future for the instruments with which
one can trade. Sometimes the data offered is that of the still valid expiration
dates, i.e.: those still being traded

This is not so helpful when it comes to 
backtesting
 because the data is
scattered over several different instruments which additionally … 
overlap

in time.

Being able to properly join the data of those instruments, from the past, into
a continuous stream alleviates the pain. The problem:

There is no law as to how best join the different expiration dates into a
    continuous future

Some literature, courtesy of 
SierraChart
 at:

http://www.sierrachart.com/index.php?page=doc/ChangingFuturesContract.html

The RollOver Data Feed

backtrader
 has added with 
1.8.10.99
 the possibility to join futures’ data
from different expiration dates into a continuous future:

```
import backtrader as bt

cerebro = bt.Cerebro()
data0 = bt.feeds.MyFeed(dataname='Expiry0')
data1 = bt.feeds.MyFeed(dataname='Expiry1')
...
dataN = bt.feeds.MyFeed(dataname='ExpiryN')

drollover = cerebro.rolloverdata(data0, data1, ..., dataN, name='MyRoll', **kwargs)

cerebro.run()

```

Note

The possible 
**kwargs
 are explained below

It can also be done by directly accessing the 
RollOver
 feed (which is
helpful if subclassing is done):

```
import backtrader as bt

cerebro = bt.Cerebro()
data0 = bt.feeds.MyFeed(dataname='Expiry0')
data1 = bt.feeds.MyFeed(dataname='Expiry1')
...
dataN = bt.feeds.MyFeed(dataname='ExpiryN')

drollover = bt.feeds.RollOver(data0, data1, ..., dataN, dataname='MyRoll', **kwargs)
cerebro.adddata(drollover)

cerebro.run()

```

Note

The possible 
**kwargs
 are explained below

Note

When using 
RollOver
 the name is assigned using 
dataname
. This
is the standard parameter used for all data feeds to pass the

name/ticker
. In this case it is reused to assign a common name to
the complete set of rolled over futures.

In the case of 
cerebro.rolloverdata
, the name is assigned to a
feed using 
name
, which is already one named argument of that method

Bottomline:

Data Feeds are created as usual but 
ARE NOT
 added to 
cerebro

Those data feeds are given as input to 
bt.feeds.RollOver

A 
dataname
 is also given, mostly for identification purposes.

This 
roll over
 data feed is then added to 
cerebro

Options for the Roll-Over

Two parameters are provided to control the roll-over process

checkdate
 (default: 
None
)

This must be a 
callable
 with the following signature:

```
checkdate(dt, d):

```

Where:

dt
 is a 
datetime.datetime
 object

d
 is the current data feed for the active future

Expected Return Values:

True
: as long as the callable returns this, a switchover can happen
    to the next future

If a commodity expires on the 3
rd
 Friday of March, 
checkdate
 could
return 
True
 for the entire week in which the expiration takes
place.

False
: the expiration cannot take place

checkcondition
 (default: 
None
)

Note

This will only be called if 
checkdate
 has returned 
True

If 
None
 this will evaluate to 
True
 (execute roll over) internally

Else this must be a 
callable
 with this signature:

```
checkcondition(d0, d1)

```

Where:

d0
 is the current data feed for the active future

d1
 is the data feed for the next expiration

Expected Return Values:

True
: roll-over to the next future

Following with the example from 
checkdate
, this could say that the
roll-over can only happen if the 
volume
 from 
d0
 is already less
than the volume from 
d1

False
: the expiration cannot take place

Subclassing 
RollOver

If specifying the 
callables
 isn’t enough, there is always the chance to
subclass 
RollOver
. The methods to subclass:

def _checkdate(self, dt, d):

Which matches the 
signature
 of the parameter of the same name above. The
expected return values are also the saame.

def _checkcondition(self, d0, d1)

Which matches the 
signature
 of the parameter of the same name above. The
expected return values are also the saame.

Let’s Roll

Note

The default behavior in the sample is to use

cerebro.rolloverdata
. This can be changed by passing the

-no-cerebro
 flag. In this case the sample uses 
RollOver
 and

cerebro.adddata

The implementation includes a sample which is available in the 
backtrader

sources.

Futures concatenation

Let’s start by looking at a pure concatenation by running the sample with no
arguments.

```
$ ./rollover.py

Len, Name, RollName, Datetime, WeekDay, Open, High, Low, Close, Volume, OpenInterest
0001, FESX, 199FESXM4, 2013-09-26, Thu, 2829.0, 2843.0, 2829.0, 2843.0, 3.0, 1000.0
0002, FESX, 199FESXM4, 2013-09-27, Fri, 2842.0, 2842.0, 2832.0, 2841.0, 16.0, 1101.0
...
0176, FESX, 199FESXM4, 2014-06-20, Fri, 3315.0, 3324.0, 3307.0, 3322.0, 134777.0, 520978.0
0177, FESX, 199FESXU4, 2014-06-23, Mon, 3301.0, 3305.0, 3265.0, 3285.0, 730211.0, 3003692.0
...
0241, FESX, 199FESXU4, 2014-09-19, Fri, 3287.0, 3308.0, 3286.0, 3294.0, 144692.0, 566249.0
0242, FESX, 199FESXZ4, 2014-09-22, Mon, 3248.0, 3263.0, 3231.0, 3240.0, 582077.0, 2976624.0
...
0306, FESX, 199FESXZ4, 2014-12-19, Fri, 3196.0, 3202.0, 3131.0, 3132.0, 226415.0, 677924.0
0307, FESX, 199FESXH5, 2014-12-22, Mon, 3151.0, 3177.0, 3139.0, 3168.0, 547095.0, 2952769.0
...
0366, FESX, 199FESXH5, 2015-03-20, Fri, 3680.0, 3698.0, 3672.0, 3695.0, 147632.0, 887205.0
0367, FESX, 199FESXM5, 2015-03-23, Mon, 3654.0, 3655.0, 3608.0, 3618.0, 802344.0, 3521988.0
...
0426, FESX, 199FESXM5, 2015-06-18, Thu, 3398.0, 3540.0, 3373.0, 3465.0, 1173246.0, 811805.0
0427, FESX, 199FESXM5, 2015-06-19, Fri, 3443.0, 3499.0, 3440.0, 3488.0, 104096.0, 516792.0

```

This uses 
cerebro.chaindata
 and the result should be clear:

Whenever a 
data feed
 is over the next one takes over

This happens always between a 
Friday
 and 
Monday
: the futures in the
    samples always expire on 
Friday

Futures roll-over with no checks

Let’s execute with 
--rollover

```
$ ./rollover.py --rollover --plot

Len, Name, RollName, Datetime, WeekDay, Open, High, Low, Close, Volume, OpenInterest
0001, FESX, 199FESXM4, 2013-09-26, Thu, 2829.0, 2843.0, 2829.0, 2843.0, 3.0, 1000.0
0002, FESX, 199FESXM4, 2013-09-27, Fri, 2842.0, 2842.0, 2832.0, 2841.0, 16.0, 1101.0
...
0176, FESX, 199FESXM4, 2014-06-20, Fri, 3315.0, 3324.0, 3307.0, 3322.0, 134777.0, 520978.0
0177, FESX, 199FESXU4, 2014-06-23, Mon, 3301.0, 3305.0, 3265.0, 3285.0, 730211.0, 3003692.0
...
0241, FESX, 199FESXU4, 2014-09-19, Fri, 3287.0, 3308.0, 3286.0, 3294.0, 144692.0, 566249.0
0242, FESX, 199FESXZ4, 2014-09-22, Mon, 3248.0, 3263.0, 3231.0, 3240.0, 582077.0, 2976624.0
...
0306, FESX, 199FESXZ4, 2014-12-19, Fri, 3196.0, 3202.0, 3131.0, 3132.0, 226415.0, 677924.0
0307, FESX, 199FESXH5, 2014-12-22, Mon, 3151.0, 3177.0, 3139.0, 3168.0, 547095.0, 2952769.0
...
0366, FESX, 199FESXH5, 2015-03-20, Fri, 3680.0, 3698.0, 3672.0, 3695.0, 147632.0, 887205.0
0367, FESX, 199FESXM5, 2015-03-23, Mon, 3654.0, 3655.0, 3608.0, 3618.0, 802344.0, 3521988.0
...
0426, FESX, 199FESXM5, 2015-06-18, Thu, 3398.0, 3540.0, 3373.0, 3465.0, 1173246.0, 811805.0
0427, FESX, 199FESXM5, 2015-06-19, Fri, 3443.0, 3499.0, 3440.0, 3488.0, 104096.0, 516792.0

```

The same behavior. It can clearly be seen that contract changes are being made
on the 3
rd
 Friday of either Mar, Jun, Sep, Dec.

But this is mostly WRONG. 
backtrader
 cannot know it, but the author knows that
the 
EuroStoxx 50
 futures stop trading at 
12:00
 CET. So even if there is a
daily bar for the 3
rd
 Friday of the expiration month, the change is happening
too late.

Changing during the Week

A 
checkdate
 callable is implemented in the sample, which calculates the date
of expiration for the currently active contract.

checkdate
 will allow a roll over as soon as the week of the 3
rd
 Friday of
the month is reached (it may be 
Tuesday
 if for example 
Monday
 is a bank holiday)

```
$ ./rollover.py --rollover --checkdate --plot

Len, Name, RollName, Datetime, WeekDay, Open, High, Low, Close, Volume, OpenInterest
0001, FESX, 199FESXM4, 2013-09-26, Thu, 2829.0, 2843.0, 2829.0, 2843.0, 3.0, 1000.0
0002, FESX, 199FESXM4, 2013-09-27, Fri, 2842.0, 2842.0, 2832.0, 2841.0, 16.0, 1101.0
...
0171, FESX, 199FESXM4, 2014-06-13, Fri, 3283.0, 3292.0, 3253.0, 3276.0, 734907.0, 2715357.0
0172, FESX, 199FESXU4, 2014-06-16, Mon, 3261.0, 3275.0, 3252.0, 3262.0, 180608.0, 844486.0
...
0236, FESX, 199FESXU4, 2014-09-12, Fri, 3245.0, 3247.0, 3220.0, 3232.0, 650314.0, 2726874.0
0237, FESX, 199FESXZ4, 2014-09-15, Mon, 3209.0, 3224.0, 3203.0, 3221.0, 153448.0, 983793.0
...
0301, FESX, 199FESXZ4, 2014-12-12, Fri, 3127.0, 3143.0, 3038.0, 3042.0, 1409834.0, 2934179.0
0302, FESX, 199FESXH5, 2014-12-15, Mon, 3041.0, 3089.0, 2963.0, 2980.0, 329896.0, 904053.0
...
0361, FESX, 199FESXH5, 2015-03-13, Fri, 3657.0, 3680.0, 3627.0, 3670.0, 867678.0, 3499116.0
0362, FESX, 199FESXM5, 2015-03-16, Mon, 3594.0, 3641.0, 3588.0, 3629.0, 250445.0, 1056099.0
...
0426, FESX, 199FESXM5, 2015-06-18, Thu, 3398.0, 3540.0, 3373.0, 3465.0, 1173246.0, 811805.0
0427, FESX, 199FESXM5, 2015-06-19, Fri, 3443.0, 3499.0, 3440.0, 3488.0, 104096.0, 516792.0

```

Much better
. The roll over is now happening 
5 days before
. A quick visual
inspection of the 
Len
 indices show it. For example:

199FESXM4
 to 
199FESXU4
 happens at 
len

171-172
. Without

checkdate
 it happened at 
176-177

The roll over is happening on the Monday before the 3
rd
 Friday of the
expiration month.

Adding a volume condition

Even with the improvement, the situation can be further improved in that not
only the date but also de negotiated 
volume
 will be taken into account. Do
switch when the new contract trades more volume than the currently active one.

Let’s add a 
checkcondition
 to the mix and run.

```
$ ./rollover.py --rollover --checkdate --checkcondition --plot

Len, Name, RollName, Datetime, WeekDay, Open, High, Low, Close, Volume, OpenInterest
0001, FESX, 199FESXM4, 2013-09-26, Thu, 2829.0, 2843.0, 2829.0, 2843.0, 3.0, 1000.0
0002, FESX, 199FESXM4, 2013-09-27, Fri, 2842.0, 2842.0, 2832.0, 2841.0, 16.0, 1101.0
...
0175, FESX, 199FESXM4, 2014-06-19, Thu, 3307.0, 3330.0, 3300.0, 3321.0, 717979.0, 759122.0
0176, FESX, 199FESXU4, 2014-06-20, Fri, 3309.0, 3318.0, 3290.0, 3298.0, 711627.0, 2957641.0
...
0240, FESX, 199FESXU4, 2014-09-18, Thu, 3249.0, 3275.0, 3243.0, 3270.0, 846600.0, 803202.0
0241, FESX, 199FESXZ4, 2014-09-19, Fri, 3273.0, 3293.0, 3250.0, 3252.0, 1042294.0, 3021305.0
...
0305, FESX, 199FESXZ4, 2014-12-18, Thu, 3095.0, 3175.0, 3085.0, 3172.0, 1309574.0, 889112.0
0306, FESX, 199FESXH5, 2014-12-19, Fri, 3195.0, 3200.0, 3106.0, 3147.0, 1329040.0, 2964538.0
...
0365, FESX, 199FESXH5, 2015-03-19, Thu, 3661.0, 3691.0, 3646.0, 3668.0, 1271122.0, 1054639.0
0366, FESX, 199FESXM5, 2015-03-20, Fri, 3607.0, 3664.0, 3595.0, 3646.0, 1182235.0, 3407004.0
...
0426, FESX, 199FESXM5, 2015-06-18, Thu, 3398.0, 3540.0, 3373.0, 3465.0, 1173246.0, 811805.0
0427, FESX, 199FESXM5, 2015-06-19, Fri, 3443.0, 3499.0, 3440.0, 3488.0, 104096.0, 516792.0

```

Even better
. We have moved the switch date to the 
Thursday
 before the well
known 
3
rd
 Friday of the expiration month

This should come to no surprise because the expiring future trades a lot less
hours on that 
Friday
 and the volume must be small.

Note

The roll over date could have also been set to that 
Thursday
 by the

checkdate
 callable. But that isn’t the point of the sample.

Concluding

backtrader
 includes now a flexible mechanism to allow rolling over futures to
create a continuous stream.

Sample Usage

```
$ ./rollover.py --help
usage: rollover.py [-h] [--no-cerebro] [--rollover] [--checkdate]
                   [--checkcondition] [--plot [kwargs]]

Sample for Roll Over of Futures

optional arguments:
  -h, --help            show this help message and exit
  --no-cerebro          Use RollOver Directly (default: False)
  --rollover
  --checkdate           Change during expiration week (default: False)
  --checkcondition      Change when a given condition is met (default: False)
  --plot [kwargs], -p [kwargs]
                        Plot the read data applying any kwargs passed For
                        example: --plot style="candle" (to plot candles)
                        (default: None)

```

Sample Code

```
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import argparse
import bisect
import calendar
import datetime

import backtrader as bt

class TheStrategy(bt.Strategy):
    def start(self):
        header = ['Len', 'Name', 'RollName', 'Datetime', 'WeekDay', 'Open',
                  'High', 'Low', 'Close', 'Volume', 'OpenInterest']
        print(', '.join(header))

    def next(self):
        txt = list()
        txt.append('%04d' % len(self.data0))
        txt.append('{}'.format(self.data0._dataname))
        # Internal knowledge ... current expiration in use is in _d
        txt.append('{}'.format(self.data0._d._dataname))
        txt.append('{}'.format(self.data.datetime.date()))
        txt.append('{}'.format(self.data.datetime.date().strftime('%a')))
        txt.append('{}'.format(self.data.open[0]))
        txt.append('{}'.format(self.data.high[0]))
        txt.append('{}'.format(self.data.low[0]))
        txt.append('{}'.format(self.data.close[0]))
        txt.append('{}'.format(self.data.volume[0]))
        txt.append('{}'.format(self.data.openinterest[0]))
        print(', '.join(txt))

def checkdate(dt, d):
    # Check if the date is in the week where the 3rd friday of Mar/Jun/Sep/Dec

    # EuroStoxx50 expiry codes: MY
    # M -> H, M, U, Z (Mar, Jun, Sep, Dec)
    # Y -> 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 -> year code. 5 -> 2015
    MONTHS = dict(H=3, M=6, U=9, Z=12)

    M = MONTHS[d._dataname[-2]]

    centuria, year = divmod(dt.year, 10)
    decade = centuria * 10

    YCode = int(d._dataname[-1])
    Y = decade + YCode
    if Y < dt.year:  # Example: year 2019 ... YCode is 0 for 2020
        Y += 10

    exp_day = 21 - (calendar.weekday(Y, M, 1) + 2) % 7
    exp_dt = datetime.datetime(Y, M, exp_day)

    # Get the year, week numbers
    exp_year, exp_week, _ = exp_dt.isocalendar()
    dt_year, dt_week, _ = dt.isocalendar()

    # print('dt {} vs {} exp_dt'.format(dt, exp_dt))
    # print('dt_week {} vs {} exp_week'.format(dt_week, exp_week))

    # can switch if in same week
    return (dt_year, dt_week) == (exp_year, exp_week)

def checkvolume(d0, d1):
    return d0.volume[0] < d1.volume[0]  # Switch if volume from d0 < d1

def runstrat(args=None):
    args = parse_args(args)

    cerebro = bt.Cerebro()

    fcodes = ['199FESXM4', '199FESXU4', '199FESXZ4', '199FESXH5', '199FESXM5']
    store = bt.stores.VChartFile()
    ffeeds = [store.getdata(dataname=x) for x in fcodes]

    rollkwargs = dict()
    if args.checkdate:
        rollkwargs['checkdate'] = checkdate

        if args.checkcondition:
            rollkwargs['checkcondition'] = checkvolume

    if not args.no_cerebro:
        if args.rollover:
            cerebro.rolloverdata(name='FESX', *ffeeds, **rollkwargs)
        else:
            cerebro.chaindata(name='FESX', *ffeeds)
    else:
        drollover = bt.feeds.RollOver(*ffeeds, dataname='FESX', **rollkwargs)
        cerebro.adddata(drollover)

    cerebro.addstrategy(TheStrategy)
    cerebro.run(stdstats=False)

    if args.plot:
        pkwargs = dict(style='bar')
        if args.plot is not True:  # evals to True but is not True
            npkwargs = eval('dict(' + args.plot + ')')  # args were passed
            pkwargs.update(npkwargs)

        cerebro.plot(**pkwargs)

def parse_args(pargs=None):

    parser = argparse.ArgumentParser(
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
        description='Sample for Roll Over of Futures')

    parser.add_argument('--no-cerebro', required=False, action='store_true',
                        help='Use RollOver Directly')

    parser.add_argument('--rollover', required=False, action='store_true')

    parser.add_argument('--checkdate', required=False, action='store_true',
                        help='Change during expiration week')

    parser.add_argument('--checkcondition', required=False,
                        action='store_true',
                        help='Change when a given condition is met')

    # Plot options
    parser.add_argument('--plot', '-p', nargs='?', required=False,
                        metavar='kwargs', const=True,
                        help=('Plot the read data applying any kwargs passed\n'
                              '\n'
                              'For example:\n'
                              '\n'
                              '  --plot style="candle" (to plot candles)\n'))

    if pargs is not None:
        return parser.parse_args(pargs)

    return parser.parse_args()

if __name__ == '__main__':
    runstrat()

```
########################################
docu-dataautoref.txt - lunghezza: 30716
########################################
Data Feeds Reference

AbstractDataBase

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

```

BacktraderCSVData

Parses a self-defined CSV Data used for testing.

Specific parameters:

dataname
: The filename to parse or a file-like object

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* headers (True)

* separator (,)

```

CSVDataBase

Base class for classes implementing CSV DataFeeds

The class takes care of opening the file, reading the lines and
tokenizing them.

Subclasses do only need to override:

_loadline(tokens)

The return value of 
_loadline
 (True/False) will be the return value
of 
_load
 which has been overriden by this base class

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* headers (True)

* separator (,)

```

Chainer

Class that chains datas

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

```

DataClone

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

```

DataFiller

This class will fill gaps in the source data using the following
information bits from the underlying data source

timeframe and compression to dimension the output bars

sessionstart and sessionend

If a data feed has missing bars in between 10:31 and 10:34 and the
timeframe is minutes, the output will be filled with bars for minutes
10:32 and 10:33 using the closing price of the last bar (10:31)

Bars can be missinga amongst other things because

Params:

```
* `fill_price` (def: None): if None (or evaluates to False),the
  closing price will be used, else the passed value (which can be
  for example ‘NaN’ to have a missing bar in terms of evaluation but
  present in terms of time

* `fill_vol` (def: NaN): used to fill the volume of missing bars

* `fill_oi` (def: NaN): used to fill the openinterest of missing bars

```

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* fill_price (None)

* fill_vol (nan)

* fill_oi (nan)

```

DataFilter

This class filters out bars from a given data source. In addition to the
standard parameters of a DataBase it takes a 
funcfilter
 parameter which
can be any callable

Logic:

funcfilter
 will be called with the underlying data source

It can be any callable

Return value 
True
: current data source bar values will used

Return value 
False
: current data source bar values will discarded

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* funcfilter (None)

```

GenericCSVData

Parses a CSV file according to the order and field presence defined by the
parameters

Specific parameters (or specific meaning):

dataname
: The filename to parse or a file-like object

The lines parameters (datetime, open, high …) take numeric values

A value of -1 indicates absence of that field in the CSV source

If 
time
 is present (parameter time >=0) the source contains
    separated fields for date and time, which will be combined

nullvalue

Value that will be used if a value which should be there is missing
(the CSV field is empty)

dtformat
: Format used to parse the datetime CSV field. See the
    python strptime/strftime documentation for the format.

If a numeric value is specified, it will be interpreted as follows

1
: The value is a Unix timestamp of type 
int
 representing
    the number of seconds since Jan 1
st
, 1970

2
: The value is a Unix timestamp of type 
float

If a 
callable
 is passed

it will accept a string and return a datetime.datetime python
    instance

tmformat
: Format used to parse the time CSV field if “present”
    (the default for the “time” CSV field is not to be present)

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* headers (True)

* separator (,)

* nullvalue (nan)

* dtformat (%Y-%m-%d %H:%M:%S)

* tmformat (%H:%M:%S)

* datetime (0)

* time (-1)

* open (1)

* high (2)

* low (3)

* close (4)

* volume (5)

* openinterest (6)

```

IBData

Interactive Brokers Data Feed.

Supports the following contract specifications in parameter 
dataname
:

TICKER  # Stock type and SMART exchange

TICKER-STK  # Stock and SMART exchange

TICKER-STK-EXCHANGE  # Stock

TICKER-STK-EXCHANGE-CURRENCY  # Stock

TICKER-CFD  # CFD and SMART exchange

TICKER-CFD-EXCHANGE  # CFD

TICKER-CDF-EXCHANGE-CURRENCY  # Stock

TICKER-IND-EXCHANGE  # Index

TICKER-IND-EXCHANGE-CURRENCY  # Index

TICKER-YYYYMM-EXCHANGE  # Future

TICKER-YYYYMM-EXCHANGE-CURRENCY  # Future

TICKER-YYYYMM-EXCHANGE-CURRENCY-MULT  # Future

TICKER-FUT-EXCHANGE-CURRENCY-YYYYMM-MULT # Future

TICKER-YYYYMM-EXCHANGE-CURRENCY-STRIKE-RIGHT  # FOP

TICKER-YYYYMM-EXCHANGE-CURRENCY-STRIKE-RIGHT-MULT  # FOP

TICKER-FOP-EXCHANGE-CURRENCY-YYYYMM-STRIKE-RIGHT # FOP

TICKER-FOP-EXCHANGE-CURRENCY-YYYYMM-STRIKE-RIGHT-MULT # FOP

CUR1.CUR2-CASH-IDEALPRO  # Forex

TICKER-YYYYMMDD-EXCHANGE-CURRENCY-STRIKE-RIGHT  # OPT

TICKER-YYYYMMDD-EXCHANGE-CURRENCY-STRIKE-RIGHT-MULT  # OPT

TICKER-OPT-EXCHANGE-CURRENCY-YYYYMMDD-STRIKE-RIGHT # OPT

TICKER-OPT-EXCHANGE-CURRENCY-YYYYMMDD-STRIKE-RIGHT-MULT # OPT

Params:

sectype
 (default: 
STK
)

Default value to apply as 
security type
 if not provided in the

dataname
 specification

exchange
 (default: 
SMART
)

Default value to apply as 
exchange
 if not provided in the

dataname
 specification

currency
 (default: 
''
)

Default value to apply as 
currency
 if not provided in the

dataname
 specification

historical
 (default: 
False
)

If set to 
True
 the data feed will stop after doing the first
download of data.

The standard data feed parameters 
fromdate
 and 
todate
 will be
used as reference.

The data feed will make multiple requests if the requested duration is
larger than the one allowed by IB given the timeframe/compression
chosen for the data.

what
 (default: 
None
)

If 
None
 the default for different assets types will be used for
historical data requests:

‘BID’ for CASH assets

‘TRADES’ for any other

Check the IB API docs if another value is wished

rtbar
 (default: 
False
)

If 
True
 the 
5 Seconds Realtime bars
 provided by Interactive
Brokers will be used as the smalles tick. According to the
documentation they correspond to real-time values (once collated and
curated by IB)

If 
False
 then the 
RTVolume
 prices will be used, which are based
on receiving ticks. In the case of 
CASH
 assets (like for example
EUR.JPY) 
RTVolume
 will always be used and from it the 
bid
 price
(industry de-facto standard with IB according to the literature
scattered over the Internet)

Even if set to 
True
, if the data is resampled/kept to a
timeframe/compression below Seconds/5, no real time bars will be used,
because IB doesn’t serve them below that level

qcheck
 (default: 
0.5
)

Time in seconds to wake up if no data is received to give a chance to
resample/replay packets properly and pass notifications up the chain

backfill_start
 (default: 
True
)

Perform backfilling at the start. The maximum possible historical data
will be fetched in a single request.

backfill
 (default: 
True
)

Perform backfilling after a disconnection/reconnection cycle. The gap
duration will be used to download the smallest possible amount of data

backfill_from
 (default: 
None
)

An additional data source can be passed to do an initial layer of
backfilling. Once the data source is depleted and if requested,
backfilling from IB will take place. This is ideally meant to backfill
from already stored sources like a file on disk, but not limited to.

latethrough
 (default: 
False
)

If the data source is resampled/replayed, some ticks may come in too
late for the already delivered resampled/replayed bar. If this is

True
 those ticks will bet let through in any case.

Check the Resampler documentation to see who to take those ticks into
account.

This can happen especially if 
timeoffset
 is set to 
False
  in
the 
IBStore
 instance and the TWS server time is not in sync with
that of the local computer

tradename
 (default: 
None
)
    Useful for some specific cases like 
CFD
 in which prices are offered
    by one asset and trading happens in a different onel

SPY-STK-SMART-USD -> SP500 ETF (will be specified as 
dataname
)

SPY-CFD-SMART-USD -> which is the corresponding CFD which offers not
  price tracking but in this case will be the trading asset (specified
  as 
tradename
)

The default values in the params are the to allow things like 
\
TICKER
,
to which the parameter
sectype
(default:
STK
) and
exchange
(default:
SMART`) are applied.

Some assets like 
AAPL
 need full specification including 
currency

(default: ‘’) whereas others like 
TWTR
 can be simply passed as it is.

AAPL-STK-SMART-USD
 would be the full specification for dataname

Or else: 
IBData
 as 
IBData(dataname='AAPL', currency='USD')

which uses the default values (
STK
 and 
SMART
) and overrides
the currency to be 
USD

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.5)

* calendar (None)

* sectype (STK)

* exchange (SMART)

* currency ()

* rtbar (False)

* historical (False)

* what (None)

* useRTH (False)

* backfill_start (True)

* backfill (True)

* backfill_from (None)

* latethrough (False)

* tradename (None)

```

InfluxDB

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* host (127.0.0.1)

* port (8086)

* username (None)

* password (None)

* database (None)

* startdate (None)

* high (high_p)

* low (low_p)

* open (open_p)

* close (close_p)

* volume (volume)

* ointerest (oi)

```

MT4CSVData

Parses a 
Metatrader4
 History
center CSV exported file.

Specific parameters (or specific meaning):

dataname
: The filename to parse or a file-like object

Uses GenericCSVData and simply modifies the params

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* headers (True)

* separator (,)

* nullvalue (nan)

* dtformat (%Y.%m.%d)

* tmformat (%H:%M)

* datetime (0)

* time (1)

* open (2)

* high (3)

* low (4)

* close (5)

* volume (6)

* openinterest (-1)

```

OandaData

Oanda Data Feed.

Params:

qcheck
 (default: 
0.5
)

Time in seconds to wake up if no data is received to give a chance to
resample/replay packets properly and pass notifications up the chain

historical
 (default: 
False
)

If set to 
True
 the data feed will stop after doing the first
download of data.

The standard data feed parameters 
fromdate
 and 
todate
 will be
used as reference.

The data feed will make multiple requests if the requested duration is
larger than the one allowed by IB given the timeframe/compression
chosen for the data.

backfill_start
 (default: 
True
)

Perform backfilling at the start. The maximum possible historical data
will be fetched in a single request.

backfill
 (default: 
True
)

Perform backfilling after a disconnection/reconnection cycle. The gap
duration will be used to download the smallest possible amount of data

backfill_from
 (default: 
None
)

An additional data source can be passed to do an initial layer of
backfilling. Once the data source is depleted and if requested,
backfilling from IB will take place. This is ideally meant to backfill
from already stored sources like a file on disk, but not limited to.

bidask
 (default: 
True
)

If 
True
, then the historical/backfilling requests will request
bid/ask prices from the server

If 
False
, then 
midpoint
 will be requested

useask
 (default: 
False
)

If 
True
 the 
ask
 part of the 
bidask
 prices will be used instead
of the default use of 
bid

includeFirst
 (default: 
True
)

Influence the delivery of the 1
st
 bar of a historical/backfilling
request by setting the parameter directly to the Oanda API calls

reconnect
 (default: 
True
)

Reconnect when network connection is down

reconnections
 (default: 
-1
)

Number of times to attempt reconnections: 
-1
 means forever

reconntimeout
 (default: 
5.0
)

Time in seconds to wait in between reconnection attemps

This data feed supports only this mapping of 
timeframe
 and

compression
, which comply with the definitions in the OANDA API
Developer’s Guid:

```
(TimeFrame.Seconds, 5): 'S5',
(TimeFrame.Seconds, 10): 'S10',
(TimeFrame.Seconds, 15): 'S15',
(TimeFrame.Seconds, 30): 'S30',
(TimeFrame.Minutes, 1): 'M1',
(TimeFrame.Minutes, 2): 'M3',
(TimeFrame.Minutes, 3): 'M3',
(TimeFrame.Minutes, 4): 'M4',
(TimeFrame.Minutes, 5): 'M5',
(TimeFrame.Minutes, 10): 'M10',
(TimeFrame.Minutes, 15): 'M15',
(TimeFrame.Minutes, 30): 'M30',
(TimeFrame.Minutes, 60): 'H1',
(TimeFrame.Minutes, 120): 'H2',
(TimeFrame.Minutes, 180): 'H3',
(TimeFrame.Minutes, 240): 'H4',
(TimeFrame.Minutes, 360): 'H6',
(TimeFrame.Minutes, 480): 'H8',
(TimeFrame.Days, 1): 'D',
(TimeFrame.Weeks, 1): 'W',
(TimeFrame.Months, 1): 'M',

```

Any other combination will be rejected

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.5)

* calendar (None)

* historical (False)

* backfill_start (True)

* backfill (True)

* backfill_from (None)

* bidask (True)

* useask (False)

* includeFirst (True)

* reconnect (True)

* reconnections (-1)

* reconntimeout (5.0)

```

PandasData

Uses a Pandas DataFrame as the feed source, using indices into column
names (which can be “numeric”)

This means that all parameters related to lines must have numeric
values as indices into the tuples

Params:

nocase
 (default 
True
) case insensitive match of column names

Note:

The 
dataname
 parameter is a Pandas DataFrame

Values possible for datetime

None: the index contains the datetime

-1: no index, autodetect column

= 0 or string: specific colum identifier

For other lines parameters

None: column not present

-1: autodetect

= 0 or string: specific colum identifier

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* nocase (True)

* datetime (None)

* open (-1)

* high (-1)

* low (-1)

* close (-1)

* volume (-1)

* openinterest (-1)

```

PandasDirectData

Uses a Pandas DataFrame as the feed source, iterating directly over the
tuples returned by “itertuples”.

This means that all parameters related to lines must have numeric
values as indices into the tuples

Note:

The 
dataname
 parameter is a Pandas DataFrame

A negative value in any of the parameters for the Data lines
    indicates it’s not present in the DataFrame
    it is

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* datetime (0)

* open (1)

* high (2)

* low (3)

* close (4)

* volume (5)

* openinterest (6)

```

Quandl

Executes a direct download of data from Quandl servers for the given time
range.

Specific parameters (or specific meaning):

dataname

The ticker to download (‘YHOO’ for example)

baseurl

The server url. Someone might decide to open a Quandl compatible
service in the future.

proxies

A dict indicating which proxy to go through for the download as in
{‘http’: ‘
http://myproxy.com
’} or {‘http’: ‘
http://127.0.0.1:8080
’}

buffered

If True the entire socket connection wil be buffered locally before
parsing starts.

reverse

Quandl returns the value in descending order (newest first). If this is

True
 (the default), the request will tell Quandl to return in
ascending (oldest to newest) format

adjclose

Whether to use the dividend/split adjusted close and adjust all values
according to it.

apikey

apikey identification in case it may be needed

dataset

string identifying the dataset to query. Defaults to 
WIKI

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* headers (True)

* separator (,)

* reverse (True)

* adjclose (True)

* round (False)

* decimals (2)

* baseurl ([https://www.quandl.com/api/v3/datasets](https://www.quandl.com/api/v3/datasets))

* proxies ({})

* buffered (True)

* apikey (None)

* dataset (WIKI)

```

QuandlCSV

Parses pre-downloaded Quandl CSV Data Feeds (or locally generated if they
comply to the Quandl format)

Specific parameters:

dataname
: The filename to parse or a file-like object

reverse
 (default: 
False
)

It is assumed that locally stored files have already been reversed
during the download process

adjclose
 (default: 
True
)

Whether to use the dividend/split adjusted close and adjust all
values according to it.

round
 (default: 
False
)

Whether to round the values to a specific number of decimals after
having adjusted the close

decimals
 (default: 
2
)

Number of decimals to round to

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* headers (True)

* separator (,)

* reverse (False)

* adjclose (True)

* round (False)

* decimals (2)

```

RollOver

Class that rolls over to the next future when a condition is met

Params:

checkdate
 (default: 
None
)

This must be a 
callable
 with the following signature:

```
checkdate(dt, d):

```

Where:

dt
 is a 
datetime.datetime
 object

d
 is the current data feed for the active future

Expected Return Values:

True
: as long as the callable returns this, a switchover can
    happen to the next future

If a commodity expires on the 3
rd
 Friday of March, 
checkdate
 could
  return 
True
 for the entire week in which the expiration takes
  place.

```
* `False`: the expiration cannot take place

```

checkcondition
 (default: 
None
)

Note
: This will only be called if 
checkdate
 has returned

True

If 
None
 this will evaluate to 
True
 (execute roll over)
internally

Else this must be a 
callable
 with this signature:

```
checkcondition(d0, d1)

```

Where:

d0
 is the current data feed for the active future

d1
 is the data feed for the next expiration

Expected Return Values:

True
: roll-over to the next future

Following with the example from 
checkdate
, this could say that the
  roll-over can only happend if the 
volume
 from 
d0
 is already less
  than the volume from 
d1

```
* `False`: the expiration cannot take place

```

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* checkdate (None)

* checkcondition (None)

```

SierraChartCSVData

Parses a 
SierraChart
 CSV exported file.

Specific parameters (or specific meaning):

dataname
: The filename to parse or a file-like object

Uses GenericCSVData and simply modifies the dateformat (dtformat) to

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* headers (True)

* separator (,)

* nullvalue (nan)

* dtformat (%Y/%m/%d)

* tmformat (%H:%M:%S)

* datetime (0)

* time (-1)

* open (1)

* high (2)

* low (3)

* close (4)

* volume (5)

* openinterest (6)

```

VCData

VisualChart Data Feed.

Params:

qcheck
 (default: 
0.5
)
    Default timeout for waking up to let a resampler/replayer that the
    current bar can be check for due delivery

The value is only used if a resampling/replaying filter has been
inserted in the data

historical
 (default: 
False
)
    If no 
todate
 parameter is supplied (defined in the base class),
    this will force a historical only download if set to 
True

If 
todate
 is supplied the same effect is achieved

milliseconds
 (default: 
True
)
    The bars constructed by 
Visual Chart
 have this aspect:
    HH:MM:59.999000

If this parameter is 
True
 a millisecond will be added to this time
to make it look like: HH::MM + 1:00.000000

tradename
 (default: 
None
)
    Continous futures cannot be traded but are ideal for data tracking. If
    this parameter is supplied it will be the name of the current future
    which will be the trading asset. Example:

001ES -> ES-Mini continuous supplied as 
dataname

ESU16 -> ES-Mini 2016-09. If this is supplied in 
tradename
 it
  will be the trading asset.

usetimezones
 (default: 
True
)
    For most markets the time offset information provided by 
Visual Chart

    allows for datetime to be converted to market time (
backtrader
 choice
    for representation)

Some markets are special (
096
) and need special internal coverage
and timezone support to display in the user expected market time.

If this parameter is set to 
True
 importing 
pytz
 will be
attempted to use timezones (default)

Disabling it will remove timezone usage (may help if the load is
excesive)

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.5)

* calendar (None)

* historical (False)

* millisecond (True)

* tradename (None)

* usetimezones (True)

```

VChartCSVData

Parses a 
VisualChart
 CSV exported file.

Specific parameters (or specific meaning):

dataname
: The filename to parse or a file-like object

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* headers (True)

* separator (,)

```

VChartData

Support for 
Visual Chart
 binary on-disk files for
both daily and intradaily formats.

Note:

dataname
: to file or open file-like object

If a file-like object is passed, the 
timeframe
 parameter will be
used to determine which is the actual timeframe.

Else the file extension (
.fd
 for daily and 
.min
 for intraday)
will be used.

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

```

VChartFile

Support for 
Visual Chart
 binary on-disk files for
both daily and intradaily formats.

Note:

dataname
: Market code displayed by Visual Chart. Example: 015ES for
    EuroStoxx 50 continuous future

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

```

YahooFinanceCSVData

Parses pre-downloaded Yahoo CSV Data Feeds (or locally generated if they
comply to the Yahoo format)

Specific parameters:

dataname
: The filename to parse or a file-like object

reverse
 (default: 
False
)

It is assumed that locally stored files have already been reversed
during the download process

adjclose
 (default: 
True
)

Whether to use the dividend/split adjusted close and adjust all
values according to it.

adjvolume
 (default: 
True
)

Do also adjust 
volume
 if 
adjclose
 is also 
True

round
 (default: 
True
)

Whether to round the values to a specific number of decimals after
having adjusted the close

roundvolume
 (default: 
0
)

Round the resulting volume to the given number of decimals after having
adjusted it

decimals
 (default: 
2
)

Number of decimals to round to

swapcloses
 (default: 
False
)

[2018-11-16] It would seem that the order of 
close
 and 
adjusted
close
 is now fixed. The parameter is retained, in case the need to
swap the columns again arose.

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

* adjclose

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* headers (True)

* separator (,)

* reverse (False)

* adjclose (True)

* adjvolume (True)

* round (True)

* decimals (2)

* roundvolume (False)

* swapcloses (False)

```

YahooFinanceData

Executes a direct download of data from Yahoo servers for the given time
range.

Specific parameters (or specific meaning):

dataname

The ticker to download (‘YHOO’ for Yahoo own stock quotes)

proxies

A dict indicating which proxy to go through for the download as in
{‘http’: ‘
http://myproxy.com
’} or {‘http’: ‘
http://127.0.0.1:8080
’}

period

The timeframe to download data in. Pass ‘w’ for weekly and ‘m’ for
monthly.

reverse

[2018-11-16] The latest incarnation of Yahoo online downloads returns
the data in the proper order. The default value of 
reverse
 for the
online download is therefore set to 
False

adjclose

Whether to use the dividend/split adjusted close and adjust all values
according to it.

urlhist

The url of the historical quotes in Yahoo Finance used to gather a

crumb
 authorization cookie for the download

urldown

The url of the actual download server

retries

Number of times (each) to try to get a 
crumb
 cookie and download
the data

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

* adjclose

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* headers (True)

* separator (,)

* reverse (False)

* adjclose (True)

* adjvolume (True)

* round (True)

* decimals (2)

* roundvolume (False)

* swapcloses (False)

* proxies ({})

* period (d)

* urlhist ([https://finance.yahoo.com/quote](https://finance.yahoo.com/quote)/{}/history)

* urldown ([https://query1.finance.yahoo.com/v7/finance/download](https://query1.finance.yahoo.com/v7/finance/download))

* retries (3)

```

YahooLegacyCSV

This is intended to load files which were downloaded before Yahoo
discontinued the original service in May-2017

Lines:

```
* close

* low

* high

* open

* volume

* openinterest

* datetime

* adjclose

```

Params:

```
* dataname (None)

* name ()

* compression (1)

* timeframe (5)

* fromdate (None)

* todate (None)

* sessionstart (None)

* sessionend (None)

* filters ([])

* tz (None)

* tzinput (None)

* qcheck (0.0)

* calendar (None)

* headers (True)

* separator (,)

* reverse (False)

* adjclose (True)

* adjvolume (True)

* round (True)

* decimals (2)

* roundvolume (False)

* swapcloses (False)

* version ()

```
########################################
docu-datafeed-develop-csv.txt - lunghezza: 4889
########################################
CSV Data Feed Development

backtrader
 already offers a Generic CSV Data feed and some specific CSV Data
Feeds. Summarizing:

GenericCSVData

VisualChartCSVData

YahooFinanceData (for online downloads)

YahooFinanceCSVData (for already downloaded data)

BacktraderCSVData (in-house … for testing purposed, but can be used)

But even with that, the end user may wish to develop support for a specific CSV
Data Feed.

The usual motto would be: “It’s easier said than done”. Actually the structure
is meant to make it easy.

Steps:

Inherit from 
backtrader.CSVDataBase

Define any 
params
 if needed

Do any initialization in the 
start
 method

Do any clean-up in the 
stop
 method

Define a 
_loadline
 method where the actual work happens

This method receives a single argument: linetokens.

As the name suggests this contains the tokens after the current line has
been splitten according to the 
separator
 parameter (inherited from the
base class)

If after doing its work there is new data … fill up the corresponding
lines and return 
True

If nothing is available and therefore the parsing has come to an end: return

False

Returning 
False
 may not even be needed if the behind the scenes code
which is reading the file lines finds out there are no more lines to parse.

Things which are already taken into account:

Opening the file (or receiving a file-like object)

Skipping the headers row if indicated as present

Reading the lines

Tokenizing the lines

Preloading support (to load the entire data feed at once in memory)

Usually an example is worth a thousand requirement descriptions. Let’s use a
simplified version of the in-house defined CSV parsing code from

BacktraderCSVData
. This one needs no initialization or clean-up (this could
be opening a socket and closing it later, for example).

Note

backtrader
 data feeds contain the usual industry standard feeds, which
are the ones to be filled. Namely:

datetime

open

high

low

close

volume

openinterest

If your strategy/algorithm or simple data perusal only needs, for example the
closing prices you can leave the others untouched (each iteration fills them
automatically with a float(‘NaN’) value before the end user code has a chance
to do anything.

In this example only a daily format is supported:

```
import itertools
...
import backtrader as bt

class MyCSVData(bt.CSVDataBase):

    def start(self):
        # Nothing to do for this data feed type
        pass

    def stop(self):
        # Nothing to do for this data feed type
        pass

    def _loadline(self, linetokens):
        i = itertools.count(0)

        dttxt = linetokens[next(i)]
        # Format is YYYY-MM-DD
        y = int(dttxt[0:4])
        m = int(dttxt[5:7])
        d = int(dttxt[8:10])

        dt = datetime.datetime(y, m, d)
        dtnum = date2num(dt)

        self.lines.datetime[0] = dtnum
        self.lines.open[0] = float(linetokens[next(i)])
        self.lines.high[0] = float(linetokens[next(i)])
        self.lines.low[0] = float(linetokens[next(i)])
        self.lines.close[0] = float(linetokens[next(i)])
        self.lines.volume[0] = float(linetokens[next(i)])
        self.lines.openinterest[0] = float(linetokens[next(i)])

        return True

```

The code expects all fields to be in place and be convertible to floats, except
for the datetime which has a fixed YYYY-MM-DD format and can be parsed without
using 
datetime.datetime.strptime
.

More complex needs can be covered by adding just a few lines of code to account
for null values, date format parsing. The 
GenericCSVData
 does that.

Caveat Emptor

Using the 
GenericCSVData
 existing feed and inheritance a lot can be
acomplished in order to support formats.

Let’s add support for 
Sierra Chart
 daily format (which
is always stored in CSV format).

Definition (by looking into one of the 
‘.dly’
 data files:

Fields
: Date, Open, High, Low, Close, Volume, OpenInterest

The industry standard ones and the ones already supported by

GenericCSVData
 in the same order (which is also industry standard)

Separator
: ,

Date Format
: YYYY/MM/DD

A parser for those files:

```
class SierraChartCSVData(backtrader.feeds.GenericCSVData):

    params = (('dtformat', '%Y/%m/%d'),)

```

The 
params
 definition simply redefines one of the existing parameters in the
base class. In this case just the formatting string for dates needs a change.

Et voilá … the parser for 
Sierra Chart
 is finished.

Here below the parameters definition of 
GenericCSVData
 as a reminder:

```
class GenericCSVData(feed.CSVDataBase):
    params = (
        ('nullvalue', float('NaN')),
        ('dtformat', '%Y-%m-%d %H:%M:%S'),
        ('tmformat', '%H:%M:%S'),

        ('datetime', 0),
        ('time', -1),
        ('open', 1),
        ('high', 2),
        ('low', 3),
        ('close', 4),
        ('volume', 5),
        ('openinterest', 6),
    )

```
########################################
docu-datafeed-develop-general-datafeed-develop-general.txt - lunghezza: 11132
########################################
Binary Datafeed Development

Note

The binary file used in the examples 
goog.fd
 belongs to VisualChart and
cannot be distributed with 
backtrader
.

VisualChart
 can be downloaded free of charge for
those interested in directly using the binary files.

CSV Data feed development has shown how to add new CSV based data
feeds. The existing base class CSVDataBase provides the framework
taking most of the work off the subclasses which in most cases can
simply do:

```
def _loadline(self, linetokens):

  # parse the linetokens here and put them in self.lines.close,
  # self.lines.high, etc

  return True # if data was parsed, else ... return False

```

The base class takes care of the parameters, initialization, opening of files,
reading lines, splitting the lines in tokens and additional things like skipping
lines which don’t fit into the date range (
fromdate
, 
todate
) which the
end user may have defined.

Developing a non-CSV datafeed follows the same pattern without going down to the
already splitted line tokens.

Things to do:

Derive from backtrader.feed.DataBase

Add any parameters you may need

Should initialization be needed, override 
__init__(self)
 and/or 
start(self)

Should any clean-up code be needed, override 
stop(self)

The work happens inside the method which MUST always be overriden: 
_load(self)

Let’s the parameters already provided by 
backtrader.feed.DataBase
:

```
from backtrader.utils.py3 import with_metaclass

...
...

class DataBase(with_metaclass(MetaDataBase, dataseries.OHLCDateTime)):

    params = (('dataname', None),
        ('fromdate', datetime.datetime.min),
        ('todate', datetime.datetime.max),
        ('name', ''),
        ('compression', 1),
        ('timeframe', TimeFrame.Days),
        ('sessionend', None))

```

Having the following meanings:

dataname
 is what allows the data feed to identify how to fetch the
    data. In the case of the 
CSVDataBase
 this parameter is meant to be a
    path to a file or already a file-like object.

fromdate
 and 
todate
 define the date range which will be passed to
    strategies. Any value provided by the feed outside of this range will be
    ignored

name
 is cosmetic for plotting purposes

timeframe
 indicates the temporal working reference

Potential values: 
Ticks
, 
Seconds
, 
Minutes
, 
Days
, 
Weeks
,

Months
 and 
Years

compression
 (default: 1)

Number of actual bars per bar. Informative. Only effective in Data
Resampling/Replaying.

compression

sessionend
 if passed (a datetime.time object) will be added to the
    datafeed 
datetime
 line which allows identifying the end of the session

Sample binary datafeed

backtrader
 already defines a CSV datafeed (
VChartCSVData
) for the
exports of 
VisualChart
, but it is also possible to
directly read the binary data files.

Let’s do it (full data feed code can be found at the bottom)

Initialization

The binary VisualChart data files can contain either daily (.fd extension) or
intraday data (.min extension). Here the parameter 
timeframe

will be used to distinguish which type of file is being read.

During 
__init__
 constants which differ for each type are set up.

```
    def __init__(self):
        super(VChartData, self).__init__()

        # Use the informative "timeframe" parameter to understand if the
        # code passed as "dataname" refers to an intraday or daily feed
        if self.p.timeframe >= TimeFrame.Days:
            self.barsize = 28
            self.dtsize = 1
            self.barfmt = 'IffffII'
        else:
            self.dtsize = 2
            self.barsize = 32
            self.barfmt = 'IIffffII'

```

Start

The Datafeed will be 
started
 when backtesting commences (it can actually be
started several times during optimizations)

In the 
start
 method the binary file is open unless a file-like object has
been passed.

```
    def start(self):
        # the feed must start ... get the file open (or see if it was open)
        self.f = None
        if hasattr(self.p.dataname, 'read'):
            # A file has been passed in (ex: from a GUI)
            self.f = self.p.dataname
        else:
            # Let an exception propagate
            self.f = open(self.p.dataname, 'rb')

```

Stop

Called when backtesting is finished.

If a file was open, it will be closed

```
    def stop(self):
        # Close the file if any
        if self.f is not None:
            self.f.close()
            self.f = None

```

Actual Loading

The actual work is done in 
_load
. Called to load the next set of data, in
this case the next : datetime, open, high, low, close, volume, openinterest. In

backtrader
 the “actual” moment corresponds to index 0.

A number of bytes will be read from the open file (determined by the constants
set up during 
__init__
), parsed with the 
struct
 module, further
processed if needed (like with divmod operations for date and time) and stored
in the 
lines
 of the data feed: datetime, open, high, low, close, volume,
openinterest.

If no data can be read from the file it is assumed that the End Of File (EOF)
has been reached

False
 is returned to indicate the fact no more data is available

Else if data has been loaded and parsed:

True
 is returned to indicate the loading of the data set was a success

```
    def _load(self):
        if self.f is None:
            # if no file ... no parsing
            return False

        # Read the needed amount of binary data
        bardata = self.f.read(self.barsize)
        if not bardata:
            # if no data was read ... game over say "False"
            return False

        # use struct to unpack the data
        bdata = struct.unpack(self.barfmt, bardata)

        # Years are stored as if they had 500 days
        y, md = divmod(bdata[0], 500)
        # Months are stored as if they had 32 days
        m, d = divmod(md, 32)
        # put y, m, d in a datetime
        dt = datetime.datetime(y, m, d)

        if self.dtsize > 1:  # Minute Bars
            # Daily Time is stored in seconds
            hhmm, ss = divmod(bdata[1], 60)
            hh, mm = divmod(hhmm, 60)
            # add the time to the existing atetime
            dt = dt.replace(hour=hh, minute=mm, second=ss)

        self.lines.datetime[0] = date2num(dt)

        # Get the rest of the unpacked data
        o, h, l, c, v, oi = bdata[self.dtsize:]
        self.lines.open[0] = o
        self.lines.high[0] = h
        self.lines.low[0] = l
        self.lines.close[0] = c
        self.lines.volume[0] = v
        self.lines.openinterest[0] = oi

        # Say success
        return True

```

Other Binary Formats

The same model can be applied to any other binary source:

Database

Hierarchical data storage

Online source

The steps again:

__init__
 -> Any init code for the instance, only once

start
 -> start of backtesting (one or more times if optimization will be
    run)

This would for example open the connection to the database or a socket to an
online service

stop
 -> clean-up like closing the database connection or open sockets

_load
 -> query the database or online source for the next set of data
    and load it into the 
lines
 of the object. The standard fields being:
    datetime, open, high, low, close, volume, openinterest

VChartData Test

The 
VCharData
 loading data from a local “.fd” file for Google for the
year 2006.

It’s only about loading the data, so not even a subclass of 
Strategy
 is
needed.

```
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import datetime

import backtrader as bt
from vchart import VChartData

if __name__ == '__main__':
    # Create a cerebro entity
    cerebro = bt.Cerebro(stdstats=False)

    # Add a strategy
    cerebro.addstrategy(bt.Strategy)

    ###########################################################################
    # Note:
    # The goog.fd file belongs to VisualChart and cannot be distributed with
    # backtrader
    #
    # VisualChart can be downloaded from www.visualchart.com
    ###########################################################################
    # Create a Data Feed
    datapath = '../../datas/goog.fd'
    data = VChartData(
        dataname=datapath,
        fromdate=datetime.datetime(2006, 1, 1),
        todate=datetime.datetime(2006, 12, 31),
        timeframe=bt.TimeFrame.Days
    )

    # Add the Data Feed to Cerebro
    cerebro.adddata(data)

    # Run over everything
    cerebro.run()

    # Plot the result
    cerebro.plot(style='bar')

```

VChartData Full Code

```
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import datetime
import struct

from backtrader.feed import DataBase
from backtrader import date2num
from backtrader import TimeFrame

class VChartData(DataBase):
    def __init__(self):
        super(VChartData, self).__init__()

        # Use the informative "timeframe" parameter to understand if the
        # code passed as "dataname" refers to an intraday or daily feed
        if self.p.timeframe >= TimeFrame.Days:
            self.barsize = 28
            self.dtsize = 1
            self.barfmt = 'IffffII'
        else:
            self.dtsize = 2
            self.barsize = 32
            self.barfmt = 'IIffffII'

    def start(self):
        # the feed must start ... get the file open (or see if it was open)
        self.f = None
        if hasattr(self.p.dataname, 'read'):
            # A file has been passed in (ex: from a GUI)
            self.f = self.p.dataname
        else:
            # Let an exception propagate
            self.f = open(self.p.dataname, 'rb')

    def stop(self):
        # Close the file if any
        if self.f is not None:
            self.f.close()
            self.f = None

    def _load(self):
        if self.f is None:
            # if no file ... no parsing
            return False

        # Read the needed amount of binary data
        bardata = self.f.read(self.barsize)
        if not bardata:
            # if no data was read ... game over say "False"
            return False

        # use struct to unpack the data
        bdata = struct.unpack(self.barfmt, bardata)

        # Years are stored as if they had 500 days
        y, md = divmod(bdata[0], 500)
        # Months are stored as if they had 32 days
        m, d = divmod(md, 32)
        # put y, m, d in a datetime
        dt = datetime.datetime(y, m, d)

        if self.dtsize > 1:  # Minute Bars
            # Daily Time is stored in seconds
            hhmm, ss = divmod(bdata[1], 60)
            hh, mm = divmod(hhmm, 60)
            # add the time to the existing atetime
            dt = dt.replace(hour=hh, minute=mm, second=ss)

        self.lines.datetime[0] = date2num(dt)

        # Get the rest of the unpacked data
        o, h, l, c, v, oi = bdata[self.dtsize:]
        self.lines.open[0] = o
        self.lines.high[0] = h
        self.lines.low[0] = l
        self.lines.close[0] = c
        self.lines.volume[0] = v
        self.lines.openinterest[0] = oi

        # Say success
        return True

```
########################################
docu-datafeed.txt - lunghezza: 5537
########################################
Data Feeds

backtrader
 comes with a set of Data Feed parsers (at the time of writing all
CSV Based) to let you load data from different sources.

Yahoo (online or already saved to a file)

VisualChart (see 
www.visualchart.com

Backtrader CSV (own cooked format for testing)

Generic CSV support

From the Quickstart guide it should be clear that you add data feeds to a

Cerebro
 instance. The data feeds will later be available to the different
strategies in:

An array self.datas (insertion order)

Alias to the array objects:

self.data and self.data0 point to the first element

self.dataX points to elements with index X in the array

A quick reminder as to how the insertion works:

```
import backtrader as bt
import backtrader.feeds as btfeeds

data = btfeeds.YahooFinanceCSVData(dataname='wheremydatacsvis.csv')

cerebro = bt.Cerebro()

cerebro.adddata(data)  # a 'name' parameter can be passed for plotting purposes

```

Data Feeds Common parameters

This data feed can download data directly from Yahoo and feed into the system.

Parameters:

dataname
 (default: None) MUST BE PROVIDED

The meaning varies with the data feed type (file location, ticker, …)

name
 (default: ‘’)

Meant for decorative purposes in plotting. If not specified it may be
derived from 
dataname
 (example: last part of a file path)

fromdate
 (default: mindate)

Python datetime object indicating that any datetime prior to this should be
ignored

todate
 (default: maxdate)

Python datetime object indicating that any datetime posterior to this should
be ignored

timeframe
 (default: TimeFrame.Days)

Potential values: 
Ticks
, 
Seconds
, 
Minutes
, 
Days
, 
Weeks
,

Months
 and 
Years

compression
 (default: 1)

Number of actual bars per bar. Informative. Only effective in Data
Resampling/Replaying.

sessionstart
 (default: None)

Indication of session starting time for the data. May be used by classes for
purposes like resampling

sessionend
 (default: None)

Indication of session ending time for the data. May be used by classes for
purposes like resampling

CSV Data Feeds Common parameters

Parameters (additional to the common ones):

headers
 (default: True)

Indicates if the passed data has an initial headers row

separator
 (default: “,”)

Separator to take into account to tokenize each of the CSV rows

GenericCSVData

This class exposes a generic interface allowing parsing mostly every CSV file
format out there.

Parses a CSV file according to the order and field presence defined by the parameters

Specific parameters (or specific meaning):

dataname

The filename to parse or a file-like object

datetime
 (default: 0) column containing the date (or datetime) field

time
 (default: -1) column containing the time field if separate from the
    datetime field (-1 indicates it’s not present)

open
 (default: 1) , 
high
 (default: 2), 
low
 (default: 3),

close
 (default: 4), 
volume
 (default: 5), 
openinterest

    (default: 6)

Index of the columns containing the corresponding fields

If a negative value is passed (example: -1) it indicates the field is not
present in the CSV data

nullvalue
 (default: float(‘NaN’))

Value that will be used if a value which should be there is missing (the CSV
field is empty)

dtformat
 (default: %Y-%m-%d %H:%M:%S)

Format used to parse the datetime CSV field

tmformat
 (default: %H:%M:%S)

Format used to parse the time CSV field if “present” (the default for the
“time” CSV field is not to be present)

An example usage covering the following requirements:

Limit input to year 2000

HLOC order rather than OHLC

Missing values to be replaced with zero (0.0)

Daily bars are provided and datetime is just the day with format YYYY-MM-DD

No 
openinterest
 column is present

The code:

```
import datetime
import backtrader as bt
import backtrader.feeds as btfeeds

...
...

data = btfeeds.GenericCSVData(
    dataname='mydata.csv',

    fromdate=datetime.datetime(2000, 1, 1),
    todate=datetime.datetime(2000, 12, 31),

    nullvalue=0.0,

    dtformat=('%Y-%m-%d'),

    datetime=0,
    high=1,
    low=2,
    open=3,
    close=4,
    volume=5,
    openinterest=-1
)

...

```

Slightly modified requirements:

Limit input to year 2000

HLOC order rather than OHLC

Missing values to be replaced with zero (0.0)

Intraday bars are provided, with separate date and time columns

Date has format YYYY-MM-DD

Time has format HH.MM.SS (instead of the usual HH:MM:SS)

No 
openinterest
 column is present

The code:

```
import datetime
import backtrader as bt
import backtrader.feeds as btfeed

...
...

data = btfeeds.GenericCSVData(
    dataname='mydata.csv',

    fromdate=datetime.datetime(2000, 1, 1),
    todate=datetime.datetime(2000, 12, 31),

    nullvalue=0.0,

    dtformat=('%Y-%m-%d'),
    tmformat=('%H.%M.%S'),

    datetime=0,
    time=1,
    high=2,
    low=3,
    open=4,
    close=5,
    volume=6,
    openinterest=-1
)

```

This can also be made 
permanent
 with subclassing:

```
import datetime
import backtrader.feeds as btfeed

class MyHLOC(btfreeds.GenericCSVData):

  params = (
    ('fromdate', datetime.datetime(2000, 1, 1)),
    ('todate', datetime.datetime(2000, 12, 31)),
    ('nullvalue', 0.0),
    ('dtformat', ('%Y-%m-%d')),
    ('tmformat', ('%H.%M.%S')),

    ('datetime', 0),
    ('time', 1),
    ('high', 2),
    ('low', 3),
    ('open', 4),
    ('close', 5),
    ('volume', 6),
    ('openinterest', -1)
)

```

This new class can be reused now by just providing the 
dataname
:

```
data = btfeeds.MyHLOC(dataname='mydata.csv')

```
########################################
docu-datayahoo.txt - lunghezza: 1118
########################################
Yahoo Data Feed Notes

In May 2017 Yahoo discontinued the existing API for historical data downloads
in 
csv
 format.

A new API (here named 
v7
) was quickly 
standardized
 and has been
implemented.

This also brought a change to the actual CSV download format.

Using the v7 API/format

Starting with version 
1.9.49.116
 this is the default behavior. Choose
simply from

YahooFinanceData
 for online downloads

YahooFinanceCSVData
 for offline downloaded files

Using the legacy API/format

To use the old API/format

Instantiate the online Yahoo data feed as:

```
data = bt.feeds.YahooFinanceData(
    ...
    version='',
    ...
)

```

of the offline Yahoo data feed as:

```
data = bt.feeds.YahooFinanceCSVData(
    ...
    version='',
    ...
)

```

It might be that the online service comes back (the service was

discontinued
 without any announcement … it might as well come back)

or

Only for Offline files downloaded before the change happened, the
     following can also be done:

```
data = bt.feeds.YahooLegacyCSV(
    ...
    ...
)

```

The new 
YahooLegacyCSV
 simply automates using 
version=''
########################################
docu-exceptions.txt - lunghezza: 1065
########################################
Exceptions

One of the design goals was to quit as early as possible and let the users have
full transparency of what was happening with errors. With the goal to force
oneself to have code that would break on exceptions and forced revisiting the
affected part.

But the time has come and some exceptions may slowly get added to the platform.

Hierarchy

The base class for all exceptions is 
BacktraderError
 (which is a direct
subclass of 
Exception
)

Location

Inside the module 
errors
 which can be reached as in for example:

```
import backtrader as bt

class Strategy(bt.Strategy):

    def __init__(self):
        if something_goes_wrong():
            raise bt.errors.StrategySkipError

```

Directly from 
backtrader
 as in:

```
import backtrader as bt

class Strategy(bt.Strategy):

    def __init__(self):
        if something_goes_wrong():
            raise bt.StrategySkipError

```

Exceptions

StrategySkipError

Requests the platform to skip this strategy for backtesting. To be raised
during the initialization (
__init__
) phase of the instance
########################################
docu-extending-a-datafeed.txt - lunghezza: 2764
########################################
Extending a Datafeed

Issues in GitHub are actually pushing into finishing documentation parts or
helping me to understand if 
backtrader
 has the ease of use and flexibility I
envisioned from the first moments and the decisions made along the way.

In this case is 
Issue #9
.

The question finally seems to boil down to:

Can the end user easily extend the existing mechanisms to add extra
    information in the form of lines that gets passed along other existing price
    information spots like 
open
, 
high
, etc?

As far as I understand the question the answer is: 
Yes

The poster seems to have these requirements (from 
Issue #6
):

A data source which is being parsed into CSV format

Using 
GenericCSVData
 to load the information

This generic csv support was developed in response to this 
Issue #6

An extra field which apparently contains P/E information which needs to be
    passed along the parsed CSV Data

Let’s build on the CSV Data Feed Development and
GenericCSVData example posts.

Steps:

Assume the P/E information is being set in the CSV data which is parsed

Use 
GenericCSVData
 as the base class

Extend the existng lines (open/high/low/close/volumen/openinterest) with

pe

Add a parameter to let the caller determine the column position of the P/E
    information

The result:

```
from backtrader.feeds import GenericCSVData

class GenericCSV_PE(GenericCSVData):

    # Add a 'pe' line to the inherited ones from the base class
    lines = ('pe',)

    # openinterest in GenericCSVData has index 7 ... add 1
    # add the parameter to the parameters inherited from the base class
    params = (('pe', 8),)

```

And the job is done …

Later and when using this data feed inside a strategy:

```
import backtrader as bt

....

class MyStrategy(bt.Strategy):

    ...

    def next(self):

        if self.data.close > 2000 and self.data.pe < 12:
            # TORA TORA TORA --- Get off this market
            self.sell(stake=1000000, price=0.01, exectype=Order.Limit)
    ...

```

Plotting that extra P/E line

There is obviously no automated plot support for that extra line in the data
feed.

The best alternative would be to do a SimpleMovingAverage on that line and
plot it in a separate axis:

```
import backtrader as bt
import backtrader.indicators as btind

....

class MyStrategy(bt.Strategy):

    def __init__(self):

        # The indicator autoregisters and will plot even if no obvious
        # reference is kept to it in the class
        btind.SMA(self.data.pe, period=1, subplot=False)

    ...

    def next(self):

        if self.data.close > 2000 and self.data.pe < 12:
            # TORA TORA TORA --- Get off this market
            self.sell(stake=1000000, price=0.01, exectype=Order.Limit)
    ...

```
########################################
docu-extending-commissions-commission-schemes-extended.txt - lunghezza: 13443
########################################
Extending Commissions

Commissions and asociated functionality were managed by a single class

CommissionInfo
 which was mostly instantiated by calling

broker.setcommission
.

The concept was limited to futures with margin and a fixed commission per
contract and stocks with a price/size percentage based commission. Not the most
flexible of schemes even if it has served its purpose.

A request for enhancement on GitHub 
#29
 led to some rework in
order to:

Keep 
CommissionInfo
 and 
broker.setcommission
 compatible with the
    original behavior

Do some clean up of the code

Make the Commission scheme flexible to support the enhancement request and
    further possibilities

The actual work before getting to the sample

```
class CommInfoBase(with_metaclass(MetaParams)):
    COMM_PERC, COMM_FIXED = range(2)

    params = (
        ('commission', 0.0), ('mult', 1.0), ('margin', None),
        ('commtype', None),
        ('stocklike', False),
        ('percabs', False),
    )

```

A base class for 
CommissionInfo
 has been introduced which add new parameters
to the mix:

commtype
 (default: 
None
)

This is the key to compatibility. If the value is 
None
, the behavior of
the 
CommissionInfo
 object and 
broker.setcommission
 will work as
before. Being that:

If 
margin
 is set then the commission scheme is for futures with a
    fixed commission per contract

If 
margin
 is not set, the commission scheme is for stocks with a
    percentage based approach

If the value is 
COMM_PERC
 or 
COMM_FIXED
 (or any other from derived
classes) this obviously decides if the commission if fixed or percent based

stocklike
 (default: 
False
)

As explained above, the actual behavior in the old 
CommissionInfo
 object
is determined by the parameter 
margin

As above if 
commtype
 is set to something else than 
None
, then this
value indicates whether the asset is a futures-like asset (margin will be
used and bar based cash adjustment will be performed9 or else this a
stocks-like asset

percabs
 (default: 
False
)

If 
False
 then the percentage must be passed in relative terms (xx%)

If 
True
 the percentage has to be passed as an absolute value (0.xx)

CommissionInfo
 is subclassed from 
CommInfoBase
 changing the default
value of this parameter to 
True
 to keep the compatible behavior

All these parameters can also be used in 
broker.setcommission
 which now
looks like this:

```
def setcommission(self,
                  commission=0.0, margin=None, mult=1.0,
                  commtype=None, percabs=True, stocklike=False,
                  name=None):

```

Notice the following:

percabs
 is 
True
 to keep the behavior compatible with the old call as
    mentioned above for the 
CommissionInfo
 object

The old sample to test 
commissions-schemes
 has been reworked to support
command line arguments and the new behavior. The usage help:

```
$ ./commission-schemes.py --help
usage: commission-schemes.py [-h] [--data DATA] [--fromdate FROMDATE]
                             [--todate TODATE] [--stake STAKE]
                             [--period PERIOD] [--cash CASH] [--comm COMM]
                             [--mult MULT] [--margin MARGIN]
                             [--commtype {none,perc,fixed}] [--stocklike]
                             [--percrel] [--plot] [--numfigs NUMFIGS]

Commission schemes

optional arguments:
  -h, --help            show this help message and exit
  --data DATA, -d DATA  data to add to the system (default:
                        ../../datas/2006-day-001.txt)
  --fromdate FROMDATE, -f FROMDATE
                        Starting date in YYYY-MM-DD format (default:
                        2006-01-01)
  --todate TODATE, -t TODATE
                        Starting date in YYYY-MM-DD format (default:
                        2006-12-31)
  --stake STAKE         Stake to apply in each operation (default: 1)
  --period PERIOD       Period to apply to the Simple Moving Average (default:
                        30)
  --cash CASH           Starting Cash (default: 10000.0)
  --comm COMM           Commission factor for operation, either apercentage or
                        a per stake unit absolute value (default: 2.0)
  --mult MULT           Multiplier for operations calculation (default: 10)
  --margin MARGIN       Margin for futures-like operations (default: 2000.0)
  --commtype {none,perc,fixed}
                        Commission - choose none for the old CommissionInfo
                        behavior (default: none)
  --stocklike           If the operation is for stock-like assets orfuture-
                        like assets (default: False)
  --percrel             If perc is expressed in relative xx{'const': True,
                        'help': u'If perc is expressed in relative xx%
                        ratherthan absolute value 0.xx', 'option_strings': [u'
                        --percrel'], 'dest': u'percrel', 'required': False,
                        'nargs': 0, 'choices': None, 'default': False, 'prog':
                        'commission-schemes.py', 'container':
                        <argparse._ArgumentGroup object at
                        0x0000000007EC9828>, 'type': None, 'metavar':
                        None}atherthan absolute value 0.xx (default: False)
  --plot, -p            Plot the read data (default: False)
  --numfigs NUMFIGS, -n NUMFIGS
                        Plot using numfigs figures (default: 1)

```

Let’s do some runs to recreate the original behavior of the original commission
schemes posts.

Commissions for futures (fixed and with margin)

The execution and chart:

```
$ ./commission-schemes.py --comm 2.0 --margin 2000.0 --mult 10 --plot

```

And the output showing a fixed commission of 2.0 monetary units (default stake
is 1):

```
2006-03-09, BUY CREATE, 3757.59
2006-03-10, BUY EXECUTED, Price: 3754.13, Cost: 2000.00, Comm 2.00
2006-04-11, SELL CREATE, 3788.81
2006-04-12, SELL EXECUTED, Price: 3786.93, Cost: 2000.00, Comm 2.00
2006-04-12, TRADE PROFIT, GROSS 328.00, NET 324.00
...

```

Commissions for stocks (perc and withoout  margin)

The execution and chart:

```
$ ./commission-schemes.py --comm 0.005 --margin 0 --mult 1 --plot

```

To improve readability a relative % value can be used:

```
$ ./commission-schemes.py --percrel --comm 0.5 --margin 0 --mult 1 --plot

```

Now 
0.5
 means directly 
0.5%

Being the output in both cases:

```
2006-03-09, BUY CREATE, 3757.59
2006-03-10, BUY EXECUTED, Price: 3754.13, Cost: 3754.13, Comm 18.77
2006-04-11, SELL CREATE, 3788.81
2006-04-12, SELL EXECUTED, Price: 3786.93, Cost: 3754.13, Comm 18.93
2006-04-12, TRADE PROFIT, GROSS 32.80, NET -4.91
...

```

Commissions for futures (perc and with margin)

Using the new parameters, futures on a perc based scheme:

```
$ ./commission-schemes.py --commtype perc --percrel --comm 0.5 --margin 2000 --mult 10 --plot

```

It should come to no surprise that by changing the commission … the final
result has changed

The output shows that the commission is variable now:

```
2006-03-09, BUY CREATE, 3757.59
2006-03-10, BUY EXECUTED, Price: 3754.13, Cost: 2000.00, Comm 18.77
2006-04-11, SELL CREATE, 3788.81
2006-04-12, SELL EXECUTED, Price: 3786.93, Cost: 2000.00, Comm 18.93
2006-04-12, TRADE PROFIT, GROSS 328.00, NET 290.29
...

```

Being in the previous run set a 2.0 monetary units (for the default stake of 1)

Another post will details the new classes and the implementation of a homme
cooked commission scheme.

The code for the sample

```
from __future__ import (absolute_import, division, print_function,
                        unicode_literals)

import argparse
import datetime

import backtrader as bt
import backtrader.feeds as btfeeds
import backtrader.indicators as btind

class SMACrossOver(bt.Strategy):
    params = (
        ('stake', 1),
        ('period', 30),
    )

    def log(self, txt, dt=None):
        ''' Logging function fot this strategy'''
        dt = dt or self.datas[0].datetime.date(0)
        print('%s, %s' % (dt.isoformat(), txt))

    def notify_order(self, order):
        if order.status in [order.Submitted, order.Accepted]:
            # Buy/Sell order submitted/accepted to/by broker - Nothing to do
            return

        # Check if an order has been completed
        # Attention: broker could reject order if not enougth cash
        if order.status in [order.Completed, order.Canceled, order.Margin]:
            if order.isbuy():
                self.log(
                    'BUY EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %
                    (order.executed.price,
                     order.executed.value,
                     order.executed.comm))
            else:  # Sell
                self.log('SELL EXECUTED, Price: %.2f, Cost: %.2f, Comm %.2f' %
                         (order.executed.price,
                          order.executed.value,
                          order.executed.comm))

    def notify_trade(self, trade):
        if trade.isclosed:
            self.log('TRADE PROFIT, GROSS %.2f, NET %.2f' %
                     (trade.pnl, trade.pnlcomm))

    def __init__(self):
        sma = btind.SMA(self.data, period=self.p.period)
        # > 0 crossing up / < 0 crossing down
        self.buysell_sig = btind.CrossOver(self.data, sma)

    def next(self):
        if self.buysell_sig > 0:
            self.log('BUY CREATE, %.2f' % self.data.close[0])
            self.buy(size=self.p.stake)  # keep order ref to avoid 2nd orders

        elif self.position and self.buysell_sig < 0:
            self.log('SELL CREATE, %.2f' % self.data.close[0])
            self.sell(size=self.p.stake)

def runstrategy():
    args = parse_args()

    # Create a cerebro
    cerebro = bt.Cerebro()

    # Get the dates from the args
    fromdate = datetime.datetime.strptime(args.fromdate, '%Y-%m-%d')
    todate = datetime.datetime.strptime(args.todate, '%Y-%m-%d')

    # Create the 1st data
    data = btfeeds.BacktraderCSVData(
        dataname=args.data,
        fromdate=fromdate,
        todate=todate)

    # Add the 1st data to cerebro
    cerebro.adddata(data)

    # Add a strategy
    cerebro.addstrategy(SMACrossOver, period=args.period, stake=args.stake)

    # Add the commission - only stocks like a for each operation
    cerebro.broker.setcash(args.cash)

    commtypes = dict(
        none=None,
        perc=bt.CommInfoBase.COMM_PERC,
        fixed=bt.CommInfoBase.COMM_FIXED)

    # Add the commission - only stocks like a for each operation
    cerebro.broker.setcommission(commission=args.comm,
                                 mult=args.mult,
                                 margin=args.margin,
                                 percabs=not args.percrel,
                                 commtype=commtypes[args.commtype],
                                 stocklike=args.stocklike)

    # And run it
    cerebro.run()

    # Plot if requested
    if args.plot:
        cerebro.plot(numfigs=args.numfigs, volume=False)

def parse_args():
    parser = argparse.ArgumentParser(
        description='Commission schemes',
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,)

    parser.add_argument('--data', '-d',
                        default='../../datas/2006-day-001.txt',
                        help='data to add to the system')

    parser.add_argument('--fromdate', '-f',
                        default='2006-01-01',
                        help='Starting date in YYYY-MM-DD format')

    parser.add_argument('--todate', '-t',
                        default='2006-12-31',
                        help='Starting date in YYYY-MM-DD format')

    parser.add_argument('--stake', default=1, type=int,
                        help='Stake to apply in each operation')

    parser.add_argument('--period', default=30, type=int,
                        help='Period to apply to the Simple Moving Average')

    parser.add_argument('--cash', default=10000.0, type=float,
                        help='Starting Cash')

    parser.add_argument('--comm', default=2.0, type=float,
                        help=('Commission factor for operation, either a'
                              'percentage or a per stake unit absolute value'))

    parser.add_argument('--mult', default=10, type=int,
                        help='Multiplier for operations calculation')

    parser.add_argument('--margin', default=2000.0, type=float,
                        help='Margin for futures-like operations')

    parser.add_argument('--commtype', required=False, default='none',
                        choices=['none', 'perc', 'fixed'],
                        help=('Commission - choose none for the old'
                              ' CommissionInfo behavior'))

    parser.add_argument('--stocklike', required=False, action='store_true',
                        help=('If the operation is for stock-like assets or'
                              'future-like assets'))

    parser.add_argument('--percrel', required=False, action='store_true',
                        help=('If perc is expressed in relative xx% rather'
                              'than absolute value 0.xx'))

    parser.add_argument('--plot', '-p', action='store_true',
                        help='Plot the read data')

    parser.add_argument('--numfigs', '-n', default=1,
                        help='Plot using numfigs figures')

    return parser.parse_args()

if __name__ == '__main__':
    runstrategy()

```
########################################
docu-filler.txt - lunghezza: 3750
########################################
Fillers

The 
backtrader
 broker simulation has a default strategy when it comes to
using volume for order execution:

Ignore volume

This is based on 2 premises:

Trade in markets liquid enough to fully absorb 
buy/sell
 orders in one go

Real volume matching requires a real wolrd

A quick example is a 
Fill or Kill
 order. Even down to the 
tick

resolution and with enough volume for a 
fill
, the 
backtrader
 broker
cannot know how many extra actors happen to be in the market to
discriminate if such an order would be or would not be matched to stick to
the 
Fill
 part or if the order should be 
Kill

But the 
broker
 can accept 
Volume Fillers
 which determine how much of the
volume at a given point in time has to be used for 
order matching
.

The fillers signature

A 
filler
 in the 
backtrader
 ecosystem can be any 
callable
 which matches
the following signature:

```
callable(order, price, ago)

```

Where:

order
 is the order which is going to be executed

This object gives access to the 
data
 object which is the target of the
operation, creation sizes/prices, execution prices/sizes/remaining sizes
and other details

price
 at which the order is going to be executed

ago
 is the index to the 
data
 in the 
order
 in which to look for
    the volume and price elements

In almost all cases this will be 
0
 (current point in time) but in a
corner case to cover 
Close
 orders this may be 
-1

To for example access the bar volume do:

```
barvolume = order.data.volume[ago]

```

The callable can be a function or for example an instance of a class
supporting the 
__call__
 method, like in:

```
class MyFiller(object):
    def __call__(self, order, price, ago):
        pass

```

Adding a Filler to the broker

The most straightforward method is to use the 
set_filler
:

```
import backtrader as bt

cerebro = Cerebro()
cerebro.broker.set_filler(bt.broker.fillers.FixedSize())

```

The second choice is to completely replace the 
broker
, although this is
probably only meant for subclasses of 
BrokerBack
 which have rewritten
portions of the functionality:

```
import backtrader as bt

cerebro = Cerebro()
filler = bt.broker.fillers.FixedSize()
newbroker = bt.broker.BrokerBack(filler=filler)
cerebro.broker = newbroker

```

The sample

The 
backtrader
 sources contain a sample named 
volumefilling
 which allows
to test some of the integrated 
fillers
 (initially all)

Reference

class backtrader.fillers.FixedSize()

Returns the execution size for a given order using a 
percentage
 of the
volume in a bar.

This percentage is set with the parameter 
perc

Params:

size
 (default: 
None
)  maximum size to be executed. The actual
    volume of the bar at execution time is also a limit if smaller than the
    size

If the value of this parameter evaluates to False, the entire volume
of the bar will be used to match the order

class backtrader.fillers.FixedBarPerc()

Returns the execution size for a given order using a 
percentage
 of the
volume in a bar.

This percentage is set with the parameter 
perc

Params:

perc
 (default: 
100.0
) (valied values: 
0.0 - 100.0
)

Percentage of the volume bar to use to execute an order

class backtrader.fillers.BarPointPerc()

Returns the execution size for a given order. The volume will be
distributed uniformly in the range 
high
-
low
 using 
minmov
 to
partition.

From the allocated volume for the given price, the 
perc
 percentage will
be used

Params:

minmov
 (default: 
0.01
)

Minimum price movement. Used to partition the range 
high
-
low
 to
proportionally distribute the volume amongst possible prices

perc
 (default: 
100.0
) (valied values: 
0.0 - 100.0
)

Percentage of the volume allocated to the order execution price to use
for matching
########################################
docu-filters-reference.txt - lunghezza: 4932
########################################
Filters Reference

SessionFilter

class backtrader.filters.SessionFilter(data)

This class can be applied to a data source as a filter and will filter out
intraday bars which fall outside of the regular session times (ie: pre/post
market data)

This is a “non-simple” filter and must manage the stack of the data (passed
during init and 
call
)

It needs no “last” method because it has nothing to deliver

SessionFilterSimple

class backtrader.filters.SessionFilterSimple(data)

This class can be applied to a data source as a filter and will filter out
intraday bars which fall outside of the regular session times (ie: pre/post
market data)

This is a “simple” filter and must NOT manage the stack of the data (passed
during init and 
call
)

It needs no “last” method because it has nothing to deliver

Bar Management will be done by the SimpleFilterWrapper class made which is
added durint the DataBase.addfilter_simple call

SessionFilller

class backtrader.filters.SessionFiller(data)

Bar Filler for a Data Source inside the declared session start/end times.

The fill bars are constructed using the declared Data Source 
timeframe

and 
compression
 (used to calculate the intervening missing times)

Params:

fill_price (def: None):

If None is passed, the closing price of the previous bar will be
used. To end up with a bar which for example takes time but it is not
displayed in a plot … use float(‘Nan’)

fill_vol (def: float(‘NaN’)):

Value to use to fill the missing volume

fill_oi (def: float(‘NaN’)):

Value to use to fill the missing Open Interest

skip_first_fill (def: True):

Upon seeing the 1
st
 valid bar do not fill from the sessionstart up to
that bar

CalendarDays

class backtrader.filters.CalendarDays(data)

Bar Filler to add missing calendar days to trading days

Params:

fill_price (def: None):

0: The given value to fill
0 or None: Use the last known closing price
-1: Use the midpoint of the last bar (High-Low average)

fill_vol (def: float(‘NaN’)):

Value to use to fill the missing volume

fill_oi (def: float(‘NaN’)):

Value to use to fill the missing Open Interest

BarReplayer_Open

class backtrader.filters.BarReplayer_Open(data)

This filters splits a bar in two parts:

Open
: the opening price of the bar will be used to deliver an
    initial price bar in which the four components (OHLC) are equal

The volume/openinterest fields are 0 for this initial bar

OHLC
: the original bar is delivered complete with the original

volume
/
openinterest

The split simulates a replay without the need to use the 
replay
 filter.

DaySplitter_Close

class backtrader.filters.DaySplitter_Close(data)

Splits a daily bar in two parts simulating 2 ticks which will be used to
replay the data:

First tick: 
OHLX

The 
Close
 will be replaced by the 
average
 of 
Open
, 
High

and 
Low

The session opening time is used for this tick

and

Second tick: 
CCCC

The 
Close
 price will be used for the four components of the price

The session closing time is used for this tick

The volume will be split amongst the 2 ticks using the parameters:

closevol
 (default: 
0.5
) The value indicate which percentage, in
    absolute terms from 0.0 to 1.0, has to be assigned to the 
closing

    tick. The rest will be assigned to the 
OHLX
 tick.

This filter is meant to be used together with

cerebro.replaydata

HeikinAshi

class backtrader.filters.HeikinAshi(data)

The filter remodels the open, high, low, close to make HeikinAshi
candlesticks

See:

```
* [https://en.wikipedia.org/wiki/Candlestick_chart#Heikin_Ashi_candlesticks](https://en.wikipedia.org/wiki/Candlestick_chart#Heikin_Ashi_candlesticks)

* [http://stockcharts.com/school/doku.php?id=chart_school:chart_analysis:heikin_ashi](http://stockcharts.com/school/doku.php?id=chart_school:chart_analysis:heikin_ashi)

```

Renko

class backtrader.filters.Renko(data)

Modify the data stream to draw Renko bars (or bricks)

Params:

hilo
 (default: 
False
) Use high and low instead of close to decide
    if a new brick is needed

size
 (default: 
None
) The size to consider for each brick

autosize
 (default: 
20.0
) If 
size
 is 
None
, this will be used
    to autocalculate the size of the bricks (simply dividing the current
    price by the given value)

dynamic
 (default: 
False
) If 
True
 and using 
autosize
, the size
    of the bricks will be recalculated when moving to a new brick. This
    will of course eliminate the perfect alignment of Renko bricks.

align
 (default: 
1.0
) Factor use to align the price boundaries of
    the bricks. If the price is for example 
3563.25
 and 
align
 is

10.0
, the resulting aligned price will be 
3560
. The calculation:

3563.25 / 10.0 = 356.325

round it and remove the decimals -> 356

356 * 10.0 -> 3560

See:

```
* [http://stockcharts.com/school/doku.php?id=chart_school:chart_analysis:renko](http://stockcharts.com/school/doku.php?id=chart_school:chart_analysis:renko)

```
########################################
docu-filters.txt - lunghezza: 11046
########################################
Filters

This functionality is a relatively late addition to 
backtrader
 and had to be
fitted to the already existing internals. This makes it to be not as flexible
and 100% feature full as wished, but it can still serve the purpose in many
cases.

Although the implementation tried to allow plug and play filter chaining, the
pre-existing internals made it difficult to ensure that could always be
achieved. As such, some filters may be chained and some others may not.

Purpose

Transform the values provided by a 
data feed
 to deliver a different 
data
    feed

The implementation was started to simplify the implementation of the two
obvious filters which can be directly used via the 
cerebro
 API. These are:

Resampling
  (
cerebro.resampledata
)

Here the filter transforms the 
timeframe
 and 
compression
 of the
incoming 
data feed
. For example:

```
(Seconds, 1) -> (Days, 1)

```

That means that the original data feed is delivery bars with a resolution
of 
1 Second
. The 
Resampling
 filter intercepts the data and buffers it
until it can deliver a 
1 Day
 bar. This will happen when a 
1 Second
 bar
from the next day is seen.

Replaying
 (
cerebro.replaydata
)

For the same timeframes as above, the filter would use the 
1 Second

resolution bars to rebuild the 
1 Day
 bar.

That means that the 
1 Day
 bar is delivered as many times as 
1 Second

bars are seen, updated to contain the latest information.

This simulates, for example, how an actual trading day has developed.

Note

The length of the data, 
len(data)
 and therefore the length of
the strategy remain unchanged as long as the 
day
 doesn’t
change.

Filters at work

Given an existing data feed/source you use the 
addfilter
 method of the data
feed:

```
data = MyDataFeed(dataname=myname)
data.addfilter(filter, *args, **kwargs)
cerebro.addata(data)

```

And even if it happens to be compatible to the 
resample/replay
 filter the
following can also be done:

```
data = MyDataFeed(dataname=myname)
data.addfilter(filter, *args, **kwargs)
cerebro.replaydata(data)

```

Filter Interface

A 
filter
 must conform to a given interface, being this:

A callable which accepts this signature:

```
callable(data, *args, **kwargs)

```

or

A class which can be 
instantiated
 and 
called

During instantiation the 
__init__
 method must support the signature:

```
def __init__(self, data, *args, **kwargs)

```

The 
__call__
 method bears this signature:

```
def __call__(self, data, *args, **kwargs)

```

The instance will be called for each new incoming values from the 
data
  feed
. The 
\*args
 and 
\*kwargs
 are the same passed to 
__init__

RETURN VALUES
:

```
* `True`: the inner data fetching loop of the data feed must retry
  fetching data from the feed, becaue the length of the stream was
  manipulated

* `False` even if data may have been edited (example: changed
  `close` price), the length of the stream has remain untouched

```

In the case of a class based filter 2 additional methods can be implemented

last
 with the following signature:

```
def last(self, data, *args, **kwargs)

```

This will be called when the 
data feed
 is over, allowing the filter to
  deliver data it may have for example buffered. A typical case is

resampling
, because a bar is buffered until data from the next time
  period is seen. When the data feed is over, there is no new data to push
  the buffered data out.

last
 offers the chance to push the buffered data out.

Note

It is obvious that if the 
filter
 supports no arguments at all and
will be added without any, the signatures can be simplified as in:

```
def __init__(self, data, *args, **kwargs) -> def __init__(self, data)

```

A Sample Filter

A very quick filter implementation:

```
class SessionFilter(object):
    def __init__(self, data):
        pass

    def __call__(self, data):
        if data.p.sessionstart <= data.datetime.time() <= data.p.sessionend:
            # bar is in the session
            return False  # tell outer data loop the bar can be processed

        # bar outside of the regular session times
        data.backwards()  # remove bar from data stack
        return True  # tell outer data loop to fetch a new bar

```

This filter:

Uses 
data.p.sessionstart
 and 
data.p.sessionend
 (standard data feed
    parameters) to decide if a bar is in the session.

If 
in-the-session
 the return value is 
False
 to indicate nothing was
    done and the processing of the current bar can continue

If 
not-in-the-session
, the bar is removed from the stream and 
True
 is
    returned to indicate a new bar must be fetched.

Note

The 
data.backwards()
 makes uses of the 
LineBuffer

interface. This digs deep into the internals of 
backtrader
.

The use of this filter:

Some data feeds contain 
out of regular trading hours
 data, which may not
    be of interest to the trader. With this filter only 
in-session
 bars will
    be considered.

Data Pseudo-API for Filters

In the example above it has been shown how the filter invokes

data.backwards()
 to remove the current bar from the stream. Useful calls
from the data feed objects which are meant as a 
pseudo-API for Filters
 are:

data.backwards(size=1, force=False)
: removes 
size
 bars from the data
    stream (default is 
1
) by moving the logical pointer backwards. If

force=True
, then the physical storage is also removed.

Removing the physical storage is a delicate operation and is only meant as
a hack for internal operations.

data.forward(value=float('NaN'), size=1)
: moves 
size
 bars the storage
    forward, increasing the physical storage if needed be and fills with

value

data._addtostack(bar, stash=False)
: adds 
bar
 to a stack for later
    processing. 
bar
 is an iterable containing as many values as 
lines

    has the data feed.

If 
stash=False
 the bar added to the stack will be consumed immediately
by the system at the beginning of the next iteration.

If 
stash=True
 the bar will undergo the entire loop processing including
potentially being reparsed by filters

data._save2stack(erase=False, force=False)
: saves the current data bar
    to the stack for later processing. If 
erase=True
 then

data.backwards
 will be invoked and will receive the parameter 
force

data._updatebar(bar, forward=False, ago=0)
: uses the values in the
    iterable 
bar
 to overwrite the values in the data stream 
ago

    positions. With the default 
ago=0
 the current bar will updated. With

-1
, the previous one.

Another example: Pinkfish Filter

This is an example of a filter that can be chained, and is meant so, to another
filter, namely the 
replay filter
. The 
Pinkfish
 name is from the library
which describes the idea in its main page: using daily data to execute
operations which would only be possible with intraday data.

To achieve the effect:

A daily bar will be broken in 2 componentes: 
OHL
 and then 
C
.

Those 2 pieces are chained with 
replay
 to have the following happening in
    the stream:

```
With Len X     -> OHL
With Len X     -> OHLC
With Len X + 1 -> OHL
With Len X + 1 -> OHLC
With Len X + 2 -> OHL
With Len X + 2 -> OHLC
...

```

Logic:

When an 
OHLC
 bar is received it is copied into an interable and broken
    down to become:

An 
OHL
 bar. Because this concept doesn’t actually exist the 
closing

  price is replaced with the 
opening
 price to really form an 
OHLO

  bar.

An 
C
 bar whic also doesn’t exist. The reality is that it will be
  delivered like a tick 
CCCC

The volume if distributed between the 2 parts

The current bar is removed from the stream

The 
OHLO
 part is put onto the stack for immediate processing

The 
CCCC
 part is put into the stash for processing in the next round

Because the stack has something for immediate processing the filter can
  return 
False
 to indicate it.

This filter works together with:

The 
replay
 filter which puts together the 
OHLO
 and 
CCCC
 parts to
    finally deliver an 
OHLC
 bar.

The use case:

Seeing something like if the maximum today is the highest maximum in the
    last 20 sessions an issuing a 
Close
 order which gets executed with the
    2
nd
 tick.

The code:

```
class DaySplitter_Close(bt.with_metaclass(bt.MetaParams, object)):
    '''
    Splits a daily bar in two parts simulating 2 ticks which will be used to
    replay the data:

      - First tick: ``OHLX``

        The ``Close`` will be replaced by the *average* of ``Open``, ``High``
        and ``Low``

        The session opening time is used for this tick

      and

      - Second tick: ``CCCC``

        The ``Close`` price will be used for the four components of the price

        The session closing time is used for this tick

    The volume will be split amongst the 2 ticks using the parameters:

      - ``closevol`` (default: ``0.5``) The value indicate which percentage, in
        absolute terms from 0.0 to 1.0, has to be assigned to the *closing*
        tick. The rest will be assigned to the ``OHLX`` tick.

    **This filter is meant to be used together with** ``cerebro.replaydata``

    '''
    params = (
        ('closevol', 0.5),  # 0 -> 1 amount of volume to keep for close
    )

    # replaying = True

    def __init__(self, data):
        self.lastdt = None

    def __call__(self, data):
        # Make a copy of the new bar and remove it from stream
        datadt = data.datetime.date()  # keep the date

        if self.lastdt == datadt:
            return False  # skip bars that come again in the filter

        self.lastdt = datadt  # keep ref to last seen bar

        # Make a copy of current data for ohlbar
        ohlbar = [data.lines[i][0] for i in range(data.size())]
        closebar = ohlbar[:]  # Make a copy for the close

        # replace close price with o-h-l average
        ohlprice = ohlbar[data.Open] + ohlbar[data.High] + ohlbar[data.Low]
        ohlbar[data.Close] = ohlprice / 3.0

        vol = ohlbar[data.Volume]  # adjust volume
        ohlbar[data.Volume] = vohl = int(vol * (1.0 - self.p.closevol))

        oi = ohlbar[data.OpenInterest]  # adjust open interst
        ohlbar[data.OpenInterest] = 0

        # Adjust times
        dt = datetime.datetime.combine(datadt, data.p.sessionstart)
        ohlbar[data.DateTime] = data.date2num(dt)

        # Ajust closebar to generate a single tick -> close price
        closebar[data.Open] = cprice = closebar[data.Close]
        closebar[data.High] = cprice
        closebar[data.Low] = cprice
        closebar[data.Volume] = vol - vohl
        ohlbar[data.OpenInterest] = oi

        # Adjust times
        dt = datetime.datetime.combine(datadt, data.p.sessionend)
        closebar[data.DateTime] = data.date2num(dt)

        # Update stream
        data.backwards(force=True)  # remove the copied bar from stream
        data._add2stack(ohlbar)  # add ohlbar to stack
        # Add 2nd part to stash to delay processing to next round
        data._add2stack(closebar, stash=True)

        return False  # initial tick can be further processed from stack

```
########################################
docu.txt - lunghezza: 828
########################################
Introduction

Welcome to the 
backtrader
 documentation!

The platform has 2 main objectives:

Ease of use

Go back to 1

Note

Loosely based on the 
Karate (Kid)
 rules by 
Mr. Miyagi
.

The basics of running this platform:

Create a Strategy

Decide on potential adjustable parameters

Instantiate the Indicators you need in the Strategy

Write down the logic for entering/exiting the market

Tip

Or alternatively:

Prepare some indicators to work as 
long
/
short
 signals

And then

Create a 
Cerebro
 Engine

First: Inject the 
Strategy
 (or signal-based strategy)

And then:

Load and Inject a Data Feed (once created use 
cerebro.adddata
)

And execute 
cerebro.run()

For visual feedback use: 
cerebro.plot()

The platform is highly configurable

Let’s hope you, the user, find the platform useful and fun to work with.
